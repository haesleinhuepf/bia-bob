{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee669bf6-190f-4ff6-9de7-bb501f3fa6a5",
   "metadata": {},
   "source": [
    "# Model fine-tuning for Bio-image Analysis tasks\n",
    "In this notebook we use `bia_bob` infrastructure to fine-tune a chatGPT 3.5 model specifically for Bio-image Analysis tasks.\n",
    "\n",
    "A little warning: Fine-tuning costs money. If you [use it the wrong way](https://x.com/haesleinhuepf/status/1718575819298103336?s=20), running this notebook can become expensive.              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "015f9dfe-6511-4a96-a3d4-99fc60aec5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bia_bob import FineTuningFromNotebooks\n",
    "from bia_bob._utilities import filter_out_blacklist\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7a7a6b-3edc-41ef-9672-26c887d1c596",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "We use Python Jupyter Notebooks as training data. These notebooks must have high quality explanatory markdown cells between code cells. For demonstration purposes, we use a subset of the [BioImage Analysis notebooks](https://haesleinhuepf.github.io/BioImageAnalysisNotebooks/intro.html).\n",
    "\n",
    "First, we make a list of notebook files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36ba83ab-0a96-4c29-ab05-f2269ec2f85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'240 notebooks listed'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks = []\n",
    "directory = \"C:/structure/code/BioImageAnalysisNotebooks/docs/\"\n",
    "\n",
    "for root, dirs, files in os.walk(directory):\n",
    "    for file in files:\n",
    "        if file.endswith(\".ipynb\") and \".ipynb_checkpoints\" not in root:\n",
    "            # print(os.path.join(root, file))\n",
    "\n",
    "            notebooks.append(os.path.join(root, file))\n",
    "\n",
    "f\"{len(notebooks)} notebooks listed\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e21576c-34a4-4f36-af33-fd39769ec818",
   "metadata": {},
   "source": [
    "We then filter out some notebooks using a blacklist of folder or filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e65b1f4-2c03-48a2-99a3-c23a97a57b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'209 notebooks remaining'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notebooks = filter_out_blacklist(notebooks, [\n",
    "    \"python_basics\",\n",
    "    \"prompt_engineering\",\n",
    "    \"sustainable_code\",\n",
    "    \"sql\",  \n",
    "])\n",
    "\n",
    "f\"{len(notebooks)} notebooks remaining\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f924721-a3ff-4529-8748-62fbe4ef8f21",
   "metadata": {},
   "source": [
    "We now initialize finetuning. Under the hood, the notebooks are parsed and conversations are extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d2ac642-34a8-4baa-8f65-616f45d680ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1253 conversations extracted'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning = FineTuningFromNotebooks(notebooks)\n",
    "\n",
    "f\"{len(fine_tuning._training_data)} conversations extracted\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e909806-c308-4af9-9043-fc12e5ed4ab0",
   "metadata": {},
   "source": [
    "We could look into a single conversation like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "732e2ee6-8fc7-41be-9a6d-7b5799342aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine_tuning._training_data[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a309f98-edcd-4a38-8838-3ced0f0a239d",
   "metadata": {},
   "source": [
    "We now filter out conversations which contain words from a black list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efbe7064-435f-4752-9d0e-a22c4ca14e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'749 conversations remaining'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning._training_data = filter_out_blacklist(fine_tuning._training_data, [\n",
    "    \"napari\",\n",
    "    \"nbscreenshot\",\n",
    "    \"def \",\n",
    "    \"print\",\n",
    "    \"openai\",\n",
    "    \"https://\"\n",
    "])\n",
    "\n",
    "f\"{len(fine_tuning._training_data)} conversations remaining\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ac2b88-3360-4263-a62a-3651cc06a0e8",
   "metadata": {},
   "source": [
    "Another way for limiting training data (to spare money) is to sample randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01627d6f-352f-488f-82e8-139ae3321c46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'100 conversations remaining'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "fine_tuning._training_data = random.sample(fine_tuning._training_data, 100)\n",
    "\n",
    "f\"{len(fine_tuning._training_data)} conversations remaining\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ead9c17-b4cf-4eb2-a631-0cecf10f180e",
   "metadata": {},
   "source": [
    "## Fine tuning\n",
    "We start the fine-tuning ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f02699c7-49ed-4aa0-b147-1b9a9dd410e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea61bf-484a-42e0-b069-dca46e0ac4a6",
   "metadata": {},
   "source": [
    "... and wait for it to be finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4a9ed81-ccba-45a1-bb96-5ca36cb186ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n",
      "Still training\n"
     ]
    }
   ],
   "source": [
    "while not fine_tuning.is_trained():\n",
    "    print(\"Still training\")\n",
    "    time.sleep(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690eb0ce-b7e1-46be-97f3-72c109bf8334",
   "metadata": {},
   "source": [
    "Afterwards, we can print out the name of the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c24e644f-3f6a-4209-99d0-4c1ff281bc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:gpt-3.5-turbo-0613:personal::8EyMmUpY'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = fine_tuning.trained_model_name()\n",
    "model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38eb7fb-fcd0-453f-b573-75a2ab71ae0a",
   "metadata": {},
   "source": [
    "We can then use this model in `bia_bob`. Note: If you copy-paste the name of this model, you can reuse it any time. However, you cannot share it with others without sharing also the API-Key.\n",
    "\n",
    "If there is an error `ServiceUnavailableError: The server is overloaded or not ready yet` in the following, the model is not available yet. Try again some minutes later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ba7833-bfd0-41e5-9e2b-1240313536fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bia_bob import bob\n",
    "bob.initialize(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4b1090-709a-485f-80b5-56a2240a6dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bob \n",
    "load the image c:/structure/data/blobs.tif,\n",
    "label the objects in it, \n",
    "expand the objects using Voronoi-Tesselation, and\n",
    "draw a mesh between the centroids of the segmented objects.\n",
    "\n",
    "Make a plan first, before you start and don't forget to add the necessary import statements on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f13043-9a7e-4408-b1a9-4286481a3893",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
