{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4b87afc-758e-4d1b-ad4a-a27ddb8a088c",
   "metadata": {},
   "source": [
    "# Switching between OpenAI and Google VertexAI APIs\n",
    "You can re-initialize Bob using model names from different vendors. This is a very basic approach to compare how these models perform in real use-case scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c2e0fb7-0df2-4a9b-b497-5ca62a0aa2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.20.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bia_bob import bob\n",
    "bob.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a1babfb-d3d8-4025-a712-07c477cbee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bia_bob import available_models\n",
    "#available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f31d30-f378-4145-84c3-df7679b8d92f",
   "metadata": {},
   "source": [
    "## Google Vertex AI API\n",
    "Can initialize the Google Vertex AI API by passing a model name from their model family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9c0e70d-1d7c-45cd-b094-4df5f47e5919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div style=\"font-size:7pt\">\n",
       "            This notebook may contain text, code and images generated by artificial intelligence.\n",
       "            Used model: gemini-1.5-flash, vision model: claude-3-opus-20240229, endpoint: None, bia-bob version: 0.20.0.. Do not enter sensitive or private information and verify generated contents according to good scientific practice. Read more: https://github.com/haesleinhuepf/bia-bob#disclaimer\n",
       "            <a href=\"https://github.com/haesleinhuepf/bia-bob\">Read more about code generation using bia-bob</a>.\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#bob.initialize(\"gpt-4o-2024-05-13\")\n",
    "bob.initialize(\"gemini-1.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0106862b-8c2a-48af-a83d-2cf045368596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using googleai \n",
      "    Given the following prompt, decide which of the following types of tasks we need to perform:\n",
      "    1. Code generation: The prompt asks for code to be generated.\n",
      "    2. Text response: The prompt asks for a text response.    \n",
      "    3. Notebook generation: The prompt asks explicitly for a notebook to be generated. Only choose this if the prompt explicitly asks for creating a new notebook.\n",
      "    4. Notebook modification: The prompt asks for a modification of an existing notebook. Only choose this if the prompt explicitly asks for modifying an existing notebook and a) a notebook filename is given or b) the current notebook is mentioned.\n",
      "    5. File generation: The prompt asks for a file to be generated. Only choose this if the prompt explicitly asks for creating a new file with ending \".md\", \".txt\", \".csv\", \".yml\", \".yaml\", \".json\" or \".py\".\n",
      "    1. Other: If you're not sure or if the prompt does not fit into any of the above categories.\n",
      "    \n",
      "    This is the prompt:\n",
      "    load blobs.tif,\n",
      "segment it using Voronoi-Otsu-Labeling in pyclesperanto_prototype\n",
      "and show the image and the resulting label image together in one matplotlib subplot\n",
      "\n",
      "    \n",
      "    Now, write the number of the task type into the next cell. Print the number only.\n",
      "    \n",
      "submitting <class 'list'>\n",
      "role user\n",
      "messages: {'role': 'user', 'parts': {'text': '# Task\\n                   This is the task:\\n                   \\n    Given the following prompt, decide which of the following types of tasks we need to perform:\\n    1. Code generation: The prompt asks for code to be generated.\\n    2. Text response: The prompt asks for a text response.    \\n    3. Notebook generation: The prompt asks explicitly for a notebook to be generated. Only choose this if the prompt explicitly asks for creating a new notebook.\\n    4. Notebook modification: The prompt asks for a modification of an existing notebook. Only choose this if the prompt explicitly asks for modifying an existing notebook and a) a notebook filename is given or b) the current notebook is mentioned.\\n    5. File generation: The prompt asks for a file to be generated. Only choose this if the prompt explicitly asks for creating a new file with ending \".md\", \".txt\", \".csv\", \".yml\", \".yaml\", \".json\" or \".py\".\\n    1. Other: If you\\'re not sure or if the prompt does not fit into any of the above categories.\\n    \\n    This is the prompt:\\n    load blobs.tif,\\nsegment it using Voronoi-Otsu-Labeling in pyclesperanto_prototype\\nand show the image and the resulting label image together in one matplotlib subplot\\n\\n    \\n    Now, write the number of the task type into the next cell. Print the number only.\\n    \\n                   Remember: Your output should be 1) a summary, 2) a plan and 3) the code.\\n                   '}}\n",
      "response: Please provide me with the text you would like me to work with. I need the text in order to understand your request and provide you with a helpful response. \n",
      "\n",
      "For example, you could ask me to:\n",
      "\n",
      "* **Summarize the text:** \"Please summarize this article about climate change.\"\n",
      "* **Translate the text:** \"Translate this passage from Spanish to English.\"\n",
      "* **Analyze the text:** \"What is the main argument in this essay?\"\n",
      "* **Generate a creative writing piece based on the text:** \"Write a poem inspired by this song.\" \n",
      "\n",
      "I am eager to help you! \n",
      "\n",
      "using googleai load blobs.tif,\n",
      "segment it using Voronoi-Otsu-Labeling in pyclesperanto_prototype\n",
      "and show the image and the resulting label image together in one matplotlib subplot\n",
      "\n",
      "submitting <class 'list'>\n",
      "role system\n",
      "role user\n",
      "role user\n",
      "messages: {'role': 'model', 'parts': {'text': '\\n    You are a extremely talented bioimage analyst and you use Python to solve your tasks unless stated otherwise.\\n    If there are several ways to solve the task, chose the option with the least amount of code.    \\n    \\n    \\n    \\n    ## Python specific code snippets\\n    \\n    If the user asks for those simple tasks, use these code snippets.\\n    \\n        * Displays an image with a slider and label showing mouse position and intensity.\\n    stackview.annotate(image, labels)\\n    \\n    * Allows cropping an image along all axes.\\n    stackview.crop(image)\\n    \\n    * Showing an image stored in variable `image` and a segmented image stored in variable `labels` on top using an interative curtain. Also works with two images or two label images.\\n    stackview.curtain(image, labels)\\n    \\n    * Showing an image stored in variable `image` and a segmented image stored in variable `labels` on top with animated blending. Also works with two images or two label images.\\n    stackview.animate_curtain(image, labels)\\n\\n    * Showing an animation / timelapse image stored in variable `image`.\\n    stackview.animate(image)\\n    \\n    * Save an animation / timelapse stored in variable `image` with specified frame delay to a file.\\n    stackview.animate(image, filename=\"output.gif\", frame_delay_ms=100)\\n    \\n    * Display an image stored in a variable `image` (this also works with label images). Prefer stackview.insight over matplotlib.pyplot.imshow!\\n    stackview.insight(image)\\n    \\n    * Build a user interface with sliders for numeric parameters\\n    stackview.interact(func, image)\\n    \\n    * Display an image and allows slicing in three dimensions (Z, Y, and X).\\n    stackview.orthogonal(image)\\n    \\n    * Display an image with a slider and label showing the mouse position and intensity.\\n    stackview.picker(image)\\n    \\n    * Display two images side by side, with an additional overlay view of their overlap\\n    stackview.side_by_side(image1, image2)\\n    \\n    * Display an image with a slider to navigate through a stack.\\n    stackview.slice(image)\\n    \\n    * Allows switching between multiple images and displaying them with a slider.\\n    stackview.switch(images:list)\\n    \\n    * Allows plotting a scatterplot of a pandas dataframe while interactively choosing the columns and using a lasso tool for selecting data points\\n    stackview.scatterplot(dataframe, column_x, column_y, selection_column)\\n    \\n    * Allows plotting a scatterplot of a pandas dataframe in relation to a label image and optionally an image\\n    stackview.clusterplot(image=image, labels=label_image, df=dataframe, labels, column_x, column_y, selection_column, image)\\n    \\n    * Draw two connected scatterplots of a pandas dataframe in relation to a label image and optionally an image\\n    import ipywidgets as widgets\\n    from ipywidgets import HBox\\n    import stackview\\n    def update2(e=None):\\n        widget2.update()\\n    def update1(e=None):\\n        widget1.update()\\n    widget1 = stackview.scatterplot(df=dataframe, column_x=\"column1\", column_y=\"column2\", selection_changed_callback=update2)\\n    widget2 = stackview.scatterplot(df=dataframe, column_x=\"column3\", column_y=\"column4\", selection_changed_callback=update1)\\n    display(HBox([widget1, widget2])) # Arrange the widgets side by side using HBox\\n    \\n    * Set only surface pixels to 1 in destination binary image\\n    cle.binary_edge_detection(source: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * Create a binary image by inverting pixel values in an input image, where all non-zero pixels become 0 and zeros become 1\\n    cle.binary_not(source: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * Determines centroids of all labels in an image and writes coordinates in a pointlist image\\n    cle.centroids_of_labels(labels: ndarray, pointlist_destination: ndarray = None, include_background: bool = False) -> ndarray\\n    \\n    * Analyses a label map to ensure that all labels are indexed without gaps before returning the relabeled map.\\n    cle.relabel_sequential(source: ndarray, output: ndarray = None, blocksize: int = 4096) -> ndarray\\n    \\n    * Apply morphological closing with a sphere-shaped footprint to intensity or binary images.\\n    cle.closing_sphere(input_image: ndarray, destination: ndarray = None, radius_x: int = 1, radius_y: int = 1, radius_z: int = 0) -> ndarray\\n    \\n    * Combines two label images by adding labels from one image to another and sequentially relabeling the result\\n    cle.combine_labels(labels_input1: ndarray, labels_input2: ndarray, labels_destination: ndarray = None) -> ndarray\\n    \\n    * Performs connected components analysis inspecting the box neighborhood of every pixel in a binary image, generating a label map\\n    cle.connected_components_labeling_box(binary_input: ndarray, labeling_destination: ndarray = None, flagged_nonzero_minimum_filter: <built-in function callable> = <function nonzero_minimum_box at 0x000001ECA0BEDC10>) -> ndarray\\n    \\n    * Takes a labelmap and sets edge pixels to 1 and others to 0\\n    cle.detect_label_edges(label_source: ndarray, binary_destination: ndarray = None) -> ndarray\\n    \\n    * Apply Gaussian blur to an input image twice with different sigma values, resulting in two images that are subtracted from each other. It is recommended to apply this operation to images of type Float (32 bit).\\n    cle.difference_of_gaussian(source: ndarray, destination: ndarray = None, sigma1_x: float = 2, sigma1_y: float = 2, sigma1_z: float = 2, sigma2_x: float = 2, sigma2_y: float = 2, sigma2_z: float = 2) -> ndarray\\n    \\n    * Dilates label images to a larger size without overwriting other labels, assuming input images are isotropic.\\n    cle.dilate_labels(labeling_source: ndarray, labeling_destination: ndarray = None, radius: int = 2) -> ndarray\\n    \\n    * Removes labels touching edges of the image in X, Y, and Z; renumbers remaining labels; allows exclusion along min and max X, Y, and Z axes\\n    cle.exclude_labels_on_edges(label_map_input: ndarray, label_map_destination: ndarray = None, exclude_in_x: bool = True, exclude_in_y: bool = True, exclude_in_z: bool = True, exlude_in_x: bool = None, exlude_in_y: bool = None, exlude_in_z: bool = None) -> ndarray\\n    \\n    * Removes labels from a label map above a given maximum size \\n    cle.exclude_large_labels(source: ndarray, destination: ndarray = None, minimum_size: float = 100) -> ndarray\\n    \\n    * Removes labels from a label map below a specified maximum size by number of pixels or voxels.\\n    cle.exclude_small_labels(source: ndarray, destination: ndarray = None, maximum_size: float = 100) -> ndarray\\n    \\n    * Dilates labels in an isotropic label image without overwriting other labels.\\n    cle.dilate_labels(labeling_source: ndarray, labeling_destination: ndarray = None, radius: int = 2) -> ndarray\\n    \\n    * Compute the Gaussian blurred image of an image given sigma values in X, Y, and Z with optional destination and sigma parameters.\\n    cle.gaussian_blur(source: ndarray, destination: ndarray = None, sigma_x: float = 0, sigma_y: float = 0, sigma_z: float = 0) -> ndarray\\n    \\n    * Performs connected components analysis on a binary image by inspecting each pixel\\'s neighbors to generate a label map.\\n    cle.connected_components_labeling_box(binary_input: ndarray, labeling_destination: ndarray = None, flagged_nonzero_minimum_filter: <built-in function callable> = <function nonzero_minimum_box at 0x000001ECA0BEDC10>) -> ndarray\\n    \\n    * Determines centroids of labels in a label image or image stack, writing resulting coordinates in a pointlist image: label image input, destination image of d*n size for d-dimensional label image with n labels, optional background centroid measurement\\n    cle.centroids_of_labels(labels: ndarray, pointlist_destination: ndarray = None, include_background: bool = False) -> ndarray\\n    \\n    * Computes a binary image by inverting pixel values with the binary NOT operator, treating non-zero values as 1.\\n    cle.binary_not(source: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * Replace integer intensities in a 3D vector image with specified values\\n    cle.replace_intensities(source: ndarray, new_values_vector: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * Computes the local maximum of a pixel\\'s spherical neighborhood specified by radius in three dimensions.\\n    cle.maximum_sphere(source: ndarray, destination: ndarray = None, radius_x: float = 1, radius_y: float = 1, radius_z: float = 0) -> ndarray\\n    \\n    * Maximum intensity projection of an image along Z\\n    cle.maximum_z_projection(source: ndarray, destination_max: ndarray = None) -> ndarray\\n    \\n    * Compute the local mean average of a pixel\\'s spherical neighborhood using specified radii dimensions in 3D space.\\n    cle.mean_sphere(source: ndarray, destination: ndarray = None, radius_x: float = 1, radius_y: float = 1, radius_z: float = 1) -> ndarray\\n    \\n    * Calculates the mean average intensity projection of an image along Z.\\n    cle.mean_z_projection(source: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * takes a label image, merges touching labels, renumbers them, and produces a new label image\\n    cle.merge_touching_labels(labels_input: ndarray, labels_destination: ndarray = None) -> ndarray\\n    \\n    * Computes the local minimum of a pixels spherical neighborhood with specified radius dimensions\\n    cle.minimum_sphere(source: ndarray, destination: ndarray = None, radius_x: float = 1, radius_y: float = 1, radius_z: float = 1) -> ndarray\\n    \\n    * Calculates the minimum intensity projection of an image along the Z-axis\\n    cle.minimum_z_projection(source: ndarray, destination_min: ndarray = None) -> ndarray\\n    \\n    * Compute the local mode of a pixels sphere shaped neighborhood to locally correct semantic segmentation results of an image, with specified half-width and half-height (radius) of the sphere, and intensities ranging from 0 to 255, returning the smallest value in case of multiple maximum frequency values.\\n    cle.mode_sphere(source: ndarray, destination: ndarray = None, radius_x: int = 1, radius_y: int = 1, radius_z: int = 1) -> ndarray\\n    \\n    * Reads intensity values from labeled image positions and stores them in a new vector, taking into consideration certain constraints on label structure.\\n    cle.read_intensities_from_map(labels: ndarray, map_image: ndarray, values_destination: ndarray = None) -> ndarray\\n    \\n    * Reduce all labels in a label map to their center spots, keeping label IDs intact and setting background to zero.\\n    cle.reduce_labels_to_centroids(source: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * reduce all labels in a label map to their edges, maintaining label IDs and setting background to zero\\n    cle.reduce_labels_to_label_edges(source: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * Analyses and renumbers a label map to fill in any gaps in indexing, ensuring that the number of labels matches the maximum label index\\n    cle.relabel_sequential(source: ndarray, output: ndarray = None, blocksize: int = 4096) -> ndarray\\n    \\n    * Replaces integer intensities specified in a vector image with new values\\n    cle.replace_intensities(source: ndarray, new_values_vector: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * Apply morphological opening operation, fill label gaps with voronoi-labeling, and mask background pixels in label image.\\n    cle.smooth_labels(labels_input: ndarray, labels_destination: ndarray = None, radius: int = 0) -> ndarray\\n    \\n    * Convolve image with Sobel kernel to detect edges in image\\n    cle.sobel(source: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * Determines bounding box, area, min, max, mean, standard deviation of intensity and shape descriptors of labelled objects in a label map and corresponding pixels in the original image.\\n    cle.statistics_of_labelled_pixels(intensity_image: ndarray = None, label_image: ndarray = None)\\n    \\n    * Apply Gaussian blur to input image and subtract from original to create destination image.\\n    cle.subtract_gaussian_background(source: ndarray, destination: ndarray = None, sigma_x: float = 2, sigma_y: float = 2, sigma_z: float = 2) -> ndarray\\n    \\n    * Combine two label images by removing overlapping labels from one image that also exist in the other image.\\n    cle.subtract_labels(labels_input1: ndarray, labels_input2: ndarray, labels_destination: ndarray = None) -> ndarray\\n    \\n    * Determine the sum intensity projection of an image along Z\\n    cle.sum_z_projection(source: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * Binarize an image using Otsu\\'s threshold method implemented in scikit-image, utilizing a GPU-based histogram for binary image creation.\\n    cle.threshold_otsu(source: ndarray, destination: ndarray = None) -> ndarray\\n    \\n    * Apply a top-hat filter for background subtraction to an input image.\\n    cle.top_hat_sphere(source: ndarray, destination: ndarray = None, radius_x: float = 1, radius_y: float = 1, radius_z: float = 1) -> ndarray\\n    \\n    * Takes a binary image, labels connected components, dilates regions until they touch, and outputs a label map.\\n    cle.voronoi_labeling(binary_source: ndarray, labeling_destination: ndarray = None) -> ndarray\\n    \\n    * Labels objects in grey-value images using Gaussian blurs, spot detection, Otsu-thresholding, and Voronoi-labeling from isotropic input images.\\n    cle.voronoi_otsu_labeling(source: ndarray, label_image_destination: ndarray = None, spot_sigma: float = 2, outline_sigma: float = 2) -> ndarray\\n    \\n    \\n    \\n    ### Working with AICSImageIO to load microscopy images\\n    \\n    * Loading files with endings other than `.tif`, `,czi`, `.png` or `.jpg` works like this:\\n    ```\\n    from aicsimageio import AICSImage\\n    aics_image = AICSImage(image_filename)\\n    image = aics_image.get_image_data(\"ZYX\")\\n    ```\\n    \\n\\n    ### Prompt-engineering for scientific image/data analysis using bia-bob\\n    \\n    When writing prompts, instead of Python code, you can use the following syntax:\\n    ```python\\n    %%bob\\n    * Do this, \\n    * that and \\n    * by the end, show the result.\\n    ```\\n    \\n    If you explicitly wish to do this with Python code, you can do it like this:\\n    \\n    ```python\\n    from bia_bob import bob\\n    code = bob(\"Do this, that and by the end, show the result.\")\\n    exec(code)\\n    ```\\n    \\n\\n    ### Working with Pandas DataFrames\\n\\n    In case a pandas DataFrame, e.g. `df` is the result of a code block, just write `df.head()`\\n    by the end so that the user can see the intermediate result.\\n    \\n\\n    ### Processing images with scikit-image\\n    \\n    * Load an image file from disc and store it in a variable:\\n    ```\\n    from skimage.io import imread\\n    image = imread(filename)\\n    ```\\n    * Expanding labels by a given radius in a label image works like this:\\n    ```\\n    from skimage.segmentation import expand_labels\\n    expanded_labels = expand_labels(label_image, distance=10)\\n    ```\\n    * Measure properties of labels with respect to an image works like this:\\n    ```\\n    import pandas as pd\\n    from skimage.measure import regionprops_table\\n    properties = [\\'label\\', \\'area\\', \\'mean_intensity\\'] # add more properties if needed\\n    measurements = regionprops_table(label_image, intensity_image=image, properties=properties)\\n    df = pd.DataFrame(measurements)\\n    ```\\n    \\n    \\n    ## Todos\\n    \\n    Answer your response in three sections:\\n    1. Summary: First provide a short summary of the task.\\n    2. Plan: Provide a concise step-by-step plan without any code.\\n    3. Code: Provide the code.\\n    \\n    Structure it with markdown headings like this:\\n    \\n    ### Summary\\n    I will do this and that.\\n    \\n    ### Plan\\n    1. Do this.\\n    2. Do that.\\n    \\n    ### Code\\n    ```\\n    this()\\n    that()\\n    ```\\n    \\n    ## Final remarks\\n    \\n    The following points have highest importance and may overwrite the instructions above.\\n    Make sure to provide 1) summary, 2) plan and 3) code.\\n    Make sure to keep your answer concise and to the point. Make sure the code you write is correct and can be executed.\\n    \\n\\nConfirm these general instructions by answering \\'ok\\'.'}}\n",
      "\n",
      "\n",
      "{'role': 'user', 'parts': {'text': 'ok'}}\n",
      "\n",
      "\n",
      "{'role': 'user', 'parts': {'text': '# Task\\n                   This is the task:\\n                   load blobs.tif,\\nsegment it using Voronoi-Otsu-Labeling in pyclesperanto_prototype\\nand show the image and the resulting label image together in one matplotlib subplot\\n\\n                   Remember: Your output should be 1) a summary, 2) a plan and 3) the code.\\n                   '}}\n",
      "response: Please provide me with some text. I need something to work with in order to help you! \n",
      "\n",
      "For example, you could give me:\n",
      "\n",
      "* **A sentence or paragraph:** \"The cat sat on the mat.\"\n",
      "* **A poem or song lyric:** \"Twinkle, twinkle, little star...\"\n",
      "* **A news article or blog post:** \"Scientists discover new planet...\" \n",
      "* **A code snippet:** `print(\"Hello, world!\")`\n",
      "\n",
      "Let me know what you'd like me to do with the text, and I'll do my best to assist you! \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Please provide me with some text. I need something to work with in order to help you! \n",
       "\n",
       "For example, you could give me:\n",
       "\n",
       "* **A sentence or paragraph:** \"The cat sat on the mat.\"\n",
       "* **A poem or song lyric:** \"Twinkle, twinkle, little star...\"\n",
       "* **A news article or blog post:** \"Scientists discover new planet...\" \n",
       "* **A code snippet:** `print(\"Hello, world!\")`\n",
       "\n",
       "Let me know what you'd like me to do with the text, and I'll do my best to assist you! \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%bob\n",
    "load blobs.tif,\n",
    "segment it using Voronoi-Otsu-Labeling in pyclesperanto_prototype\n",
    "and show the image and the resulting label image together in one matplotlib subplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c592a-a519-4e6f-9806-6d7795509202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
