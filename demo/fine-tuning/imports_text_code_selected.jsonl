{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\nNow we take the average over columns, which means along the first axis or ```axis=0```:", "code": "np.mean(image2, axis=0)"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\nThe same logic applies to all other statistical functions such as taking the minium (```np.min()```), the maxiumum (```np.max()```), standard deviation (```np.std()```), median (```np.median()```) etc.\n\nNote that most of this function can also be called directly on the Numpy array variable. For example", "code": "np.std(image2)"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\nBefore we can crop an image, we may want to know its precise shape (dimensions):", "code": "image.shape"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\nCropping images works exactly like cropping lists and tuples, by using indices to specify the range of elements to use:", "code": "cropped_image1 = image[0:128]\n\nimshow(cropped_image1);\n\nmylist = [1,2,2,3,4,5,78]"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\nTo crop the image in the second dimension as well, we add a `,` in the square brackets:", "code": "cropped_image2 = image[0:128, 128:]\n\nimshow(cropped_image2);"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\n## Sub-sampling images\nAlso step sizes can be specified as if we would process lists and tuples. Technically, we are sub-sampling the image in this case. We sample a subset of the original pixels for example in steps of 5:", "code": "sampled_image = image[::5, ::5]\n\nimshow(sampled_image);"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\n## Flipping images\nNegative step sizes flip the image.", "code": "flipped_image = image[::, ::-1]\n\nimshow(flipped_image);"}
{"imports": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.data import cells3d", "text": "\n\nThe `cells3d` dataset is a 4D-image. Using array-acces we extract a single 2D slice and show it.", "code": "image = cells3d()[30,0]\nimage.shape\n\nplt.imshow(image, cmap='gray')\nplt.colorbar()"}
{"imports": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.data import cells3d", "text": "\n\n## Adjusting visualization independent from the specific image\nThe next image we open may, or may not, have a similar grey-value range. Therefore, we could inspect the histogram of the image and guess a better threshold manually. ", "code": "plt.hist(image.ravel())"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")\nimshow(image)", "text": "\n\n`cle.` also comes with an imshow function, that allows for example showing label images more conveniently:", "code": "cle.imshow(labels, labels=True)"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")\nimshow(image)", "text": "\n\nOne can also determine label edges and blend them over the image.", "code": "label_edges = cle.detect_label_edges(labels) * labels\n\ncle.imshow(image, continue_drawing=True, color_map=\"Greys_r\")\ncle.imshow(label_edges, labels=True, alpha=0.5)"}
{"imports": "import pyclesperanto_prototype as cle\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\ninput_image = imread('../../data/Haase_MRT_tfl3d1.tif')", "text": "\n\n## Projection\npyclesperanto offers min/mean/max and sum projections in x, y and z.", "code": "# Maximum Z Projection\nprojection = cle.maximum_z_projection(input_image)\n\n# show result\ncle.imshow(projection)"}
{"imports": "import pyclesperanto_prototype as cle\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\ninput_image = imread('../../data/Haase_MRT_tfl3d1.tif')", "text": "\n\n## Transpose XZ\nIn order to transpose axes of images in the GPU, use the transpose methods", "code": "# Transpose X against Z\ntransposed_image = cle.create([256, 256, 129]);\ncle.transpose_xz(input_image, transposed_image)\n\n# show result\ncle.imshow(transposed_image[126])\ncle.imshow(transposed_image[98])"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage.restoration import rolling_ball \nfrom skimage.morphology import disk\nimport matplotlib.pyplot as plt\nfrom skimage.filters import difference_of_gaussians\nfrom skimage.morphology import white_tophat", "text": "\n\nIn some scenarios it also makes sense to divide the image by the background. This helps for example to make all nuclei in this image have similar intensities. This could be advantageous for nuclei segmentation.", "code": "background_gaussian = gaussian(zfish_image, sigma=50, preserve_range=True)\n\nzfish_gaussian = zfish_image / background_gaussian\n\nfig, axs = plt.subplots(1, 3, figsize=(15,10))\n\n# first row\nimshow(zfish_image, plot=axs[0])\naxs[0].set_title(\"Original\")\nimshow(background_gaussian, plot=axs[1])\naxs[1].set_title(\"Background (Gaussian)\")\nimshow(zfish_gaussian, plot=axs[2])\naxs[2].set_title(\"Background divided\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nfrom skimage import filters\nfrom skimage.morphology import ball\nfrom scipy.ndimage import convolve\nimport matplotlib.pyplot as plt\n\ncle.select_device('RTX')", "text": "\n\n## Other kernels\nDepending on which kerne is used for the convolution, the images can look quite differently. A _mean_-kernel for example computes the average pixel intensity locally:", "code": "mean_kernel = np.asarray([\n  [0, 0.2, 0],\n  [0.2, 0.2, 0.2],\n  [0, 0.2, 0],\n])\n\nmean_convolved = convolve(image, mean_kernel)\n\nimshow(mean_convolved, colorbar=True)\n\nmean_convolved"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread, imshow\nfrom skimage.filters import gaussian", "text": "\n\nThis intensity gradient can be removed by dividing the image by its background, a Gaussian blurred version of it self.", "code": "intensity_equivalized = cle.divide_by_gaussian_background(image, sigma_x=10, sigma_y=10)\nintensity_equivalized"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = imread(\"../../data/blobs.tif\")\nblobs.shape\n\ncle.imshow(blobs)", "text": "\n\n## Local Variance filter", "code": "blobs_edges = cle.variance_box(blobs, radius_x=5, radius_y=5)\ncle.imshow(blobs_edges)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = imread(\"../../data/blobs.tif\")\nblobs.shape\n\ncle.imshow(blobs)", "text": "\n\n# Local standard deviation\n... is just the square root of the local variance", "code": "blobs_edges = cle.standard_deviation_box(blobs, radius_x=5, radius_y=5)\ncle.imshow(blobs_edges)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = imread(\"../../data/blobs.tif\")\nblobs.shape\n\ncle.imshow(blobs)", "text": "\n\n## Edge detection is not edge enhancement\nIntuitively, one could apply an edge detection filter to enhance edges in images showing edges. Let's try with an image showing membranes. It's a 3D image btw.", "code": "image = imread(\"../../data/EM_C_6_c0.tif\")\nimage.shape\n\ncle.imshow(image[60])\n\nimage_sobel = cle.sobel(image)\ncle.imshow(image_sobel[60])"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = imread(\"../../data/blobs.tif\")\nblobs.shape\n\ncle.imshow(blobs)", "text": "\n\n## Enhancing edges\nThus, to enhance edges in a membrane image, other filters are more useful. Enhancement may for example mean making membranes thicker and potentially closing gaps.\n\n## Local standard deviation", "code": "image_std = cle.standard_deviation_box(image, radius_x=5, radius_y=5, radius_z=5)\ncle.imshow(image_std[60])"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\n## Denoising\nCommon filters for denoising images are the mean filter, the median filter and the Gaussian filter.", "code": "denoised_mean = filters.rank.mean(image3.astype(np.uint8), morphology.disk(1))\n\nplt.imshow(denoised_mean, cmap='gray')\n\ndenoised_median = filters.median(image3, morphology.disk(1))\n\nplt.imshow(denoised_median, cmap='gray')\n\ndenoised_median2 = filters.median(image3, morphology.disk(5))\n\nplt.imshow(denoised_median2, cmap='gray')\n\ndenoised_gaussian = filters.gaussian(image3, sigma=1)\n\nplt.imshow(denoised_gaussian, cmap='gray')"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\n### Top-hat filtering / background removal", "code": "top_hat = morphology.white_tophat(image3, morphology.disk(15))\n\nplt.imshow(top_hat, cmap='gray')"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\n### Edge detection", "code": "sobel = filters.sobel(image3)\n\nplt.imshow(sobel, cmap='gray')"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Rotation\nFor rotating an image, you need to provide angles corresponding to axes.", "code": "rotated = cle.rotate(input_image, angle_around_z_in_degrees=45)\ncle.imshow(rotated)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\nImages are rotated around their center by default. You can change this by providing an additional parameter. The image will then be rotated around the origin.", "code": "rotated = cle.rotate(input_image, angle_around_z_in_degrees=15, rotate_around_center=False)\ncle.imshow(rotated)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Translation\nImages can be translate by providing translation distances along axes:", "code": "translated = cle.translate(input_image, translate_x=50, translate_y=-50)\ncle.imshow(translated)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Scaling\nYou can scale the image by providing scaling factors.", "code": "scaled = cle.scale(input_image, factor_x=0.5, factor_y=2)\ncle.imshow(scaled)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Rigid transform\nRigid transforms allow to do translations and rotations in one shot", "code": "rigid_transformed = cle.rigid_transform(input_image, translate_x=50, angle_around_z_in_degrees=45)\ncle.imshow(rigid_transformed)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Affine transforms\nTo do translation, rotation, scaling and shearing in one shot, use affine transforms.\n\nTo setup an affine transform, you can do this using a 4x4 transform matrix:", "code": "transform_matrix = np.asarray([\n    [1, 0, 0, 50],\n    [0, 2, 0, 0],\n    [0, 0, 0.5, 0],\n    [0, 0, 0, 1]\n])\ntransformed_image = cle.affine_transform(input_image, transform=transform_matrix)\ncle.imshow(transformed_image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom scipy.linalg import inv\n\nimage = imread('../../data/Haase_MRT_tfl3d1.tif')\n\nimage.shape", "text": "\n\nNote that the affine_transform function in scipy expects a transform that describes the transformation from the output image to the source image. This is the inverse of the defined transform matrix above. Hence, we call `inv()` to invert the matrix. This is very common in software that applies affine transforms. It technically makes sense, even though it might not be the most intuitive way of working with transforms.", "code": "scipy_transformed = ndi.affine_transform(image, inv(matrix))\n\ncle.imshow(scipy_transformed[100])"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\n## Slicing\nFor visualizing 3D images using scikit-image's `imshow`, we need to select a slice to visualize. For example, a Z-slice:", "code": "slice_image = image[100]\n\nimshow(slice_image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\nWe can also select a plane where all pixels have the same Y-position. We just need to specify, that we would like to keep all pixels in Z using the `:` syntax.", "code": "slice_image = image[:, 100]\n\nimshow(slice_image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\n## Cropping\nWe can also select a sub-stack using indexing in the square brackets.", "code": "sub_stack = image[50:150]\n\nsub_stack.shape"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\nWe can also select a sub-region in X. If we want to keep all pixels along Z and Y (the first two dimensions), we just specify `:` to keep all.", "code": "sub_region_x = image[:, :, 100:200]\n\nimshow(sub_region_x[100])"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\nLast but not least, this is how a cropped cube is specified.", "code": "cropped_cube = image[80:130, 120:170, :50]\n\ncropped_cube.shape\n\nimshow(cropped_cube[20])"}
{"imports": "import pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread", "text": "\n\n## Scaling with the voxel size\nThe easiest way for fixing this problem is to scale the dataset with its voxel size. Per definition, this will result in a dataset where the voxels are isotropic and have `voxel_size = 1` (microns in our case) in all directions.", "code": "scale_factor_x = voxel_size_x\nscale_factor_y = voxel_size_y\nscale_factor_z = voxel_size_z\n\nresampled = cle.scale(input_image, \n                      factor_x=scale_factor_x, \n                      factor_y=scale_factor_y, \n                      factor_z=scale_factor_z, \n                      linear_interpolation=True,\n                      auto_size=True)\n\nshow(resampled)"}
{"imports": "import pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread", "text": "\n\nA potential solution is to introduce a `zoom_factor`. It allows tuning how large the resampled image will be:", "code": "zoom_factor = 2\n\nscale_factor_x = voxel_size_x * zoom_factor\nscale_factor_y = voxel_size_y * zoom_factor\nscale_factor_z = voxel_size_z * zoom_factor\n\nresampled_zoomed = cle.scale(input_image, \n                      factor_x=scale_factor_x, \n                      factor_y=scale_factor_y, \n                      factor_z=scale_factor_z, \n                      linear_interpolation=True,\n                      auto_size=True)\n\nshow(resampled_zoomed)\n\nresampled_zoomed.shape"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport stackview\n\nimage = imread(\"../../data/blobs.tif\")[:50,:50]\n\nlabel_image = cle.voronoi_otsu_labeling(image, spot_sigma=4)\n\nlabel_image", "text": "\n\nFrom the objects in this label image, we can derive centroid coordinates.", "code": "centroids = cle.centroids_of_labels(label_image)\ncentroids"}
{"imports": "import stackview\nfrom cellpose import models, io\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\n## Loading a pretrained model\nCellPose comes with a number of pretrained models, e.g. for segmenting images showing cells or nuclei. We will just load a model for segmenting nuclei.", "code": "model = models.Cellpose(gpu=False, model_type='nuclei')"}
{"imports": "import stackview\nfrom cellpose import models, io\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\nWe let the model \"evaluate\" the image to produce masks of segmented nuclei.", "code": "channels = [0,0] # This means we are processing single-channel greyscale images.\n\nmasks, flows, styles, diams = model.eval(image, diameter=None, channels=channels)\n\nstackview.insight(masks.astype(np.uint32))"}
{"imports": "from stardist.models import StarDist2D\nfrom csbdeep.utils import normalize\nfrom stardist import random_label_cmap\n\nimport stackview\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\n## Normalizing the input image\nMany algorithms using neural networks need normalized input data to work on. For example, you can determine the 1% and the 99.8% percentile (that's very commond) and normalize your image so that the intensities spread between these percentiles are afterwards in the range between 0 and 1. We need to do this because the model was trained on an image in this range and might not be able to segment images with different intensity ranges.", "code": "axis_norm = (0,1)\nimage = normalize(image, 1,99.8, axis=axis_norm)"}
{"imports": "from stardist.models import StarDist2D\nfrom csbdeep.utils import normalize\nfrom stardist import random_label_cmap\n\nimport stackview\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\nSegmenting the image and labeling the individual objects is often called \"instance segmentation\" or \"prediction\" in the artificial intelligence community.", "code": "labels, details = model.predict_instances(image)\n\nstackview.insight(labels)"}
{"imports": "from stardist.models import StarDist2D\nfrom csbdeep.utils import normalize\nfrom stardist import random_label_cmap\n\nimport stackview\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\n... or by drawing outlines around segmented regions.", "code": "# create a new plot\nfig, axes = plt.subplots(1,1)\n\n# add two images\naxes.imshow(image, cmap=plt.cm.gray)\naxes.contour(labels, [0.5], linewidths=1.2, colors='r')"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nWe now identify the pixels that sit on the borders of the cells.", "code": "cell_borders = cle.reduce_labels_to_label_edges(cells)\ncell_borders"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nWe can do exactly the same with the organoid to identify the pixels on its surface.", "code": "organoid_border = cle.reduce_labels_to_label_edges(organoid)\norganoid_border"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nBy masking the cell borders with the organoid border - technically that's a pixel-by-pixel multiplication - we can identify the outer borders.", "code": "outer_borders = cle.mask(cell_borders, organoid_border).astype(np.uint32)\nouter_borders"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nIf we subtract the outer borders from all cell borders, we retrieve the inner borders", "code": "inner_borders = (cell_borders - outer_borders).astype(np.uint32)\ninner_borders"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nimage = cle.asarray(imread(\"../../data/mitosis_mod.tif\")[0:40,25:65])\nimage", "text": "\n\nWe then segment the nuclei.", "code": "label_image = cle.voronoi_otsu_labeling(image, spot_sigma=2, outline_sigma=1)\nlabel_image"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nimage = cle.asarray(imread(\"../../data/mitosis_mod.tif\")[0:40,25:65])\nimage", "text": "\n\nFrom the nuclei label image we can extract another label image which contains all pixels that are on the edge of the labels.", "code": "edge_label_image = cle.reduce_labels_to_label_edges(label_image)\nedge_label_image"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nimage = cle.asarray(imread(\"../../data/mitosis_mod.tif\")[0:40,25:65])\nimage", "text": "\n\nIn case one wanted to measure in thicker areas along the borders, we could expand the borders.", "code": "thicker_edges = cle.dilate_labels(edge_label_image, radius=1)\nthicker_edges"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nWe can now merge all cells whose borders are annotated.", "code": "result = cle.merge_annotated_touching_labels(oversegmented, annotation)\nresult"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nAs the membranes have different intensity depending on the region in the image, we need to correct for this first.", "code": "background_subtracted = cle.divide_by_gaussian_background(image, sigma_x=10, sigma_y=10)\nbackground_subtracted"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nFrom this image, we extract the coordinates of centroids. From these centroids, we can build a distance matrix. In this matrix, the distance from all centroids to all other centroids is computed. The diagonale is zero as it corresponds to the distance of one centroid to itself. Furthermore, the distance to background (first row and first colum) is also zero, as background is not considered for distance computation.", "code": "centroids = cle.centroids_of_labels(labels)\n\ndistance_matrix = cle.generate_distance_matrix(centroids, centroids)\ndistance_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport numpy as np", "text": "\n\nFirst, we dilate the labels by half of the maximum distance the edges are allowed to have.", "code": "maximum_distance = 12\n\ndilated_labels = cle.dilate_labels(labels, radius=maximum_distance/2)\ndilated_labels"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport numpy as np", "text": "\n\nWe then merge the labels if the touch.", "code": "merged_dilated_labels = cle.merge_touching_labels(dilated_labels)\nmerged_dilated_labels"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport stackview", "text": "\n\nUsing the functions `mode_sphere` and `mode_box` we can make the result less noisy.", "code": "cle.mode_sphere(semantic_segmentation, radius_x=2, radius_y=2).astype(np.uint32)\n\ncle.mode_sphere(semantic_segmentation, radius_x=4, radius_y=4).astype(np.uint32)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport stackview", "text": "\n\nWhen the radius becomes wider and wider, the result contains less and less local information.", "code": "cle.mode_sphere(semantic_segmentation, radius_x=10, radius_y=10).astype(np.uint32)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom skimage import filters", "text": "\n\n## Erosion and Dilation\nTo make white islands in the black ocean smaller, we need to _erode_ its coastlines.", "code": "eroded = morphology.binary_erosion(image_binary, disk)\n\nplt.imshow(eroded, cmap='gray')"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom skimage import filters", "text": "\n\nIf we dilate the image afterwards, we get white islands back that look smoother than in the original binary image.", "code": "eroded_dilated = morphology.binary_dilation(eroded, disk)\n\nplt.imshow(eroded_dilated, cmap='gray')"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom skimage import filters", "text": "\n\nCalling erosion and dilation subsequently is so common that there is an extra function which does exactly that. As the gab between islands _open_ the operation is called _opening_.", "code": "opened = morphology.binary_opening(image_binary, disk)\n\nplt.imshow(opened, cmap='gray')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nlabel_image = cle.gauss_otsu_labeling(imread(\"../../data/mitosis_mod.tif\"), outline_sigma=0)\nlabel_image", "text": "\n\n## Eroding labels\nWhen eroding labels, we need to be careful that objects might split into two. This could be intentional, e.g. to differentiate touching nuclei like in the example above.", "code": "eroded_label_image = cle.erode_labels(label_image,\n                                      radius=2,\n                                      relabel_islands=False)\neroded_label_image\n\neroded_label_image2 = cle.erode_labels(label_image,\n                                      radius=2,\n                                      relabel_islands=True)\neroded_label_image2"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nlabel_image = cle.gauss_otsu_labeling(imread(\"../../data/mitosis_mod.tif\"), outline_sigma=0)\nlabel_image", "text": "\n\n## Dilating labels\nWe can then dilate the labels again to come back to their original size approximately. This might also be useful in case segmented objects are too small in general.", "code": "dilated_label_image = cle.dilate_labels(eroded_label_image2, \n                                        radius=2)\ndilated_label_image"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nlabel_image = cle.gauss_otsu_labeling(imread(\"../../data/mitosis_mod.tif\"), outline_sigma=0)\nlabel_image", "text": "\n\n## Opening and closing labels\nOpening and closing for label images is similar like for binary images. The only difference is that when labels touch, they cannot expand anymore.\n\nNote that opening labels may make small labels disappear.", "code": "opened_label_image = cle.opening_labels(label_image,\n                                        radius=2)\nopened_label_image\n\nclosed_label_image = cle.closing_labels(label_image,\n                                        radius=2)\nclosed_label_image"}
{"imports": "import apoc\n\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport numpy as np\n\ncle.select_device('RTX')\n\nimage = imread('../../data/blobs.tif')\nlabels = cle.label(cle.threshold_otsu(image))\nannotation = imread('../../data/label_annotation.tif')\n\ncle.imshow(image)\ncle.imshow(labels, labels=True)\ncle.imshow(annotation, labels=True)", "text": "\n\n## Training\nFor training the classifier, you need to specify features. In the following we use mean and standard deviation intensity within the labeled objects and the object size and shape.", "code": "features = 'area,mean_max_distance_to_centroid_ratio,standard_deviation_intensity'\n\ncl_filename = \"object_selector.cl\"\n\n# Create an object classifier\napoc.erase_classifier(cl_filename) # delete it if it was existing before\nclassifier = apoc.ObjectSelector(cl_filename, positive_class_identifier=1)\n\n# train it\nclassifier.train(features, labels, annotation, image)"}
{"imports": "import apoc\n\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport numpy as np\n\ncle.select_device('RTX')\n\nimage = imread('../../data/blobs.tif')\nlabels = cle.label(cle.threshold_otsu(image))\nannotation = imread('../../data/label_annotation.tif')\n\ncle.imshow(image)\ncle.imshow(labels, labels=True)\ncle.imshow(annotation, labels=True)", "text": "\n\nAfter training, we can ask the classifier how important features were while doing the prediction.", "code": "classifier.feature_importances()"}
{"imports": "import pyclesperanto_prototype as cle\n\nfrom skimage.io import imread\nimport matplotlib\nimport numpy as np\nimport stackview\n\n# initialize GPU\ncle.select_device(\"GTX\")", "text": "\n\nLet's assume we're not interested in the very small objects as they might be result of a false segmentation of some noise. We do know that the objects we imaged have a certain minimum size. From this physical guess, we need to estimate a number of pixels (in 2D) or voxels (in 3D) object are large. We can then use this number as `size_threshold` in pixels or voxels.", "code": "size_threshold = 200 # pixels\n\nlarge_labels_only = cle.exclude_small_labels(label_image, maximum_size=size_threshold)\n\nlarge_labels_only"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\nWhen measuring the maximum intensity in the image, we can see that this label image containing 4 labels is obviously not sequentially labeled.", "code": "np.max(label_image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\nAlso pyclesperanto has a function for relabeling label images sequentially. The result is supposed identical to the result in scikit-image. It just doesn't return the additional values.", "code": "relabeled1 = cle.relabel_sequential(label_image)\n\ncle.imshow(relabeled1, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\n## Reverting sequential labeling\nIn some cases we apply an operation to a label image that returns a new label image with less labels that are sequentially labeled but the label-identity is lost. This happens for example when excluding labels from the label image that are too small.", "code": "large_labels = cle.exclude_small_labels(relabeled, maximum_size=260)\n\ncle.imshow(large_labels, labels=True, max_display_intensity=4)\n\nnp.unique(large_labels)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nThe `smooth_labels` function allows to straighten the outlines of the labels.", "code": "cle.smooth_labels(labels, radius=5)"}
{"imports": "import numpy as np\nfrom pyclesperanto_prototype import imshow\nimport matplotlib.pyplot as plt\n\nimage = np.asarray([\n    [1, 0, 2, 1, 0, 0, 0],\n    [0, 3, 1, 0, 1, 0, 1],\n    [0, 5, 5, 1, 0, 1, 0],\n    [0, 6, 6, 5, 1, 0, 2],\n    [0, 0, 5, 6, 3, 0, 1],\n    [0, 1, 2, 1, 0, 0, 1],\n    [1, 0, 1, 0, 0, 1, 0]\n])\n\nimshow(image, colorbar=True)", "text": "\n\n## Binary images\nThe most basic way of that is binarization, turning the image into a \"positive\" and a \"negative\" region. Typically, binary images are used for that, which could for example contain two different pixel values `True` and `False` representing \"positive\" and \"negative\", respectively. Technically, every image can be interpreted as a binary image using the rationale \"Every pixel is considered positive that is neither `False` nor `0`.\"\n\n## Image thresholding\nA very basic algorithm for separating low intensity regions from high intensity regions in the image is thresholding.\nWe will now make a new image containing `True` and `False` as pixel values depending on if the original image had intensity lower or higher a given threshold. As this image has just two different pixel values, it is a binary image:", "code": "threshold = 4\n\nbinary_image = image > threshold\n\nbinary_image\n\nimshow(binary_image)"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk, binary_erosion, binary_dilation, binary_opening, binary_closing\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes\nimport pyclesperanto_prototype as cle\n\n# load image\nimage = imread(\"../../data/embryos_grey.tif\")\n\n# binarize the image\nthreshold = filters.threshold_otsu(image)\nbinary_image = image <= threshold\n\n# Show original image and binary image side-by-side\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(image, plot=axs[0])\naxs[0].set_title('Original')\n\ncle.imshow(binary_image, plot=axs[1])\naxs[1].set_title('Binary')", "text": "\n\n## Binary dilation\nAnalogously, dilation turns black pixels white which have a white neighbor.", "code": "dilated1 = binary_dilation(binary_image, disk(1))\ndilated4 = binary_dilation(binary_image, disk(4))\n\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\ncle.imshow(binary_image, plot=axs[0])\naxs[0].set_title('Binary image')\n\ncle.imshow(dilated1, plot=axs[1])\naxs[1].set_title('Dilated r=1')\n\ncle.imshow(dilated4, plot=axs[2])\naxs[2].set_title('Dilated r=4')"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk, binary_erosion, binary_dilation, binary_opening, binary_closing\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes\nimport pyclesperanto_prototype as cle\n\n# load image\nimage = imread(\"../../data/embryos_grey.tif\")\n\n# binarize the image\nthreshold = filters.threshold_otsu(image)\nbinary_image = image <= threshold\n\n# Show original image and binary image side-by-side\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(image, plot=axs[0])\naxs[0].set_title('Original')\n\ncle.imshow(binary_image, plot=axs[1])\naxs[1].set_title('Binary')", "text": "\n\n## Binary closing and opening\nBy combining operations such as erosion and dilation subsequently, one can close and open binary images.", "code": "opened = binary_opening(binary_image, disk(4))\nclosed = binary_closing(binary_image, disk(4))\n\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\ncle.imshow(binary_image, plot=axs[0])\naxs[0].set_title('Binary image')\n\ncle.imshow(opened, plot=axs[1])\naxs[1].set_title('Opened')\n\ncle.imshow(closed, plot=axs[2])\naxs[2].set_title('Closed')"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk, binary_erosion, binary_dilation, binary_opening, binary_closing\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes\nimport pyclesperanto_prototype as cle\n\n# load image\nimage = imread(\"../../data/embryos_grey.tif\")\n\n# binarize the image\nthreshold = filters.threshold_otsu(image)\nbinary_image = image <= threshold\n\n# Show original image and binary image side-by-side\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(image, plot=axs[0])\naxs[0].set_title('Original')\n\ncle.imshow(binary_image, plot=axs[1])\naxs[1].set_title('Binary')", "text": "\n\n## Comparing binary images\nFor better visualization of differenced between binary images, we would like to subtract one of the two binary images from the other. If we compute the absolute of this image, we should an image, where all pixels are have value `1` where the two binary images have different values. Unfortunately, we cannot subtract binary images with values `True` and `False` using the `-` operator. We first should turn the `True/False` binary images into numeric images. This is possible by multiplying the images with `1`:", "code": "absolute_difference = np.abs(opened * 1 - binary_image * 1)\n\ncle.imshow(absolute_difference)"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk, binary_erosion, binary_dilation, binary_opening, binary_closing\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes\nimport pyclesperanto_prototype as cle\n\n# load image\nimage = imread(\"../../data/embryos_grey.tif\")\n\n# binarize the image\nthreshold = filters.threshold_otsu(image)\nbinary_image = image <= threshold\n\n# Show original image and binary image side-by-side\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(image, plot=axs[0])\naxs[0].set_title('Original')\n\ncle.imshow(binary_image, plot=axs[1])\naxs[1].set_title('Binary')", "text": "\n\nThe same result can also be achieved using pyclesperanto's `absolute_difference` function:", "code": "absolute_difference2 = cle.absolute_difference(opened, binary_image)\n\ncle.imshow(absolute_difference2)"}
{"imports": "from skimage.measure import label\nlabeled_8_connected = label(binary_image, connectivity=2)\n\nimshow(labeled_8_connected, labels=True)", "text": "\n\nIn practice, for counting cells, the connectivity is not so important. This is why the connectivity parameter is often not provided.\n\n## Connected component labeling in clesperanto\nIn clesperanto, both connectivity options for connected component labeling is implemented in two different functions. When labeling objects using the 4-connected pixel neighborhood, we consider the \"diamond\" neighborhood of all pixels.", "code": "labeled_4_connected2 = cle.connected_components_labeling_diamond(binary_image)\n\nimshow(labeled_4_connected2, labels=True)"}
{"imports": "from skimage.measure import label\nlabeled_8_connected = label(binary_image, connectivity=2)\n\nimshow(labeled_8_connected, labels=True)", "text": "\n\nThe 8-connected neighborhood considers a \"box\" around all pixels.", "code": "labeled_8_connected2 = cle.connected_components_labeling_box(binary_image)\n\nimshow(labeled_8_connected2, labels=True)"}
{"imports": "from skimage.measure import label\nlabeled_8_connected = label(binary_image, connectivity=2)\n\nimshow(labeled_8_connected, labels=True)", "text": "\n\n## Labeling in practice\nTo demonstrate labeling in a practical use case, we label the blobs.tif image.", "code": "# Load data\nfrom skimage.io import imread\nblobs = imread(\"../../data/blobs.tif\")\n\n# Thresholding\nfrom skimage.filters import threshold_otsu\nthreshold = threshold_otsu(blobs)\nbinary_blobs = blobs > threshold\n\n# Connected component labeling\nfrom skimage.measure import label\nlabeled_blobs = label(binary_blobs)\n\n# Visualization\nimport matplotlib.pyplot as plt\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\n\ncle.imshow(blobs, plot=axs[0])\ncle.imshow(binary_blobs, plot=axs[1])\ncle.imshow(labeled_blobs, plot=axs[2], labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nfrom skimage.filters import gaussian", "text": "\n\n## Image Thesholding\nThe most common binarization technique is thresholding. We _apply a threshold_ to determine which pixel lie above a certain pixel intensity and which are below.", "code": "image_binary = image_nuclei > 60\n\nimshow(image_binary)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\n## Measure the mean intensity along lines\nNext we use the matrix configured above to measure the mean average intensity along the lines. We also need to specify how many samples will be taken along the lines.", "code": "num_samples = 10\n\nmean_intensity_matrix = cle.generate_mean_intensity_between_points_matrix(\n                                membranes, coords, connection_matrix, num_samples=num_samples)\nmean_intensity_matrix"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Image segmentation\nFirst, we use cellpose to segment the cells", "code": "# load cellpose model\nmodel = models.Cellpose(gpu=False, model_type='nuclei')\n\n# apply model\nchannels = [0,0] # This means we are processing single channel greyscale images.\nlabel_image, flows, styles, diams = model.eval(nuclei_channel, diameter=None, channels=channels)\n\n# show result\ncle.imshow(label_image, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Labeling pixels on label borders\nNext, we will extract the outline of the segmented nuclei.", "code": "binary_borders = cle.detect_label_edges(label_image)\n\nlabeled_borders = binary_borders * label_image\n\ncle.imshow(label_image, labels=True)\ncle.imshow(binary_borders)\ncle.imshow(labeled_borders, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Dilating outlines\nWe extend the outlines a bit to have a more robust measurement.", "code": "extended_outlines = cle.dilate_labels(labeled_borders, radius=2)\n\ncle.imshow(extended_outlines, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Label intensity statistics\nMeasuring the intensity in the image works using the right intensty and label images.", "code": "stats = cle.statistics_of_labelled_pixels(nuclear_envelope_channel, extended_outlines)\n\nstats[\"mean_intensity\"]"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Parametric maps\nThese measurements can also be visualized using parametric maps", "code": "intensity_map = cle.mean_intensity_map(nuclear_envelope_channel, extended_outlines)\ncle.imshow(intensity_map, min_display_intensity=3000, colorbar=True, colormap=\"jet\")"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nfrom skimage import measure\nfrom pyclesperanto_prototype import imshow\nimport pandas as pd \nimport numpy as np\n\n# load image\nimage = imread(\"../../data/blobs.tif\")\n\n# denoising\nblurred_image = filters.gaussian(image, sigma=1)\n\n# binarization\nthreshold = filters.threshold_otsu(blurred_image)\nthresholded_image = blurred_image >= threshold\n\n# labeling\nlabel_image = measure.label(thresholded_image)\n\n# visualization\nimshow(label_image, labels=True)", "text": "\n\nYou can also add custom columns by computing your own metric, for example the `aspect_ratio`:", "code": "df['aspect_ratio'] = [p.major_axis_length / p.minor_axis_length for p in properties]\ndf"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nfrom skimage import measure\nfrom pyclesperanto_prototype import imshow\nimport pandas as pd \nimport numpy as np\n\n# load image\nimage = imread(\"../../data/blobs.tif\")\n\n# denoising\nblurred_image = filters.gaussian(image, sigma=1)\n\n# binarization\nthreshold = filters.threshold_otsu(blurred_image)\nthresholded_image = blurred_image >= threshold\n\n# labeling\nlabel_image = measure.label(thresholded_image)\n\n# visualization\nimshow(label_image, labels=True)", "text": "\n\nThose dataframes can be saved to disk conveniently:", "code": "df.to_csv(\"blobs_analysis.csv\")"}
{"imports": "from skimage.measure import regionprops\nimport numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nFrom such a pair of spots-image and voronoi diagram, we can dermine to matrices, a touch-matrix (also known as adjaceny-graph matrix) and a distance matrix.", "code": "touch_matrix = cle.generate_touch_matrix(voronoi_diagram)\n\n# igonore touching the background\ncle.set_column(touch_matrix, 0, 0)\n\n\ncentroids = cle.centroids_of_labels(voronoi_diagram)\n\ndistance_matrix = cle.generate_distance_matrix(centroids, centroids)\n\n\ncle.imshow(touch_matrix)\ncle.imshow(distance_matrix)"}
{"imports": "from skimage.io import imread\nimport stackview\n\nfrom nyxus import Nyxus\n\nintensity_image = imread(\"../../data/blobs.tif\")\n\nstackview.insight(intensity_image)\n\nlabel_image = imread(\"../../data/blobs_labeled.tif\")\n\n# visualization\nstackview.insight(label_image)", "text": "\n\nThus, one can also request only specific columns, which should also be faster.", "code": "nyx = Nyxus(['ORIENTATION', 'PERIMETER'])\nfeatures = nyx.featurize(intensity_image, label_image)\nfeatures"}
{"imports": "import pyclesperanto_prototype as cle\n\nimport pandas as pd\nfrom skimage.io import imread, imsave, imshow\nimport matplotlib\nimport numpy as np\n\n# initialize GPU\ncle.select_device(\"RTX\")\n\n# load data\nimage = imread('../../data/blobs.tif')\n\n# segment the image\nlabels = cle.voronoi_otsu_labeling(image, spot_sigma=3.5)\ncle.imshow(labels, labels=True)", "text": "\n\n## Deriving basic statistics of labelled objects", "code": "statistics = cle.statistics_of_labelled_pixels(image, labels)\nstatistics.keys()"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")", "text": "\n\n## Touching neighbors\nWe can show all cells that belong to the \"touching\" neighborhood by visualizing the touching neighbor graph as mesh.", "code": "mesh = cle.draw_mesh_between_touching_labels(tissue)\n\n# make lines a bit thicker for visualization purposes\nmesh = cle.maximum_sphere(mesh, radius_x=1, radius_y=1)\n\ncle.imshow(mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")", "text": "\n\n## Proximal neighbors\nWe can also compute the local maximum of cells with centroid distances below a given upper threshold.", "code": "local_maximum = cle.maximum_of_proximal_neighbors_map(example_image, tissue, max_distance=20)\ncle.imshow(local_maximum, min_display_intensity=30, max_display_intensity=90, color_map='jet')\n\nlocal_maximum = cle.maximum_of_proximal_neighbors_map(example_image, tissue, max_distance=50)\ncle.imshow(local_maximum, min_display_intensity=30, max_display_intensity=90, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\n## Mesh between neighboring cells\n\nBefore counting neighbors, we should visualize neighbor-relationships. We can do this by drawing a mesh between centroids of touching neighbor cells.", "code": "mesh = cle.draw_mesh_between_touching_labels(cells)\n\ncle.imshow(mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\n## Analyze and visualize number of touching neighbors\nWe can also count the touching neighbors and visualize the result as parametric image in colours.", "code": "neighbor_count_image = cle.touching_neighbor_count_map(cells)\n\ncle.imshow(neighbor_count_image, color_map='jet', colorbar=True, min_display_intensity=0)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\nNote, the numbers along the image border may not be accurate. Hence, we should exclude the corresponding cells from the further analysis.", "code": "cells_ex_border = cle.exclude_labels_on_edges(cells)\n\ncle.imshow(cells_ex_border, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\n... we can also read these values together with all other statistics and put them in a pandas DataFrame.", "code": "statistics = cle.statistics_of_labelled_pixels(neighbor_count_image_ex_border, cells_ex_border)\n\ntable = pd.DataFrame(statistics)\n\n# rename a column\ntable = table.rename(columns={\"mean_intensity\": \"number_of_neighbors\"})\n\n# only filter out a subset of all columns; only what we care\ntable = table[[\"label\", \"number_of_neighbors\", \"centroid_x\", \"centroid_y\"]]\n\ntable"}
{"imports": "import pyclesperanto_prototype as cle\nfrom numpy import random\nfrom skimage.io import imread", "text": "\n\nA mesh can for example be drawn between proximal neighbors, nuclei which are closer than a given maximum distance.", "code": "max_distance = 320\n\nproximal_neighbor_mesh = cle.draw_mesh_between_proximal_labels(nuclei, maximum_distance=max_distance)\n\n# we make the lines a bit thicker for visualization purposes\nproximal_neighbor_mesh = cle.maximum_box(proximal_neighbor_mesh, radius_x=5, radius_y=5)\n\ncle.imshow(proximal_neighbor_mesh)\n\nproximal_distance_mesh = cle.draw_distance_mesh_between_proximal_labels(nuclei, maximum_distance=max_distance)\n\n# we make the lines a bit thicker for visualization purposes\nproximal_distance_mesh = cle.maximum_box(proximal_distance_mesh, radius_x=5, radius_y=5)\n\ncle.imshow(proximal_distance_mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom numpy import random\nfrom skimage.io import imread", "text": "\n\n## Distance meshes in more detail\nFor drawing a distance mesh, we need to combine a distance matrix, an abstract representation of distances of all objects to each other with a neighborhood-matrix, which represents which cells are neighbors.\n\nWe start with the distance matrix.", "code": "centroids = cle.centroids_of_background_and_labels(nuclei)\n\ndistance_matrix = cle.generate_distance_matrix(centroids, centroids)\n\n# we ignor distances to the background object\ncle.set_column(distance_matrix, 0, 0)\ncle.set_row(distance_matrix, 0, 0)\n\ncle.imshow(distance_matrix, colorbar=True)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport pandas as pd\n\ncle.get_device()", "text": "\n\nWe now count for every label in `label_image`, how many labels are proximal to it in the `sparse_labels` image. For measuring the distance, we use the centroid distance.", "code": "distance_map = cle.average_distance_to_n_nearest_other_labels_map(label_image, sparse_labels, n=1)\ncle.imshow(distance_map)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Local averaging smoothes edges\nBy averaging measurments locally, we can reduce the noise, but we also introduce a stripe where the region touch", "code": "local_mean_measurements = cle.mean_of_touching_neighbors(measurements, touch_matrix)\n\nparametric_image = cle.replace_intensities(tissue, local_mean_measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Edge preserving filters: median\nBy averaging using a median filter, we can also reduce noise while keeping the edge between the regions sharp", "code": "local_median_measurements = cle.median_of_touching_neighbors(measurements, touch_matrix)\n\nparametric_image = cle.replace_intensities(tissue, local_median_measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nWe can now segment nuclei in our our dataset.", "code": "background_subtracted = cle.top_hat_box(raw_image, radius_x=5, radius_y=5, radius_z=5)\n\nnuclei = cle.voronoi_otsu_labeling(background_subtracted)\n\northogonal_show(nuclei, labels=True)"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nAfter segmentation, we expand the labels a bit so they touch.", "code": "expanded_nuclei = cle.dilate_labels(nuclei, radius=4)\n\northogonal_show(expanded_nuclei, labels=True)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n# Distance meshes\nBefore diving into details we should first have a look at neighborhood relationships and distances between neighbors. A distance mesh visualizes the distances between centroids in colour.", "code": "distance_mesh = cle.draw_distance_mesh_between_touching_labels(labels)\ncle.imshow(distance_mesh, colorbar=True, colormap=\"rainbow\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\nFor more detailed statistics we use a table / pandas DataFrame.", "code": "stats = pd.DataFrame(cle.statistics_of_labelled_neighbors(labels))\nstats"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n## Visualization of statistics\nWe can visualize those measurements in parametric map images.\n\nFor visualization of the table columns as maps, we typically need to prefix the measurements with a `0`. This `0` represents the measurement of the background.", "code": "stats[\"touching_neighbor_count\"].tolist()\n\nlist_of_measurements = cle.prefix_in_x([stats[\"touching_neighbor_count\"].tolist()])\nlist_of_measurements\n\ncle.replace_intensities(labels, list_of_measurements)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Number of touching neighbors and proximal neighbors", "code": "visualize(cell_estimation, tribolium_statistics, \"touching_neighbor_count\")\n\nvisualize(cell_estimation, tribolium_statistics, \"proximal_neighbor_count_d10\")\n\nvisualize(cell_estimation, tribolium_statistics, \"proximal_neighbor_count_d20\")\n\nvisualize(cell_estimation, tribolium_statistics, \"proximal_neighbor_count_d40\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Distances to touching neighbors", "code": "visualize(cell_estimation, tribolium_statistics, \"minimum_distance_of_touching_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"average_distance_of_touching_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_touching_neighbors\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Distance to nearest neighbors", "code": "visualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_n1_nearest_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_n6_nearest_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_n10_nearest_neighbors\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Distance to the most distant other label", "code": "visualize(cell_estimation, tribolium_statistics, \"distance_to_most_distant_other\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Touch count\nTouch count is the number of voxels labels touch others.", "code": "visualize(cell_estimation, tribolium_statistics, \"touch_count_sum\")\n\nvisualize(cell_estimation, tribolium_statistics, \"minimum_touch_count\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_touch_count\")"}
{"imports": "import apoc\n\nfrom skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib.pyplot as plt", "text": "\n\nNext, we need to define which features we want to use for classifying objects. We will use area, shape and the standard deviation of the intensity.", "code": "features = 'area mean_max_distance_to_centroid_ratio standard_deviation_intensity'\n\n# Create an object classifier\nfilename = \"../../data/blobs_object_classifier.cl\"\nclassifier = apoc.ObjectClassifier(filename)\n\n# train it; after training, it will be saved to the file specified above\nclassifier.train(features, labels, annotation, image)"}
{"imports": "import apoc\n\nfrom skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib.pyplot as plt", "text": "\n\nAfter the classifier has been trained, we can use it immediately to predict the classification of the objects in the image.", "code": "# determine object classification\nclassification_result = classifier.predict(labels, image)\n\ncle.imshow(classification_result, labels=True)"}
{"imports": "import apoc\n\nfrom skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib.pyplot as plt", "text": "\n\n## Prediction\nYou can also reload the classifier from disc and apply it to other images. We will simulate this by rotating the original image. This is by the way a good sanity check to see if the classification depends on the orientation of the image.", "code": "image2 = cle.rotate(image, angle_around_z_in_degrees=90)\nlabels2 = cle.rotate(labels, angle_around_z_in_degrees=90)\n\nclassifier2 = apoc.ObjectClassifier(\"../../data/blobs_object_classifier.cl\")\n\nclassification_result2 = classifier2.predict(labels2, image2)\n\ncle.imshow(classification_result2, labels=True)"}
{"imports": "from skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport pandas as pd\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ncle.select_device('RTX')", "text": "\n\nWe previously created an object classifier and apply it now to the pair of intensity and label images.", "code": "classifier = apoc.ObjectClassifier(\"../../data/maize_cslm_object_classifier.cl\")\nclassification_map = classifier.predict(labels=labels, image=image)\n\ncle.imshow(classification_map, labels=True, min_display_intensity=0)"}
{"imports": "from sklearn.ensemble import RandomForestClassifier\n\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow, replace_intensities, relabel_sequential\nfrom skimage.filters import threshold_otsu\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import clear_border\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt", "text": "\n\n## Feature extraction\nThe first step to classify objects according to their properties is [feature extraction](feature_extraction).", "code": "stats = regionprops(labels, intensity_image=image)\n\n# read out specific measurements\nlabel_ids =          np.asarray([s.label for s in stats])\nareas =              np.asarray([s.area for s in stats])\nminor_axis_lengths = np.asarray([s.minor_axis_length for s in stats])\nmajor_axis_lengths = np.asarray([s.major_axis_length for s in stats])\n\n# compute additional parameters\naspect_ratios = major_axis_lengths / minor_axis_lengths"}
{"imports": "from sklearn.ensemble import RandomForestClassifier\n\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow, replace_intensities, relabel_sequential\nfrom skimage.filters import threshold_otsu\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import clear_border\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt", "text": "\n\nWe also read out the maximum intensity of every labeled object from the ground truth annotation. These values will serve to train the classifier.", "code": "annotation_stats = regionprops(labels, intensity_image=annotation)\n\nannotated_class = np.asarray([s.max_intensity for s in annotation_stats])"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\n## Applying the tiled image processing to a zarr-backed dataset\n\nApplying the function to our zarr dataset will also result in a dask array.", "code": "overlap_width = 30\n\ntile_map = da.map_overlap(area_map, zarr_image, depth=overlap_width, boundary=0)\n\ntile_map"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nWhen we invoke saving the results to disk, the processing will happen on individual tiles.", "code": "processed_zarr_filename = '../../data/P1_H_C3H_M004_17-processed.zarr'\n\ntile_map.to_zarr(processed_zarr_filename, overwrite=True)"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nfrom skimage.measure import label as skimage_label\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom dask_image.ndmeasure import label as daskimage_label\n\nimage = imread(\"../../data/blobs.tif\") > 128\nimshow(image)\n\ntiles = da.from_array(image, chunks=(128, 128))\ntiles", "text": "\n\n## Tiled connected component labeling using dask-image\nThe image processing library dask-image has a distributed version of connected component labeling available [dask_image.ndmeasure.label](http://image.dask.org/en/latest/dask_image.ndmeasure.html?highlight=label#dask_image.ndmeasure.label):", "code": "result_di, num_labels = daskimage_label(image)\n\nimshow(result_di, labels=True)"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\n## Loading the zarr-backed image\nDask brings built-in support for the zarr file format. We can create dask arrays directly from a zarr file.", "code": "zarr_image = da.from_zarr(zarr_filename)\nzarr_image"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nThis time, we do not use tile overlap, because we are not measuring properties of the nuclei and thus, don't need a prefect segmentation of them.", "code": "tile_map = da.map_blocks(count_nuclei, zarr_image)\n\ntile_map"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\n## Loading the zarr-backed image\nDask brings built-in support for the zarr file format. We can create dask arrays directly from a zarr file.", "code": "zarr_image = da.from_zarr(zarr_filename)\nzarr_image"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nFor processing tiles using dask, we setup processing blocks with no overlap.", "code": "tile_map = da.map_blocks(count_nuclei, zarr_image)\n\ntile_map"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow", "text": "\n\nOur starting point is again a binary image showing segmented objects.", "code": "image = imread(\"../../data/blobs.tif\") > 128\nimshow(image)"}
{"imports": "import stackview", "text": "\n\n`stackview.curtain` allows us to visualize our label_image on top of our image", "code": "stackview.curtain(image, label_image, continuous_update=True,zoom_factor = 3) "}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import measure\nimport pyclesperanto_prototype as cle", "text": "\n\nWe first open an image and label objects in it.", "code": "# Load data\nblobs = imread('../../data/blobs.tif')\ncle.asarray(blobs)\n\nlabeled_blobs = cle.voronoi_otsu_labeling(blobs, spot_sigma=3.5)\nlabeled_blobs"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import measure\nimport pyclesperanto_prototype as cle", "text": "\n\nThen, we analyze the labeled elements and get their properties.", "code": "# Analyse objects\nregionprops = measure.regionprops(labeled_blobs)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom numpy import random\nfrom skimage.io import imread\nimport matplotlib", "text": "\n\n# Starting point: Label map", "code": "binary = cle.binary_not(cle.threshold_otsu(intensity_image))\ncells = cle.voronoi_labeling(binary)\n\ncle.imshow(cells, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom numpy import random\nfrom skimage.io import imread\nimport matplotlib", "text": "\n\n## Nearest neighbor distance maps", "code": "average_distance_of_n_closest_neighbors_map = cle.average_distance_of_n_closest_neighbors_map(cells, n=1)\ncle.imshow(average_distance_of_n_closest_neighbors_map, color_map='jet')\n\naverage_distance_of_n_closest_neighbors_map = cle.average_distance_of_n_closest_neighbors_map(cells, n=5)\ncle.imshow(average_distance_of_n_closest_neighbors_map, color_map='jet')"}
