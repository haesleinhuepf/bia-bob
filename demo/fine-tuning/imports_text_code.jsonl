{"imports": "import numpy as np\nfrom matplotlib.pyplot import imshow", "text": "\n\n## Numpy arrays\n\nAn image is just a two dimensional list of pixels values, in other words a matrix, with a certain number of rows and columns. Therefore we can define it as a list of lists, each list being a row of pixels:", "code": "raw_image_array = [\n    [1, 0, 2, 1, 0, 0, 0],\n    [0, 3, 1, 0, 1, 0, 1],\n    [0, 5, 5, 1, 0, 1, 0],\n    [0, 6, 6, 5, 1, 0, 2],\n    [0, 0, 5, 6, 3, 0, 1],\n    [0, 1, 2, 1, 0, 0, 1],\n    [1, 0, 1, 0, 0, 1, 0]\n]\nraw_image_array\n\nimshow(raw_image_array)"}
{"imports": "import numpy as np\nfrom matplotlib.pyplot import imshow", "text": "\n\nThis output is almost the same as above with the difference that now it is indicated that we are dealing with a Numpy ```array```. Such Numpy arrays can now be treated as a one entity and we can perform the computation that we coudn't before:", "code": "image = np.asarray(raw_image_array)\n\nimage - 2"}
{"imports": "import numpy as np\nfrom matplotlib.pyplot import imshow", "text": "\n\nNote that these computations are very efficient because they are *vectorized*, i.e. they can in principle be performed in parallel.\n\n## Two important properties\n\nArrays like ```image``` have different properties. Two of the most important ones are:\n- the ```shape``` of the array, i.e. the number of rows, columns (and channels, planes etc. for multi-dimensional images)\n- the ```dtype``` of the array, i.e. an image of type `int64` has 2 to the power of 64 different grey values.", "code": "image.shape\n\nimage.dtype"}
{"imports": "import numpy as np\nfrom matplotlib.pyplot import imshow", "text": "\n\nAs images are just arrays, we just set pixel values as if we were accessing arrays. From this you also learn that the first axis (coordinate 0) is going from top to bottom while the second axis (coordinate 3) goes from left to right.", "code": "image1[0,3] = 1\n\nimshow(image1)"}
{"imports": "from skimage.io import imread\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\nAs shown earlier, images are just matrices of intensities. However, showing them as such is not convenient.", "code": "image"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\n## Simple calculus\n\nAs a recap from last chapter, we have seen that we can do arithemtics with images just as we would with simple numbers:", "code": "image1_plus = image1 + 3\nimage1_plus"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\nThis is valid for all basis operations like addition, multiplication etc. Even raising to a given power works:", "code": "image1_plus ** 2"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\n## Combining images\n\nIf images have the same size, we can here again treat them like simple numbers and do maths with them: again addition, multiplication etc. For example:", "code": "image1 + image2"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\n## Functions pixel by pixel\n\nIn addition of allowing us to create various types of arrays, Numpy also provides us functions that can operate on arrays. In many cases, the input is an image and the output is an image of the same size where *a given function has been applied to each individual pixel*. \n\nFor example we might want to apply a log function to an image to reduce the range of values that pixels can take. Here we would use the ```np.log``` function:", "code": "np.log(image2)"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\nAs we can see the input image had 3 rows and 5 columns and the output image has the same dimensions. You can find many functions in Numpy that operate this way e.g. to take an exponential (```np.exp()```), to do trigonometry (```np.cos()```, ```np.sin()```) etc.\n\n## Image statistics\n\nAnother type of functions takes an image as input but returns an output of a different size by computing a statistic on the image or parts of it. For example we can compute the average of *all* ```image2``` pixel values:", "code": "np.mean(image2)"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\nOr we can specify that we want to compute the mean along a certain dimension of the image, in 2D along columns or rows. Let's keep in mind what ```image2``` is:", "code": "image2"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\nNow we take the average over columns, which means along the first axis or ```axis=0```:", "code": "np.mean(image2, axis=0)"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\nThe same logic applies to all other statistical functions such as taking the minium (```np.min()```), the maxiumum (```np.max()```), standard deviation (```np.std()```), median (```np.median()```) etc.\n\nNote that most of this function can also be called directly on the Numpy array variable. For example", "code": "np.std(image2)"}
{"imports": "import numpy as np\nfrom matplotlib import pyplot as plt\n\nimage1 = np.ones((3,5))\nimage1\n\nimage2 = np.random.random((3,5))\nimage2", "text": "\n\nand", "code": "image2.std()"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\nBefore we can crop an image, we may want to know its precise shape (dimensions):", "code": "image.shape"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\nRecap: Visualization using `imshow`:", "code": "imshow(image)"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\nCropping images works exactly like cropping lists and tuples, by using indices to specify the range of elements to use:", "code": "cropped_image1 = image[0:128]\n\nimshow(cropped_image1);\n\nmylist = [1,2,2,3,4,5,78]"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\nTo crop the image in the second dimension as well, we add a `,` in the square brackets:", "code": "cropped_image2 = image[0:128, 128:]\n\nimshow(cropped_image2);"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\n## Sub-sampling images\nAlso step sizes can be specified as if we would process lists and tuples. Technically, we are sub-sampling the image in this case. We sample a subset of the original pixels for example in steps of 5:", "code": "sampled_image = image[::5, ::5]\n\nimshow(sampled_image);"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")", "text": "\n\n## Flipping images\nNegative step sizes flip the image.", "code": "flipped_image = image[::, ::-1]\n\nimshow(flipped_image);"}
{"imports": "import numpy\nmeasurements = numpy.asarray([1, 17, 25, 3, 5, 26, 12])\nmeasurements", "text": "\n\nOur goal is now to recover in this array only values larger than a certain threshold, ```10``` for example. When we use simple Python variables, such comparisons can be done like this:", "code": "a = 5\nb = a > 10\nb"}
{"imports": "import numpy\nmeasurements = numpy.asarray([1, 17, 25, 3, 5, 26, 12])\nmeasurements", "text": "\n\nThe output is a *boolean* value which takes the value ```True``` or ```False```. Luckily we can do the same thing with Numpy arrays:", "code": "mask = measurements > 10\nmask"}
{"imports": "import numpy\nmeasurements = numpy.asarray([1, 17, 25, 3, 5, 26, 12])\nmeasurements", "text": "\n\nInstead of getting a single boolean value we now get a *Numpy array of booleans*. We can now apply use this array as a mask to our data to retrieve a new array that only contains masked values (```True``` in the mask array). For this we use again brackets (like for selecting rows and columns), but use the mask instead of indices:", "code": "measurements[mask]"}
{"imports": "from skimage.io import imread, imshow\nfrom microfilm.microplot import microshow\n\nimage = imread(\"../../data/blobs.tif\")\n\nmicroshow(image);\n\nmask = image > 100\nmask", "text": "\n\nNow we obtain a 2D array filled with boolean values. We can even look at it (white values are ```True```):", "code": "microshow(mask);"}
{"imports": "from skimage.io import imread, imshow\nfrom microfilm.microplot import microshow\n\nimage = imread(\"../../data/blobs.tif\")\n\nmicroshow(image);\n\nmask = image > 100\nmask", "text": "\n\nAnd now we can do indexing to recover all pixel values above our threshold of 100:", "code": "image[mask]\n\nlen(image[mask])"}
{"imports": "from skimage.io import imread, imshow\nfrom microfilm.microplot import microshow\n\nimage = imread(\"../../data/blobs.tif\")\n\nmicroshow(image);\n\nmask = image > 100\nmask", "text": "\n\nWe have 24969 pixels above the threshold.\n\n## Exercises\n\nCreate a new mask for all pixel values above 200.", "code": ""}
{"imports": "from skimage.io import imread, imshow\nfrom microfilm.microplot import microshow\n\nimage = imread(\"../../data/blobs.tif\")\n\nmicroshow(image);\n\nmask = image > 100\nmask", "text": "\n\nApply the mask to retrieve a new array with numbers above 200.", "code": ""}
{"imports": "from microfilm.microplot import microshow\nmicroshow(image_rolled);", "text": "\n\nBy default it uses a Cyan, Magenta, Yellow combination of colormaps, but those can also be changed:", "code": "microshow(image_rolled, cmaps=['pure_red', 'pure_green', 'pure_blue']);"}
{"imports": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.data import cells3d", "text": "\n\nThe `cells3d` dataset is a 4D-image. Using array-acces we extract a single 2D slice and show it.", "code": "image = cells3d()[30,0]\nimage.shape\n\nplt.imshow(image, cmap='gray')\nplt.colorbar()"}
{"imports": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.data import cells3d", "text": "\n\nIf we want to increase brightness, i.e., the perception that the image is emitting more light, we can configure the display range by setting its minimum `vmin` and maximum `vmax`. This improves visibility of the membranes.", "code": "plt.imshow(image, cmap='gray', vmax=10000)\nplt.colorbar()"}
{"imports": "import numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.data import cells3d", "text": "\n\n## Adjusting visualization independent from the specific image\nThe next image we open may, or may not, have a similar grey-value range. Therefore, we could inspect the histogram of the image and guess a better threshold manually. ", "code": "plt.hist(image.ravel())"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")\nimshow(image)", "text": "\n\nThe `cle.` gateway has all methods you need, it does not have sub-packages:", "code": "# noise removal\nblurred = cle.gaussian_blur(image, sigma_x=1, sigma_y=1)\nblurred\n\n# binarization\nbinary = cle.threshold_otsu(blurred)\nbinary\n\n# labeling\nlabels = cle.connected_components_labeling_box(binary)\nlabels\n\n# visualize results\nimshow(labels)"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")\nimshow(image)", "text": "\n\n`cle.` also comes with an imshow function, that allows for example showing label images more conveniently:", "code": "cle.imshow(labels, labels=True)"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")\nimshow(image)", "text": "\n\nOne can also determine label edges and blend them over the image.", "code": "label_edges = cle.detect_label_edges(labels) * labels\n\ncle.imshow(image, continue_drawing=True, color_map=\"Greys_r\")\ncle.imshow(label_edges, labels=True, alpha=0.5)"}
{"imports": "from skimage.io import imread, imshow\n\nimage = imread(\"../../data/blobs.tif\")\nimshow(image)", "text": "\n\nTherefore, it may make sense to increase the figure and combine multiple sub-plots", "code": "fig, axs = plt.subplots(1, 2, figsize=(12,12))\n\n# left plot\ncle.imshow(image, color_map=\"Greys_r\", plot=axs[0])\n\n# right plot\ncle.imshow(image, alpha=0.5, continue_drawing=True, color_map=\"Greys_r\", plot=axs[1])\ncle.imshow(label_edges, labels=True, alpha=0.5, plot=axs[1])"}
{"imports": "from skimage.measure import regionprops\n\nstatistics = regionprops(labels)\n\nimport numpy as np\nnp.mean([s.area for s in statistics])", "text": "\n\nIf you want to explicitly convert your image, e.g. into a numpy array, you can do it like this:", "code": "np.asarray(labels)"}
{"imports": "", "text": "\n\nIn order to process an image using CUDA on the GPU, we need to convert it. Under the hood of this conversion, the image data is sent from computer random access memory (RAM) to the GPUs memory.", "code": "image_gpu = cp.asarray(image)\n\nimage_gpu.shape"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\nIf we then run an operation on the GPU and check memory consumption again, we should see an increase.", "code": "image = np.random.random((1024, 1024, 100))\n\nblurred = cle.gaussian_blur(image)\n\n!nvidia-smi --query-gpu=memory.used --format=csv"}
{"imports": "from skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nimage_stack = imread('../../data/Haase_MRT_tfl3d1.tif')\n\nimage_stack.shape", "text": "\n\nWe see that the data has indeed three dimensions, in this case 192 Z-planes and 256 X and Y pixels. We can display it with pyclesperanto's ```imshow```:", "code": "imshow(image_stack)"}
{"imports": "import matplotlib.pyplot as plt\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\n\n# show three planar images\naxs[0].imshow(image_stack[48], cmap='Greys_r')\naxs[1].imshow(image_stack[96], cmap='Greys_r')\naxs[2].imshow(image_stack[144], cmap='Greys_r');", "text": "\n\n## Videos\nIf an image dataset has a temporal dimension, we call it a video. Processing videos works similar to multi-channel images and image stacks. Let's open a microscopy dataset showing yeast cells rounding over time. (Image data courtesy of Anne Esslinger, Alberti lab, MPI CBG)", "code": "video = imread('../../data/rounding_assay.tif')\n\nvideo.shape\n\nfig, axs = plt.subplots(1, 4, figsize=(15,15))\n\n# show three planar images\naxs[0].imshow(video[0], cmap='Greys_r')\naxs[1].imshow(video[5], cmap='Greys_r')\naxs[2].imshow(video[10], cmap='Greys_r')\naxs[3].imshow(video[15], cmap='Greys_r');"}
{"imports": "import matplotlib.pyplot as plt\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\n\n# show three planar images\naxs[0].imshow(image_stack[48], cmap='Greys_r')\naxs[1].imshow(image_stack[96], cmap='Greys_r')\naxs[2].imshow(image_stack[144], cmap='Greys_r');", "text": "\n\n## n-dimensional data\nHigh-dimensional data are pretty common in microscopy. To process them correctly, one must study carefully what dimensions an image dataset has. We can explore possibilities using the `mitosis` dataset:", "code": "mitosis = imread('../../data/mitosis.tif')\n\nmitosis.shape"}
{"imports": "import matplotlib.pyplot as plt\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\n\n# show three planar images\naxs[0].imshow(image_stack[48], cmap='Greys_r')\naxs[1].imshow(image_stack[96], cmap='Greys_r')\naxs[2].imshow(image_stack[144], cmap='Greys_r');", "text": "\n\nHint: Open the dataset in ImageJ/Fiji to understand what these numbers stand for. You can see there that the mitosis dataset has\n* 51 frames,\n* 5 Z-slices,\n* 2 channels and\n* is 171 x 196 pixels large.\n\nWe grab now channels 1 and 2 of the first time point (index 0) in the center plane (index 2):", "code": "timepoint = 0\nplane = 2\n\nchannel1 = mitosis[timepoint, plane, 0]\nchannel2 = mitosis[timepoint, plane, 1]\n\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\n\naxs[0].imshow(channel1, cmap='Greys_r')\naxs[1].imshow(channel2, cmap='Greys_r');"}
{"imports": "import pyclesperanto_prototype as cle\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\ninput_image = imread('../../data/Haase_MRT_tfl3d1.tif')", "text": "\n\n## Copy Slice\nIn order to visualize crop specific slices; without the image leaving GPU memory, use the `copy_slice` method. ", "code": "# Copy Slice\nimage_slice = cle.create([256, 256]);\nslice_z_position = 40.0;\ncle.copy_slice(input_image, image_slice, slice_z_position)\n\n# show result\ncle.imshow(image_slice)\n\n# Alternatively, don't hand over the output image and retrieve it\nanother_slice = cle.create_2d_xy(input_image)\ncle.copy_slice(input_image, another_slice, slice_index = 80)\n\n# show result\ncle.imshow(another_slice)"}
{"imports": "import pyclesperanto_prototype as cle\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\ninput_image = imread('../../data/Haase_MRT_tfl3d1.tif')", "text": "\n\n## Projection\npyclesperanto offers min/mean/max and sum projections in x, y and z.", "code": "# Maximum Z Projection\nprojection = cle.maximum_z_projection(input_image)\n\n# show result\ncle.imshow(projection)"}
{"imports": "import pyclesperanto_prototype as cle\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\ninput_image = imread('../../data/Haase_MRT_tfl3d1.tif')", "text": "\n\nIf you pass an image stack to `cle.imshow` it will make the maximum intensity projection along Z for you:", "code": "cle.imshow(input_image)\n\n# Sum Z Projection\nprojection = cle.sum_z_projection(input_image)\n\n# show result\ncle.imshow(projection)\n\n# Mean Y Projection\nprojection = cle.mean_y_projection(input_image)\n\n# show result\ncle.imshow(projection)"}
{"imports": "import pyclesperanto_prototype as cle\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\ninput_image = imread('../../data/Haase_MRT_tfl3d1.tif')", "text": "\n\n## Transpose XZ\nIn order to transpose axes of images in the GPU, use the transpose methods", "code": "# Transpose X against Z\ntransposed_image = cle.create([256, 256, 129]);\ncle.transpose_xz(input_image, transposed_image)\n\n# show result\ncle.imshow(transposed_image[126])\ncle.imshow(transposed_image[98])"}
{"imports": "import numpy as np\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk\nfrom skimage.io import imread\n\ntest_image = np.zeros((10,10))\ntest_image[5,3] = 1\ntest_image[5,7] = 1\ntest_image\n\nimshow(test_image)", "text": "\n\nLet's compare Gaussian blurred images with different sigma", "code": "blurred05 = gaussian(test_image, sigma=0.5)\nblurred1 = gaussian(test_image, sigma=1)\nblurred2 = gaussian(test_image, sigma=2)\nblurred3 = gaussian(test_image, sigma=3)\n\nfig, axs = plt.subplots(1, 4, figsize=(15,15))\n\nimshow(blurred05, plot=axs[0])\nimshow(blurred1, plot=axs[1])\nimshow(blurred2, plot=axs[2])\nimshow(blurred3, plot=axs[3])"}
{"imports": "import numpy as np\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk\nfrom skimage.io import imread\n\ntest_image = np.zeros((10,10))\ntest_image[5,3] = 1\ntest_image[5,7] = 1\ntest_image\n\nimshow(test_image)", "text": "\n\nDisks with other radii look like this:", "code": "max_radius = 5\n\nfig, axs = plt.subplots(1, max_radius, figsize=(15,15))\n\nfor r in range(1, max_radius + 1):\n    imshow(disk(r), plot=axs[r - 1])\n    axs[r - 1].set_title(\"Radius \" + str(r))"}
{"imports": "import numpy as np\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk\nfrom skimage.io import imread\n\n# open dataset and extract single plane\nnoisy_mri = imread('../../data/Haase_MRT_tfl3d1.tif')[90]\n\n# zoom in by cropping a part out\nnoisy_mri_zoom = noisy_mri[50:100, 50:100]\n\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\n\naxs[0].imshow(noisy_mri)\naxs[1].imshow(noisy_mri_zoom)", "text": "\n\nNow we apply three filters and compare resulting images.", "code": "median_filtered = filters.median(noisy_mri, disk(1))\nmean_filtered = filters.rank.mean(noisy_mri, disk(1))\ngaussian_filtered = filters.gaussian(noisy_mri, sigma=1)\n\nfig, axs = plt.subplots(2, 3, figsize=(15,10))\n\n# first row\naxs[0, 0].imshow(median_filtered)\naxs[0, 0].set_title(\"Median\")\naxs[0, 1].imshow(mean_filtered)\naxs[0, 1].set_title(\"Mean\")\naxs[0, 2].imshow(gaussian_filtered)\naxs[0, 2].set_title(\"Gaussian\")\n\n# second row\naxs[1, 0].imshow(median_filtered[50:100, 50:100])\naxs[1, 1].imshow(mean_filtered[50:100, 50:100])\naxs[1, 2].imshow(gaussian_filtered[50:100, 50:100])\n"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage.restoration import rolling_ball \nfrom skimage.morphology import disk\nimport matplotlib.pyplot as plt\nfrom skimage.filters import difference_of_gaussians\nfrom skimage.morphology import white_tophat", "text": "\n\nAs example image, we will work with a zebrafish eye data set (Courtesy of Mauricio Rocha Martins, Norden lab, MPI CBG). As you can see, there is some intensity spread around the nuclei we want to segment later on. The source of this background signal is out-of-focus light.", "code": "# load zfish image and extract a channel\nzfish_image = imread('../../data/zfish_eye.tif')[:,:,0]\n\nimshow(zfish_image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage.restoration import rolling_ball \nfrom skimage.morphology import disk\nimport matplotlib.pyplot as plt\nfrom skimage.filters import difference_of_gaussians\nfrom skimage.morphology import white_tophat", "text": "\n\nAfterwards, we subtract the background from the original and display all three images:", "code": "zfish_rolling = zfish_image - background_rolling\n\nfig, axs = plt.subplots(1, 3, figsize=(15,10))\n\n# first row\nimshow(zfish_image, plot=axs[0])\naxs[0].set_title(\"Original\")\nimshow(background_rolling, plot=axs[1])\naxs[1].set_title(\"Background (rolling ball)\")\nimshow(zfish_rolling, plot=axs[2])\naxs[2].set_title(\"Background subtracted\")"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage.restoration import rolling_ball \nfrom skimage.morphology import disk\nimport matplotlib.pyplot as plt\nfrom skimage.filters import difference_of_gaussians\nfrom skimage.morphology import white_tophat", "text": "\n\nWe could do the same using a Gaussian blur filter.", "code": "background_gaussian = gaussian(zfish_image, sigma=20, preserve_range=True)\n\nzfish_gaussian = zfish_image - background_gaussian\n\nfig, axs = plt.subplots(1, 3, figsize=(15,10))\n\n# first row\nimshow(zfish_image, plot=axs[0])\naxs[0].set_title(\"Original\")\nimshow(background_gaussian, plot=axs[1])\naxs[1].set_title(\"Background (Gaussian)\")\nimshow(zfish_gaussian, plot=axs[2])\naxs[2].set_title(\"Background subtracted\")"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage.restoration import rolling_ball \nfrom skimage.morphology import disk\nimport matplotlib.pyplot as plt\nfrom skimage.filters import difference_of_gaussians\nfrom skimage.morphology import white_tophat", "text": "\n\nIn some scenarios it also makes sense to divide the image by the background. This helps for example to make all nuclei in this image have similar intensities. This could be advantageous for nuclei segmentation.", "code": "background_gaussian = gaussian(zfish_image, sigma=50, preserve_range=True)\n\nzfish_gaussian = zfish_image / background_gaussian\n\nfig, axs = plt.subplots(1, 3, figsize=(15,10))\n\n# first row\nimshow(zfish_image, plot=axs[0])\naxs[0].set_title(\"Original\")\nimshow(background_gaussian, plot=axs[1])\naxs[1].set_title(\"Background (Gaussian)\")\nimshow(zfish_gaussian, plot=axs[2])\naxs[2].set_title(\"Background divided\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nfrom skimage import filters\nfrom skimage.morphology import ball\nfrom scipy.ndimage import convolve\nimport matplotlib.pyplot as plt\n\ncle.select_device('RTX')", "text": "\n\nFor demonstrating the principle of convolution, we first define an example image that's rather simple.", "code": "image = np.asarray([\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 2, 0, 0],\n  [0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n]).astype(float)\n\nimshow(image)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nfrom skimage import filters\nfrom skimage.morphology import ball\nfrom scipy.ndimage import convolve\nimport matplotlib.pyplot as plt\n\ncle.select_device('RTX')", "text": "\n\nNext, we define a simple convolution kernel, that is represented by a small image.", "code": "kernel = np.asarray([\n  [0, 1, 0],\n  [1, 1, 1],\n  [0, 1, 0],\n])"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow\nfrom skimage import filters\nfrom skimage.morphology import ball\nfrom scipy.ndimage import convolve\nimport matplotlib.pyplot as plt\n\ncle.select_device('RTX')", "text": "\n\n## Other kernels\nDepending on which kerne is used for the convolution, the images can look quite differently. A _mean_-kernel for example computes the average pixel intensity locally:", "code": "mean_kernel = np.asarray([\n  [0, 0.2, 0],\n  [0.2, 0.2, 0.2],\n  [0, 0.2, 0],\n])\n\nmean_convolved = convolve(image, mean_kernel)\n\nimshow(mean_convolved, colorbar=True)\n\nmean_convolved"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread, imshow\nfrom skimage.filters import gaussian", "text": "\n\nIn this image you see that the intensity of the membranes decreases from top to bottom.", "code": "image = imread('../../data/membranes_2d.tif')\ncle.asarray(image)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread, imshow\nfrom skimage.filters import gaussian", "text": "\n\nThis intensity gradient can be removed by dividing the image by its background, a Gaussian blurred version of it self.", "code": "intensity_equivalized = cle.divide_by_gaussian_background(image, sigma_x=10, sigma_y=10)\nintensity_equivalized"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = imread(\"../../data/blobs.tif\")\nblobs.shape\n\ncle.imshow(blobs)", "text": "\n\n## Local Variance filter", "code": "blobs_edges = cle.variance_box(blobs, radius_x=5, radius_y=5)\ncle.imshow(blobs_edges)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = imread(\"../../data/blobs.tif\")\nblobs.shape\n\ncle.imshow(blobs)", "text": "\n\n# Local standard deviation\n... is just the square root of the local variance", "code": "blobs_edges = cle.standard_deviation_box(blobs, radius_x=5, radius_y=5)\ncle.imshow(blobs_edges)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = imread(\"../../data/blobs.tif\")\nblobs.shape\n\ncle.imshow(blobs)", "text": "\n\n## Edge detection is not edge enhancement\nIntuitively, one could apply an edge detection filter to enhance edges in images showing edges. Let's try with an image showing membranes. It's a 3D image btw.", "code": "image = imread(\"../../data/EM_C_6_c0.tif\")\nimage.shape\n\ncle.imshow(image[60])\n\nimage_sobel = cle.sobel(image)\ncle.imshow(image_sobel[60])"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = imread(\"../../data/blobs.tif\")\nblobs.shape\n\ncle.imshow(blobs)", "text": "\n\nWhen looking very carefully, you may observe that the edges are a bit thicker in the second image. The edge detection filter detects two edges, the increasing signal side of the membrane and the decreasing signal on the opposite side. Let's zoom:", "code": "fig, axs = plt.subplots(1, 2)\ncle.imshow(                image[60, 125:145, 135:155], plot=axs[0])\ncle.imshow(cle.pull(image_sobel)[60, 125:145, 135:155], plot=axs[1])"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = imread(\"../../data/blobs.tif\")\nblobs.shape\n\ncle.imshow(blobs)", "text": "\n\n## Enhancing edges\nThus, to enhance edges in a membrane image, other filters are more useful. Enhancement may for example mean making membranes thicker and potentially closing gaps.\n\n## Local standard deviation", "code": "image_std = cle.standard_deviation_box(image, radius_x=5, radius_y=5, radius_z=5)\ncle.imshow(image_std[60])"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\nTo demonstrate what specific filters do, we start with a very simple image. It contains a lot of zeros and a single pixel with value `1` in the middle.", "code": "image1 = np.zeros((5, 5))\nimage1[2, 2] = 1\nimage1\n\nplt.imshow(image1, cmap='gray')\nplt.colorbar()"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\n## Laplacian\nWhenever you wonder what a filter might be doing, just create a simple test image and apply the filter to it.", "code": "image2 = np.zeros((9, 9))\nimage2[4, 4] = 1\n\nplt.imshow(image2, cmap='gray')\nplt.colorbar()\n\nmexican_hat = filters.laplace(image2)\n\nplt.imshow(mexican_hat, cmap='gray')\nplt.colorbar()"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\n## Interactive filter parameter tuning\nTo understand better what filters are doing, it shall be recommended to apply them interactively. The following code will not render on github.com. You need to execute the notebook locally use this interactive user-interface.", "code": "image3 = imread('../../data/mitosis_mod.tif').astype(float)\n\nstackview.interact(laplacian_of_gaussian, image3, zoom_factor=4)"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\n## More filter examples\nWe demonstrate some more typical filters using this nuclei example image.", "code": "plt.imshow(image3, cmap='gray')"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\n## Denoising\nCommon filters for denoising images are the mean filter, the median filter and the Gaussian filter.", "code": "denoised_mean = filters.rank.mean(image3.astype(np.uint8), morphology.disk(1))\n\nplt.imshow(denoised_mean, cmap='gray')\n\ndenoised_median = filters.median(image3, morphology.disk(1))\n\nplt.imshow(denoised_median, cmap='gray')\n\ndenoised_median2 = filters.median(image3, morphology.disk(5))\n\nplt.imshow(denoised_median2, cmap='gray')\n\ndenoised_gaussian = filters.gaussian(image3, sigma=1)\n\nplt.imshow(denoised_gaussian, cmap='gray')"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\nWe can also show these images side-by-side using matplotlib.", "code": "fig, axes = plt.subplots(1,3, figsize=(15,15))\n\naxes[0].imshow(denoised_mean, cmap='gray')\naxes[1].imshow(denoised_median, cmap='gray')\naxes[2].imshow(denoised_gaussian, cmap='gray')"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\n### Top-hat filtering / background removal", "code": "top_hat = morphology.white_tophat(image3, morphology.disk(15))\n\nplt.imshow(top_hat, cmap='gray')"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\n### Edge detection", "code": "sobel = filters.sobel(image3)\n\nplt.imshow(sobel, cmap='gray')"}
{"imports": "import numpy as np\n\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nfrom skimage import data\nfrom skimage import filters\nfrom skimage import morphology\nfrom scipy.ndimage import convolve, gaussian_laplace\nimport stackview", "text": "\n\nUse a simple function call to try out the function.", "code": "dog_image = difference_of_gaussian(image3, 1, 5)\n\nplt.imshow(dog_image, cmap='gray')"}
{"imports": "import numpy as np\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk\nfrom skimage.io import imread\n\ntest_image = np.zeros((10,10))\ntest_image[5,3] = 1\ntest_image[5,7] = 1\ntest_image\n\nimshow(test_image)", "text": "\n\nLet's compare Gaussian blurred images with different sigma", "code": "blurred05 = gaussian(test_image, sigma=0.5)\nblurred1 = gaussian(test_image, sigma=1)\nblurred2 = gaussian(test_image, sigma=2)\nblurred3 = gaussian(test_image, sigma=3)\n\nfig, axs = plt.subplots(1, 4, figsize=(15,15))\n\nimshow(blurred05, plot=axs[0])\nimshow(blurred1, plot=axs[1])\nimshow(blurred2, plot=axs[2])\nimshow(blurred3, plot=axs[3])"}
{"imports": "import numpy as np\nfrom pyclesperanto_prototype import imshow\nfrom skimage.filters import gaussian\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk\nfrom skimage.io import imread\n\ntest_image = np.zeros((10,10))\ntest_image[5,3] = 1\ntest_image[5,7] = 1\ntest_image\n\nimshow(test_image)", "text": "\n\nDisks with other radii look like this:", "code": "max_radius = 5\n\nfig, axs = plt.subplots(1, max_radius, figsize=(15,15))\n\nfor r in range(1, max_radius + 1):\n    imshow(disk(r), plot=axs[r - 1])\n    axs[r - 1].set_title(\"Radius \" + str(r))"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Rotation\nFor rotating an image, you need to provide angles corresponding to axes.", "code": "rotated = cle.rotate(input_image, angle_around_z_in_degrees=45)\ncle.imshow(rotated)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\nImages are rotated around their center by default. You can change this by providing an additional parameter. The image will then be rotated around the origin.", "code": "rotated = cle.rotate(input_image, angle_around_z_in_degrees=15, rotate_around_center=False)\ncle.imshow(rotated)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Translation\nImages can be translate by providing translation distances along axes:", "code": "translated = cle.translate(input_image, translate_x=50, translate_y=-50)\ncle.imshow(translated)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Scaling\nYou can scale the image by providing scaling factors.", "code": "scaled = cle.scale(input_image, factor_x=0.5, factor_y=2)\ncle.imshow(scaled)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\nIn this context, the `auto_size` parameter might be useful:", "code": "scaled_auto_size = cle.scale(input_image, factor_x=0.5, factor_y=2, auto_size=True)\ncle.imshow(scaled_auto_size)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Rigid transform\nRigid transforms allow to do translations and rotations in one shot", "code": "rigid_transformed = cle.rigid_transform(input_image, translate_x=50, angle_around_z_in_degrees=45)\ncle.imshow(rigid_transformed)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n## Affine transforms\nTo do translation, rotation, scaling and shearing in one shot, use affine transforms.\n\nTo setup an affine transform, you can do this using a 4x4 transform matrix:", "code": "transform_matrix = np.asarray([\n    [1, 0, 0, 50],\n    [0, 2, 0, 0],\n    [0, 0, 0.5, 0],\n    [0, 0, 0, 1]\n])\ntransformed_image = cle.affine_transform(input_image, transform=transform_matrix)\ncle.imshow(transformed_image)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\nAlternatively, you can configure a transform object and pass it:", "code": "transform = cle.AffineTransform3D()\ntransform.translate(50)\ntransform.scale(1, 2, 0.5)\n\ntransformed_image = cle.affine_transform(input_image, transform=transform)\ncle.imshow(transformed_image)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n# Linear interpolation versus nearest neighbor interpolation\nLet's crop the nose and transform it using different interpolation modes.", "code": "crop = input_image[50,125:150,45:70]\n\ncle.imshow(crop)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('TX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape\n\n# push it to GPU memory\ninput_image = cle.push_zyx(np_array)\n\ncle.imshow(input_image)", "text": "\n\n# Nearest neighbor interpolation", "code": "# create a larger image\nrescaled = cle.create(np.asarray(crop.shape) * 10)\n\n# fill it with a scaled version of the image; \ncle.scale(crop, rescaled, factor_x=10, factor_y=10, factor_z=10, linear_interpolation=False)\ncle.imshow(rescaled)"}
{"imports": "import numpy as np\n\n# scaling by factor 1 / s\ns = 0.5\nmatrix = np.asarray([\n    [s, 0, 0, 0],\n    [0, s, 0, 0],\n    [0, 0, s, 0],\n    [0, 0, 0, 1],\n])", "text": "\n\nBefore we can apply a cupy operation to an image, we need to send it to GPU memory. We receive a handle to an image on the GPU that cannot be shown using `imshow`.", "code": "cuda_image = cupy.asarray(image)\ncuda_image.shape"}
{"imports": "import numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape", "text": "\n\nTo setup an affine transform, you can do this using a 4x4 transform matrix:", "code": "transform_matrix = np.asarray([\n    [1, 0, 0, 50],\n    [0, 2, 0, 0],\n    [0, 0, 0.5, 0],\n    [0, 0, 0, 1]\n])"}
{"imports": "import numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\n\n# Laod example data\nnp_array = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_array.shape", "text": "\n\nScikit-image only supports 2D transforms and thus, we pick a slice to transform it:", "code": "# pull image stack from GPU and pick a slice\nimage = np_array[100]\n\nfrom skimage.io import imshow\nimshow(image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom scipy.linalg import inv\n\nimage = imread('../../data/Haase_MRT_tfl3d1.tif')\n\nimage.shape", "text": "\n\n## Translating images\nTo explain the difference between the coordinate systems a bit more, we will now use an affine transform matrix to translate the image. We will translate it by 100 pixels in Y-direction (ZYX-system), also known as dimension 1  (012-system) and -50 pixels in X-direction, a.k.a. the dimension 2. ", "code": "tz = 0\nty = 100\ntx = -50\n\nt0 = 0\nt1 = 100\nt2 = -50"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom scipy.linalg import inv\n\nimage = imread('../../data/Haase_MRT_tfl3d1.tif')\n\nimage.shape", "text": "\n\n### Translating images using scipy\nIn scipy, which follows the 012-system and hence, the transform looks like this:", "code": "matrix = np.asarray([\n [1, 0, 0, t0],\n [0, 1, 0, t1],\n [0, 0, 1, t2],\n [0, 0, 0, 1],\n])"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom scipy.linalg import inv\n\nimage = imread('../../data/Haase_MRT_tfl3d1.tif')\n\nimage.shape", "text": "\n\nNote that the affine_transform function in scipy expects a transform that describes the transformation from the output image to the source image. This is the inverse of the defined transform matrix above. Hence, we call `inv()` to invert the matrix. This is very common in software that applies affine transforms. It technically makes sense, even though it might not be the most intuitive way of working with transforms.", "code": "scipy_transformed = ndi.affine_transform(image, inv(matrix))\n\ncle.imshow(scipy_transformed[100])"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom scipy.linalg import inv\n\nimage = imread('../../data/Haase_MRT_tfl3d1.tif')\n\nimage.shape", "text": "\n\n## Keep it simple\nTo keep affine transforms and coordinate systems easy to use, we have an `AffineTransform3D` class in clesperanto that will manage transform matrices for us and we don't have to think about them anymore. We just need to keep in mind that X goes from left to right, Y goes from top to bottom and Z from front to back in our image stack.", "code": "transform = cle.AffineTransform3D()\ntransform.translate(\n    translate_x=tx,\n    translate_y=ty,\n    translate_z=tz\n)\n\ncle_translated2 = cle.affine_transform(image, transform=transform)\n\ncle.imshow(cle_translated2[100])"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom scipy.linalg import inv\n\nimage = imread('../../data/Haase_MRT_tfl3d1.tif')\n\nimage.shape", "text": "\n\nThe same also works with scaling and rotations.", "code": "scale_factor = 2\n\ntransform = cle.AffineTransform3D()\ntransform.scale(scale_x=scale_factor)\n\ncle_translated2 = cle.affine_transform(image, transform=transform, auto_size=True)\n\ncle.imshow(cle_translated2[100])\n\nscale_factor = 2\nrotation_angle = 45\n\ntransform = cle.AffineTransform3D()\n\ntransform.scale(scale_x=scale_factor)\ntransform.rotate_around_z_axis(rotation_angle)\n\ncle_translated2 = cle.affine_transform(image, transform=transform, auto_size=True)\n\ncle.imshow(cle_translated2[100])"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\n## Slicing\nFor visualizing 3D images using scikit-image's `imshow`, we need to select a slice to visualize. For example, a Z-slice:", "code": "slice_image = image[100]\n\nimshow(slice_image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\nWe can also select a plane where all pixels have the same Y-position. We just need to specify, that we would like to keep all pixels in Z using the `:` syntax.", "code": "slice_image = image[:, 100]\n\nimshow(slice_image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\n## Cropping\nWe can also select a sub-stack using indexing in the square brackets.", "code": "sub_stack = image[50:150]\n\nsub_stack.shape"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\nWe can also select a sub-region in X. If we want to keep all pixels along Z and Y (the first two dimensions), we just specify `:` to keep all.", "code": "sub_region_x = image[:, :, 100:200]\n\nimshow(sub_region_x[100])"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\nFor selectinng all pixels in one direction above a given value, we just need to specify the start before `:`.", "code": "sub_region_y = image[:, 100:]\n\nimshow(sub_region_y[100])"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\nSimilarly, we can select all pixels up to a given position.", "code": "sub_region_x2 = image[:, :, :50]\n\nimshow(sub_region_x2[100])"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow", "text": "\n\nLast but not least, this is how a cropped cube is specified.", "code": "cropped_cube = image[80:130, 120:170, :50]\n\ncropped_cube.shape\n\nimshow(cropped_cube[20])"}
{"imports": "import numpy as np\nimport skimage.transform as sk_transform\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt", "text": "\n\n## Original image\n\nIn our example, we use an image of the actin cytoskeleton of fixed, adherent bovine pulmonary artery endothelial cells.\n\nWe add some artificial noise to better illustrate the effect of denoising later.", "code": "image = imread('../../data/BPAE_actin.tif')\n\n# increase noise to better illustrate the effect of denoising later\nnoisy_image = image + np.random.normal(np.median(image), 2 * np.std(image), image.shape)\n\ncle.imshow(noisy_image)"}
{"imports": "import numpy as np\nimport skimage.transform as sk_transform\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt", "text": "\n\nThis looks a lot better than without anti-aliasing. The gaussian filter managed to remove the noise without loosing more detail than the down-sampling itself.\n\n### GPU accelerated down-scaling with anti-aliasing\n\n`cle.scale()` does not come with an anti-aliasing argument. However, nothing stops us from applying that filter ourselves before down-scaling. We use the same sigma as for `skimage.transform.rescale()` above.", "code": "# first, denoise\nblurred = cle.gaussian_blur(noisy_image, sigma_x=sigma, sigma_y=sigma)\n\n# then down-scale\ncle_denoised_scaled = cle.scale(blurred, factor_x=scale_factor, factor_y=scale_factor, auto_size=True)\n\ncle.imshow(cle_denoised_scaled)"}
{"imports": "import numpy as np\nimport skimage.transform as sk_transform\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt", "text": "\n\n## Side-by side comparison\n\nLet's compare the denoising results side-by-side", "code": "# Define the labels for figure titles and bar chart\nlabels = [\n    'Numpy decimate',\n    'Scikit rescale without antialiasing',\n    'Scikit rescale with antialiasing',\n    'Scikit downscale_local_mean',\n    'CLE scale',\n    'CLE Gaussian blur + scale',\n]\n\nfig, axes = plt.subplots(2, 3, figsize=(10, 5))\n\naxes[0, 0].imshow(numpy_decimated, cmap='gray')\naxes[0, 0].set_title(labels[0])\n\naxes[0, 1].imshow(scikit_rescaled, cmap='gray')\naxes[0, 1].set_title(labels[1])\n\naxes[0, 2].imshow(cle_scaled, cmap='gray')\naxes[0, 2].set_title(labels[4])\n\naxes[1, 0].imshow(scikit_downsampled, cmap='gray')\naxes[1, 0].set_title(labels[3])\n\naxes[1, 1].imshow(scikit_rescaled_antialiasing, cmap='gray')\naxes[1, 1].set_title(labels[2])\n\naxes[1, 2].imshow(cle_denoised_scaled, cmap='gray')\naxes[1, 2].set_title(labels[5])\n\nfor ax in axes.flatten():\n    ax.axis('off')\n\nfig.tight_layout()\n"}
{"imports": "import pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread", "text": "\n\n## Scaling with the voxel size\nThe easiest way for fixing this problem is to scale the dataset with its voxel size. Per definition, this will result in a dataset where the voxels are isotropic and have `voxel_size = 1` (microns in our case) in all directions.", "code": "scale_factor_x = voxel_size_x\nscale_factor_y = voxel_size_y\nscale_factor_z = voxel_size_z\n\nresampled = cle.scale(input_image, \n                      factor_x=scale_factor_x, \n                      factor_y=scale_factor_y, \n                      factor_z=scale_factor_z, \n                      linear_interpolation=True,\n                      auto_size=True)\n\nshow(resampled)"}
{"imports": "import pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread", "text": "\n\nA potential solution is to introduce a `zoom_factor`. It allows tuning how large the resampled image will be:", "code": "zoom_factor = 2\n\nscale_factor_x = voxel_size_x * zoom_factor\nscale_factor_y = voxel_size_y * zoom_factor\nscale_factor_z = voxel_size_z * zoom_factor\n\nresampled_zoomed = cle.scale(input_image, \n                      factor_x=scale_factor_x, \n                      factor_y=scale_factor_y, \n                      factor_z=scale_factor_z, \n                      linear_interpolation=True,\n                      auto_size=True)\n\nshow(resampled_zoomed)\n\nresampled_zoomed.shape"}
{"imports": "import pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread", "text": "\n\nWhen zooming/scaling 3D images, keep memory limitations in mind. You can read the size of the images in the box on the right in the following view. Zooming an image by factor 2, like in the example above, increases the image size of a 3D stack by factor 8 (2x2x2).", "code": "resampled\n\nresampled_zoomed"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport stackview\n\nimage = imread(\"../../data/blobs.tif\")[:50,:50]\n\nlabel_image = cle.voronoi_otsu_labeling(image, spot_sigma=4)\n\nlabel_image", "text": "\n\nFrom the objects in this label image, we can derive centroid coordinates.", "code": "centroids = cle.centroids_of_labels(label_image)\ncentroids"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport stackview\n\nimage = imread(\"../../data/blobs.tif\")[:50,:50]\n\nlabel_image = cle.voronoi_otsu_labeling(image, spot_sigma=4)\n\nlabel_image", "text": "\n\nSuch a point list has d times n numbers for d dimensions (commonly 2 or 3) and n points.", "code": "centroids.shape"}
{"imports": "from skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport apoc\n\nimage = imread('../../data/blobs.tif')\ncle.imshow(image)\n\nmanual_annotations = imread('../../data/blobs_annotations.tif')\n\ncle.imshow(manual_annotations, labels=True)", "text": "\n\n## Prediction / segmentation\nThe classifier can then be used to classify all pixels in the given image. Starting point is again, the feature stack. Thus, the user must make sure that the same features are used for training and for prediction. Prediction can be done on the CPU using the original scikit-learn code and on the GPU using the generated OpenCL-code. OCLRFC works well if both result images look identical.", "code": "segmentation_result = clf.predict(features=features, image=image)\ncle.imshow(segmentation_result, labels=True)"}
{"imports": "import apoc\nimport os\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\n## Training\nIf the folders are setup properly, we can pass the folders to the training.", "code": "# setup classifer and where it should be saved\nsegmenter = apoc.ObjectSegmenter(opencl_filename=\"test2.cl\")\n\n# setup feature set used for training\nfeatures = apoc.PredefinedFeatureSet.object_size_1_to_5_px.value\n\n# train classifier on folders\napoc.train_classifier_from_image_folders(\n    segmenter, \n    features, \n    image = image_folder, \n    ground_truth = masks_folder)"}
{"imports": "from skimage.io import imread, imshow\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt", "text": "\n\nWe start again with the blobs example image.", "code": "image = imread('../../data/blobs.tif')\nimshow(image)"}
{"imports": "from skimage.io import imread, imshow\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt", "text": "\n\n## Feature stacks\nA feature stack is a list of 2D or 3D images, typically derived from an original image. If you don't specify any feature specfication, a stack will be generated with the original image, a blurred version and an edge image:", "code": "feature_stack = apoc.generate_feature_stack(image)\n\nvisualize(feature_stack)"}
{"imports": "from skimage.io import imread, imshow\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt", "text": "\n\nYou can also vary radii / sigmas of the fetures:", "code": "feature_stack = apoc.generate_feature_stack(image, \"gaussian_blur=1 gaussian_blur=5 gaussian_blur=10 gaussian_blur=20\")\n\nvisualize(feature_stack)"}
{"imports": "from skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimage = imread('../../data/blobs.tif')\n\nmanual_annotation = imread('../../data/blobs_annotations.tif')\n\nfig, axs = plt.subplots(1,2)\n\ncle.imshow(image, plot=axs[0])\ncle.imshow(manual_annotation, labels=True, plot=axs[1])", "text": "\n\n## Training - with too many features\nWe now train a object segmenter and provide many features. We also need to provide parameters to configure deep decision trees and many trees. This is necessary so that the next steps, deriving statistics, has enough statistical power.\nAfterwards, we take a look at the result for a quick sanity check.", "code": "# define features\nfeatures = apoc.PredefinedFeatureSet.small_dog_log.value + \" \" + \\\n           apoc.PredefinedFeatureSet.medium_dog_log.value + \" \" + \\\n           apoc.PredefinedFeatureSet.large_dog_log.value\n\n# this is where the model will be saved\ncl_filename = '../../data/blobs_object_segmenter2.cl'\n\napoc.erase_classifier(cl_filename)\nclassifier = apoc.ObjectSegmenter(opencl_filename=cl_filename, \n                           positive_class_identifier=2, \n                           max_depth=5,\n                           num_ensembles=1000)\nclassifier.train(features, manual_annotation, image)\n\nsegmentation_result = classifier.predict(features=features, image=image)\ncle.imshow(segmentation_result, labels=True)"}
{"imports": "from skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimage = imread('../../data/blobs.tif')\n\nmanual_annotation = imread('../../data/blobs_annotations.tif')\n\nfig, axs = plt.subplots(1,2)\n\ncle.imshow(image, plot=axs[0])\ncle.imshow(manual_annotation, labels=True, plot=axs[1])", "text": "\n\nIn this visualization you can see that the features `gaussian_blur=1`, `difference_of_gaussian=5` and `laplace_box_of_gaussian_blur=5` make about 65% of the decision. On the first level (level `0`). If these three features are crucial, we can train another classifier that only takes these features into account. Furthermore, we see that the share the features are used on the higher three depth levels is more uniformly distributed. These levels may not make a big difference when classifying pixels. The next classifier we train, we can train with lower `max_depth`.", "code": "# define features\nfeatures = \"gaussian_blur=1 difference_of_gaussian=5 laplace_box_of_gaussian_blur=5\"\n\n# this is where the model will be saved\ncl_filename = '../../data/blobs_object_segmenter3.cl'\n\napoc.erase_classifier(cl_filename)\nclassifier = apoc.ObjectSegmenter(opencl_filename=cl_filename, \n                           positive_class_identifier=2, \n                           max_depth=3,\n                           num_ensembles=1000)\nclassifier.train(features, manual_annotation, image)\n\nsegmentation_result = classifier.predict(features=features, image=image)\ncle.imshow(segmentation_result, labels=True)"}
{"imports": "from skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimage = imread('../../data/blobs.tif')\n\nmanual_annotation = imread('../../data/blobs_annotations.tif')\n\nfig, axs = plt.subplots(1,2)\n\ncle.imshow(image, plot=axs[0])\ncle.imshow(manual_annotation, labels=True, plot=axs[1])", "text": "\n\nThe new classifier still produces a very similar result. It takes less features into account, which makes it faster, but potentially also less robust again differences between images and imaging conditions. We just take another look at the classifier statistics:", "code": "shares, counts = classifier.statistics()\ndf = pd.DataFrame(shares).T\ndf.style.pipe(colorize)"}
{"imports": "from skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimage = imread('../../data/blobs.tif')\n\nmanual_annotation = imread('../../data/blobs_annotations.tif')\n\nfig, axs = plt.subplots(1,2)\n\ncle.imshow(image, plot=axs[0])\ncle.imshow(manual_annotation, labels=True, plot=axs[1])", "text": "\n\nFor demonstration purposes, we will now train another classifier with very similar features.", "code": "# define features\nfeatures = \"gaussian_blur=1 difference_of_gaussian=2 difference_of_gaussian=3 difference_of_gaussian=4 difference_of_gaussian=5 difference_of_gaussian=6 laplace_box_of_gaussian_blur=5\"\n\n# this is where the model will be saved\ncl_filename = '../../data/blobs_object_segmenter3.cl'\n\napoc.erase_classifier(cl_filename)\nclassifier = apoc.ObjectSegmenter(opencl_filename=cl_filename, \n                           positive_class_identifier=2, \n                           max_depth=3,\n                           num_ensembles=1000)\nclassifier.train(features, manual_annotation, image)\n\nsegmentation_result = classifier.predict(features=features, image=image)\ncle.imshow(segmentation_result, labels=True)"}
{"imports": "from skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimage = imread('../../data/blobs.tif')\n\nmanual_annotation = imread('../../data/blobs_annotations.tif')\n\nfig, axs = plt.subplots(1,2)\n\ncle.imshow(image, plot=axs[0])\ncle.imshow(manual_annotation, labels=True, plot=axs[1])", "text": "\n\nAgain, the segmentation result looks very similar, but the classifier statistic is different.", "code": "shares, counts = classifier.statistics()\ndf = pd.DataFrame(shares).T\ndf.style.pipe(colorize)"}
{"imports": "import stackview\nfrom cellpose import models, io\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\n## Loading a pretrained model\nCellPose comes with a number of pretrained models, e.g. for segmenting images showing cells or nuclei. We will just load a model for segmenting nuclei.", "code": "model = models.Cellpose(gpu=False, model_type='nuclei')"}
{"imports": "import stackview\nfrom cellpose import models, io\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\nWe let the model \"evaluate\" the image to produce masks of segmented nuclei.", "code": "channels = [0,0] # This means we are processing single-channel greyscale images.\n\nmasks, flows, styles, diams = model.eval(image, diameter=None, channels=channels)\n\nstackview.insight(masks.astype(np.uint32))"}
{"imports": "from stardist.models import StarDist2D\nfrom csbdeep.utils import normalize\nfrom stardist import random_label_cmap\n\nimport stackview\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\n## Normalizing the input image\nMany algorithms using neural networks need normalized input data to work on. For example, you can determine the 1% and the 99.8% percentile (that's very commond) and normalize your image so that the intensities spread between these percentiles are afterwards in the range between 0 and 1. We need to do this because the model was trained on an image in this range and might not be able to segment images with different intensity ranges.", "code": "axis_norm = (0,1)\nimage = normalize(image, 1,99.8, axis=axis_norm)"}
{"imports": "from stardist.models import StarDist2D\nfrom csbdeep.utils import normalize\nfrom stardist import random_label_cmap\n\nimport stackview\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\nSegmenting the image and labeling the individual objects is often called \"instance segmentation\" or \"prediction\" in the artificial intelligence community.", "code": "labels, details = model.predict_instances(image)\n\nstackview.insight(labels)"}
{"imports": "from stardist.models import StarDist2D\nfrom csbdeep.utils import normalize\nfrom stardist import random_label_cmap\n\nimport stackview\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\n## Result visualization\nCell / nuclei segmentation results can be checked best if the resulting label image is overlaid to the original image", "code": "plt.figure(figsize=(5,5))\nplt.imshow(image, clim=(0,1), cmap='gray')\nplt.imshow(labels, cmap=random_label_cmap(), alpha=0.5)\nplt.axis('off');"}
{"imports": "from stardist.models import StarDist2D\nfrom csbdeep.utils import normalize\nfrom stardist import random_label_cmap\n\nimport stackview\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\n... or by drawing outlines around segmented regions.", "code": "# create a new plot\nfig, axes = plt.subplots(1,1)\n\n# add two images\naxes.imshow(image, cmap=plt.cm.gray)\naxes.contour(labels, [0.5], linewidths=1.2, colors='r')"}
{"imports": "from stardist.models import StarDist2D\nfrom csbdeep.utils import normalize\nfrom stardist import random_label_cmap\n\nimport stackview\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom skimage.data import human_mitosis\n\nimage = human_mitosis()\nstackview.insight(image)", "text": "\n\nNote: The model we applied here to blobs.gif was not trained on it. The result doesn't look so bad though.\n\n## More available pretrained models\n\nStarDist offers more available pretrained models.", "code": "StarDist2D.from_pretrained() "}
{"imports": "import pyclesperanto_prototype as cle\n\n# import a function from a file in the same folder\nfrom simulated_cell_clumb import simulate_data\n\ncells = simulate_data()\ncells", "text": "\n\n## Determining which cells touch the background\nTo determine which cells touch the background, we need to produce a touch matrix which tells us which objects touch which others.", "code": "touch_matrix = cle.generate_touch_matrix(cells)\ntouch_matrix"}
{"imports": "import pyclesperanto_prototype as cle\n\n# import a function from a file in the same folder\nfrom simulated_cell_clumb import simulate_data\n\ncells = simulate_data()\ncells", "text": "\n\nThe first row and column in this image represent objects touching the background. We can read out this first row or column like this:", "code": "touching_background = touch_matrix[0]\ntouching_background"}
{"imports": "import pyclesperanto_prototype as cle\n\n# import a function from a file in the same folder\nfrom simulated_cell_clumb import simulate_data\n\ncells = simulate_data()\ncells", "text": "\n\nAnd we can visualized it in the original image coordinates.", "code": "cle.replace_intensities(cells, touching_background)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nFirst, we build our synthetic dataset. It is made of 6 cell-centers we dilated to form an organoid.", "code": "points = np.asarray([\n    [50, 50],\n    [60, 60],\n    [25, 40],\n    [70, 30],\n    [35, 65],\n    [50, 25]\n]).T\nimage = np.zeros((100, 100))\nspots = cle.pointlist_to_labelled_spots(points, image)\ncells = cle.dilate_labels(spots, radius=15)\nspots.shape"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nThese are our cells:", "code": "cells"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nAnd that's the organoid:", "code": "organoid = cells > 0\norganoid"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nWe now identify the pixels that sit on the borders of the cells.", "code": "cell_borders = cle.reduce_labels_to_label_edges(cells)\ncell_borders"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nWe can do exactly the same with the organoid to identify the pixels on its surface.", "code": "organoid_border = cle.reduce_labels_to_label_edges(organoid)\norganoid_border"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nBy masking the cell borders with the organoid border - technically that's a pixel-by-pixel multiplication - we can identify the outer borders.", "code": "outer_borders = cle.mask(cell_borders, organoid_border).astype(np.uint32)\nouter_borders"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nIf we subtract the outer borders from all cell borders, we retrieve the inner borders", "code": "inner_borders = (cell_borders - outer_borders).astype(np.uint32)\ninner_borders"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nimage = cle.asarray(imread(\"../../data/mitosis_mod.tif\")[0:40,25:65])\nimage", "text": "\n\nWe then segment the nuclei.", "code": "label_image = cle.voronoi_otsu_labeling(image, spot_sigma=2, outline_sigma=1)\nlabel_image"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nimage = cle.asarray(imread(\"../../data/mitosis_mod.tif\")[0:40,25:65])\nimage", "text": "\n\nFrom the nuclei label image we can extract another label image which contains all pixels that are on the edge of the labels.", "code": "edge_label_image = cle.reduce_labels_to_label_edges(label_image)\nedge_label_image"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nimage = cle.asarray(imread(\"../../data/mitosis_mod.tif\")[0:40,25:65])\nimage", "text": "\n\nIn case one wanted to measure in thicker areas along the borders, we could expand the borders.", "code": "thicker_edges = cle.dilate_labels(edge_label_image, radius=1)\nthicker_edges"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nOur starting point is an oversegmented (synthetic) label image.", "code": "oversegmented = cle.asarray(imread('../../data/syntetic_cells.tif')).astype(np.uint32)\noversegmented"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nFurthermore, we need an annotation where pixel-intensity = 1 implies that labels should be merged.", "code": "annotation = cle.asarray(imread('../../data/syntetic_cells_merge_annotation.tif')).astype(np.uint32)\n\n# binarize the image\nannotation = annotation == 1\n\nannotation"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nFor visualization purposes, we overlay both.", "code": "cle.imshow(oversegmented, labels=True, continue_drawing=True)\ncle.imshow(annotation, alpha=0.5)"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nWe can now merge all cells whose borders are annotated.", "code": "result = cle.merge_annotated_touching_labels(oversegmented, annotation)\nresult"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nA common example can be derived from an image showing intensities in cell membranes.", "code": "image = imread('../../data/membrane2d.tif')\ncle.asarray(image)"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nAs the membranes have different intensity depending on the region in the image, we need to correct for this first.", "code": "background_subtracted = cle.divide_by_gaussian_background(image, sigma_x=10, sigma_y=10)\nbackground_subtracted"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nFor technical reasons it is also recommeded to turn the intensity image into an image of type integer. Therefore, normalization might be necessary. It is important that images used for training and images used for prediction have intensities in the same range.", "code": "oversegmented = imread(\"../../data/membrane2d_oversegmented.tif\")\ncle.asarray(oversegmented).astype(np.uint32)"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nAn annotation serves telling the algorithm which segmented objects should be merged and which not.", "code": "annotation = imread(\"../../data/membrane2d_merge_annotation.tif\")\ncle.asarray(annotation).astype(np.uint32)"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nFor visualization purposes, we can overlay the annotation with the membrane image.", "code": "cle.imshow(background_subtracted, max_display_intensity=4, continue_drawing=True)\ncle.imshow(annotation, alpha=0.6, labels=True)"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nimport numpy as np", "text": "\n\nTo show more closely what needs to be annotated, we also overlay the label-edge image and the annotation. Note that the edges which are not supposed to be merged are small dots always carefully only annotating two objects (that should not be merged. ", "code": "cle.imshow(cle.detect_label_edges(oversegmented), continue_drawing=True)\ncle.imshow(annotation, alpha=0.6, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nFor demonstration purposes, we use a modified version of the labels derived from the blobs example-image. We artificially introduce gaps between them.", "code": "image = imread(\"../../data/blobs.tif\")\nimage[:, 80:150] = 0\nimage[80:130, 100:] = 0\n\nimage = cle.asarray(image)\nlabels = cle.voronoi_otsu_labeling(image, spot_sigma=4, outline_sigma=3)\nlabels"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nFrom this image, we extract the coordinates of centroids. From these centroids, we can build a distance matrix. In this matrix, the distance from all centroids to all other centroids is computed. The diagonale is zero as it corresponds to the distance of one centroid to itself. Furthermore, the distance to background (first row and first colum) is also zero, as background is not considered for distance computation.", "code": "centroids = cle.centroids_of_labels(labels)\n\ndistance_matrix = cle.generate_distance_matrix(centroids, centroids)\ndistance_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nWe can threshold this distance matrix with a given maximum distance. The result is a binary matrix.", "code": "maximum_distance = 40\n\nmerge_matrix = distance_matrix <= maximum_distance\nmerge_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nIf we werged labels with the background, all labels would be merged because all touch the background. In order to prevent this, we set the first row and column to zero.", "code": "cle.set_column(merge_matrix, 0, 0)\ncle.set_row(merge_matrix, 0, 0)\n\nmerge_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport numpy as np", "text": "\n\nFor demonstration purposes, we use a modified version of the labels derived from the blobs example-image. We artificially introduce gaps between them.", "code": "image = imread(\"../../data/blobs.tif\")\nimage[:, 80:150] = 0\nimage[80:130, 100:] = 0\n\nimage = cle.asarray(image)\nlabels = cle.voronoi_otsu_labeling(image, spot_sigma=4, outline_sigma=3)\nlabels"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport numpy as np", "text": "\n\nFirst, we dilate the labels by half of the maximum distance the edges are allowed to have.", "code": "maximum_distance = 12\n\ndilated_labels = cle.dilate_labels(labels, radius=maximum_distance/2)\ndilated_labels"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport numpy as np", "text": "\n\nWe then merge the labels if the touch.", "code": "merged_dilated_labels = cle.merge_touching_labels(dilated_labels)\nmerged_dilated_labels"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport stackview", "text": "\n\nFor demonstrating the filter, we create a semantic segmentation of blobs.", "code": "blobs = cle.imread(\"../../data/blobs.tif\")\n\nsemantic_segmentation = (blobs > 70) + \\\n                        (blobs > 200) + 1\n\nsemantic_segmentation.astype(np.uint32)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport stackview", "text": "\n\nUsing the functions `mode_sphere` and `mode_box` we can make the result less noisy.", "code": "cle.mode_sphere(semantic_segmentation, radius_x=2, radius_y=2).astype(np.uint32)\n\ncle.mode_sphere(semantic_segmentation, radius_x=4, radius_y=4).astype(np.uint32)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport stackview", "text": "\n\nWhen the radius becomes wider and wider, the result contains less and less local information.", "code": "cle.mode_sphere(semantic_segmentation, radius_x=10, radius_y=10).astype(np.uint32)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom skimage import filters", "text": "\n\n## Binary morphology\n\nFor demonstrating morphological filtering of binary images, we use the small nuclei image again.", "code": "image_nuclei = imread('../../data/mitosis_mod.tif').astype(float)\nimage_binary = image_nuclei > filters.threshold_otsu(image_nuclei)\n\nplt.imshow(image_binary, cmap='gray')"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom skimage import filters", "text": "\n\n## Erosion and Dilation\nTo make white islands in the black ocean smaller, we need to _erode_ its coastlines.", "code": "eroded = morphology.binary_erosion(image_binary, disk)\n\nplt.imshow(eroded, cmap='gray')"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom skimage import filters", "text": "\n\nIf we dilate the image afterwards, we get white islands back that look smoother than in the original binary image.", "code": "eroded_dilated = morphology.binary_dilation(eroded, disk)\n\nplt.imshow(eroded_dilated, cmap='gray')"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom skimage import filters", "text": "\n\nCalling erosion and dilation subsequently is so common that there is an extra function which does exactly that. As the gab between islands _open_ the operation is called _opening_.", "code": "opened = morphology.binary_opening(image_binary, disk)\n\nplt.imshow(opened, cmap='gray')"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import morphology\nfrom skimage import filters", "text": "\n\n## Exercise 1\nThere is also a _closing_ operation. Apply it to the binary image.", "code": ""}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nlabel_image = cle.gauss_otsu_labeling(imread(\"../../data/mitosis_mod.tif\"), outline_sigma=0)\nlabel_image", "text": "\n\n## Eroding labels\nWhen eroding labels, we need to be careful that objects might split into two. This could be intentional, e.g. to differentiate touching nuclei like in the example above.", "code": "eroded_label_image = cle.erode_labels(label_image,\n                                      radius=2,\n                                      relabel_islands=False)\neroded_label_image\n\neroded_label_image2 = cle.erode_labels(label_image,\n                                      radius=2,\n                                      relabel_islands=True)\neroded_label_image2"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nlabel_image = cle.gauss_otsu_labeling(imread(\"../../data/mitosis_mod.tif\"), outline_sigma=0)\nlabel_image", "text": "\n\n## Dilating labels\nWe can then dilate the labels again to come back to their original size approximately. This might also be useful in case segmented objects are too small in general.", "code": "dilated_label_image = cle.dilate_labels(eroded_label_image2, \n                                        radius=2)\ndilated_label_image"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread\n\nlabel_image = cle.gauss_otsu_labeling(imread(\"../../data/mitosis_mod.tif\"), outline_sigma=0)\nlabel_image", "text": "\n\n## Opening and closing labels\nOpening and closing for label images is similar like for binary images. The only difference is that when labels touch, they cannot expand anymore.\n\nNote that opening labels may make small labels disappear.", "code": "opened_label_image = cle.opening_labels(label_image,\n                                        radius=2)\nopened_label_image\n\nclosed_label_image = cle.closing_labels(label_image,\n                                        radius=2)\nclosed_label_image"}
{"imports": "import apoc\n\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport numpy as np\n\ncle.select_device('RTX')\n\nimage = imread('../../data/blobs.tif')\nlabels = cle.label(cle.threshold_otsu(image))\nannotation = imread('../../data/label_annotation.tif')\n\ncle.imshow(image)\ncle.imshow(labels, labels=True)\ncle.imshow(annotation, labels=True)", "text": "\n\n## Training\nFor training the classifier, you need to specify features. In the following we use mean and standard deviation intensity within the labeled objects and the object size and shape.", "code": "features = 'area,mean_max_distance_to_centroid_ratio,standard_deviation_intensity'\n\ncl_filename = \"object_selector.cl\"\n\n# Create an object classifier\napoc.erase_classifier(cl_filename) # delete it if it was existing before\nclassifier = apoc.ObjectSelector(cl_filename, positive_class_identifier=1)\n\n# train it\nclassifier.train(features, labels, annotation, image)"}
{"imports": "import apoc\n\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport numpy as np\n\ncle.select_device('RTX')\n\nimage = imread('../../data/blobs.tif')\nlabels = cle.label(cle.threshold_otsu(image))\nannotation = imread('../../data/label_annotation.tif')\n\ncle.imshow(image)\ncle.imshow(labels, labels=True)\ncle.imshow(annotation, labels=True)", "text": "\n\nAfter training, we can ask the classifier how important features were while doing the prediction.", "code": "classifier.feature_importances()"}
{"imports": "import pyclesperanto_prototype as cle\n\nfrom skimage.io import imread\nimport matplotlib\nimport numpy as np\nimport stackview\n\n# initialize GPU\ncle.select_device(\"GTX\")", "text": "\n\nWe start from a labeled version of the blobs image.", "code": "# load data\nlabel_image = imread('../../data/blobs_labeled.tif')\n\nstackview.insight(label_image)"}
{"imports": "import pyclesperanto_prototype as cle\n\nfrom skimage.io import imread\nimport matplotlib\nimport numpy as np\nimport stackview\n\n# initialize GPU\ncle.select_device(\"GTX\")", "text": "\n\nLet's assume we're not interested in the very small objects as they might be result of a false segmentation of some noise. We do know that the objects we imaged have a certain minimum size. From this physical guess, we need to estimate a number of pixels (in 2D) or voxels (in 3D) object are large. We can then use this number as `size_threshold` in pixels or voxels.", "code": "size_threshold = 200 # pixels\n\nlarge_labels_only = cle.exclude_small_labels(label_image, maximum_size=size_threshold)\n\nlarge_labels_only"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\nOur starting point is a label image with labels 1-8, where some labels are not present:", "code": "label_image = imread(\"../../data/label_map_with_index_gaps.tif\")\ncle.imshow(label_image, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\nWhen measuring the maximum intensity in the image, we can see that this label image containing 4 labels is obviously not sequentially labeled.", "code": "np.max(label_image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\nWe can use the `unique` function to figure out which labels are present:", "code": "np.unique(label_image)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\nAfterwards, the unique labels should be sequential:", "code": "np.unique(relabeled)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\nAlso pyclesperanto has a function for relabeling label images sequentially. The result is supposed identical to the result in scikit-image. It just doesn't return the additional values.", "code": "relabeled1 = cle.relabel_sequential(label_image)\n\ncle.imshow(relabeled1, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\n## Reverting sequential labeling\nIn some cases we apply an operation to a label image that returns a new label image with less labels that are sequentially labeled but the label-identity is lost. This happens for example when excluding labels from the label image that are too small.", "code": "large_labels = cle.exclude_small_labels(relabeled, maximum_size=260)\n\ncle.imshow(large_labels, labels=True, max_display_intensity=4)\n\nnp.unique(large_labels)"}
{"imports": "import numpy as np\nfrom skimage.io import imread\nfrom skimage.segmentation import relabel_sequential\nimport pyclesperanto_prototype as cle", "text": "\n\nTo restore the original label identities, we need to multiply a binary image representing the remaining labels with the original label image.", "code": "binary_remaining_labels = large_labels > 0\n\ncle.imshow(binary_remaining_labels)\n\nlarge_labels_with_original_identity = binary_remaining_labels * relabeled\n\ncle.imshow(large_labels_with_original_identity, labels=True, max_display_intensity=4)\n\nnp.unique(large_labels_with_original_identity)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nA potential use-case is fine-tuning cell segmentation results. Thus, we take a look at a segmentation of cells based on membranes.", "code": "membranes = cle.imread(\"../../data/membranes.tif\")\nmembranes\n\n\nlabels = cle.imread(\"../../data/membranes_labeled.tif\").astype(np.uint32)\nlabels"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nThe `smooth_labels` function allows to straighten the outlines of the labels.", "code": "cle.smooth_labels(labels, radius=5)"}
{"imports": "import numpy as np\nfrom pyclesperanto_prototype import imshow\nimport matplotlib.pyplot as plt\n\nimage = np.asarray([\n    [1, 0, 2, 1, 0, 0, 0],\n    [0, 3, 1, 0, 1, 0, 1],\n    [0, 5, 5, 1, 0, 1, 0],\n    [0, 6, 6, 5, 1, 0, 2],\n    [0, 0, 5, 6, 3, 0, 1],\n    [0, 1, 2, 1, 0, 0, 1],\n    [1, 0, 1, 0, 0, 1, 0]\n])\n\nimshow(image, colorbar=True)", "text": "\n\n## Binary images\nThe most basic way of that is binarization, turning the image into a \"positive\" and a \"negative\" region. Typically, binary images are used for that, which could for example contain two different pixel values `True` and `False` representing \"positive\" and \"negative\", respectively. Technically, every image can be interpreted as a binary image using the rationale \"Every pixel is considered positive that is neither `False` nor `0`.\"\n\n## Image thresholding\nA very basic algorithm for separating low intensity regions from high intensity regions in the image is thresholding.\nWe will now make a new image containing `True` and `False` as pixel values depending on if the original image had intensity lower or higher a given threshold. As this image has just two different pixel values, it is a binary image:", "code": "threshold = 4\n\nbinary_image = image > threshold\n\nbinary_image\n\nimshow(binary_image)"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk, binary_erosion, binary_dilation, binary_opening, binary_closing\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes\nimport pyclesperanto_prototype as cle\n\n# load image\nimage = imread(\"../../data/embryos_grey.tif\")\n\n# binarize the image\nthreshold = filters.threshold_otsu(image)\nbinary_image = image <= threshold\n\n# Show original image and binary image side-by-side\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(image, plot=axs[0])\naxs[0].set_title('Original')\n\ncle.imshow(binary_image, plot=axs[1])\naxs[1].set_title('Binary')", "text": "\n\n## Binary dilation\nAnalogously, dilation turns black pixels white which have a white neighbor.", "code": "dilated1 = binary_dilation(binary_image, disk(1))\ndilated4 = binary_dilation(binary_image, disk(4))\n\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\ncle.imshow(binary_image, plot=axs[0])\naxs[0].set_title('Binary image')\n\ncle.imshow(dilated1, plot=axs[1])\naxs[1].set_title('Dilated r=1')\n\ncle.imshow(dilated4, plot=axs[2])\naxs[2].set_title('Dilated r=4')"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk, binary_erosion, binary_dilation, binary_opening, binary_closing\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes\nimport pyclesperanto_prototype as cle\n\n# load image\nimage = imread(\"../../data/embryos_grey.tif\")\n\n# binarize the image\nthreshold = filters.threshold_otsu(image)\nbinary_image = image <= threshold\n\n# Show original image and binary image side-by-side\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(image, plot=axs[0])\naxs[0].set_title('Original')\n\ncle.imshow(binary_image, plot=axs[1])\naxs[1].set_title('Binary')", "text": "\n\n## Binary closing and opening\nBy combining operations such as erosion and dilation subsequently, one can close and open binary images.", "code": "opened = binary_opening(binary_image, disk(4))\nclosed = binary_closing(binary_image, disk(4))\n\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\ncle.imshow(binary_image, plot=axs[0])\naxs[0].set_title('Binary image')\n\ncle.imshow(opened, plot=axs[1])\naxs[1].set_title('Opened')\n\ncle.imshow(closed, plot=axs[2])\naxs[2].set_title('Closed')"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk, binary_erosion, binary_dilation, binary_opening, binary_closing\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes\nimport pyclesperanto_prototype as cle\n\n# load image\nimage = imread(\"../../data/embryos_grey.tif\")\n\n# binarize the image\nthreshold = filters.threshold_otsu(image)\nbinary_image = image <= threshold\n\n# Show original image and binary image side-by-side\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(image, plot=axs[0])\naxs[0].set_title('Original')\n\ncle.imshow(binary_image, plot=axs[1])\naxs[1].set_title('Binary')", "text": "\n\n## Comparing binary images\nFor better visualization of differenced between binary images, we would like to subtract one of the two binary images from the other. If we compute the absolute of this image, we should an image, where all pixels are have value `1` where the two binary images have different values. Unfortunately, we cannot subtract binary images with values `True` and `False` using the `-` operator. We first should turn the `True/False` binary images into numeric images. This is possible by multiplying the images with `1`:", "code": "absolute_difference = np.abs(opened * 1 - binary_image * 1)\n\ncle.imshow(absolute_difference)"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import disk, binary_erosion, binary_dilation, binary_opening, binary_closing\nimport numpy as np\nfrom scipy.ndimage import binary_fill_holes\nimport pyclesperanto_prototype as cle\n\n# load image\nimage = imread(\"../../data/embryos_grey.tif\")\n\n# binarize the image\nthreshold = filters.threshold_otsu(image)\nbinary_image = image <= threshold\n\n# Show original image and binary image side-by-side\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(image, plot=axs[0])\naxs[0].set_title('Original')\n\ncle.imshow(binary_image, plot=axs[1])\naxs[1].set_title('Binary')", "text": "\n\nThe same result can also be achieved using pyclesperanto's `absolute_difference` function:", "code": "absolute_difference2 = cle.absolute_difference(opened, binary_image)\n\ncle.imshow(absolute_difference2)"}
{"imports": "from skimage.measure import label\nlabeled_8_connected = label(binary_image, connectivity=2)\n\nimshow(labeled_8_connected, labels=True)", "text": "\n\nIn practice, for counting cells, the connectivity is not so important. This is why the connectivity parameter is often not provided.\n\n## Connected component labeling in clesperanto\nIn clesperanto, both connectivity options for connected component labeling is implemented in two different functions. When labeling objects using the 4-connected pixel neighborhood, we consider the \"diamond\" neighborhood of all pixels.", "code": "labeled_4_connected2 = cle.connected_components_labeling_diamond(binary_image)\n\nimshow(labeled_4_connected2, labels=True)"}
{"imports": "from skimage.measure import label\nlabeled_8_connected = label(binary_image, connectivity=2)\n\nimshow(labeled_8_connected, labels=True)", "text": "\n\nThe 8-connected neighborhood considers a \"box\" around all pixels.", "code": "labeled_8_connected2 = cle.connected_components_labeling_box(binary_image)\n\nimshow(labeled_8_connected2, labels=True)"}
{"imports": "from skimage.measure import label\nlabeled_8_connected = label(binary_image, connectivity=2)\n\nimshow(labeled_8_connected, labels=True)", "text": "\n\n## Labeling in practice\nTo demonstrate labeling in a practical use case, we label the blobs.tif image.", "code": "# Load data\nfrom skimage.io import imread\nblobs = imread(\"../../data/blobs.tif\")\n\n# Thresholding\nfrom skimage.filters import threshold_otsu\nthreshold = threshold_otsu(blobs)\nbinary_blobs = blobs > threshold\n\n# Connected component labeling\nfrom skimage.measure import label\nlabeled_blobs = label(binary_blobs)\n\n# Visualization\nimport matplotlib.pyplot as plt\nfig, axs = plt.subplots(1, 3, figsize=(15,15))\n\ncle.imshow(blobs, plot=axs[0])\ncle.imshow(binary_blobs, plot=axs[1])\ncle.imshow(labeled_blobs, plot=axs[2], labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nfrom skimage.filters import gaussian", "text": "\n\nWe use this example image of nuclei.", "code": "image_nuclei = imread('../../data/mitosis_mod.tif')\n\nimshow(image_nuclei)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nfrom skimage.filters import gaussian", "text": "\n\n## Image Thesholding\nThe most common binarization technique is thresholding. We _apply a threshold_ to determine which pixel lie above a certain pixel intensity and which are below.", "code": "image_binary = image_nuclei > 60\n\nimshow(image_binary)"}
{"imports": "import stackview\nstackview.picker(instance_segmentation)", "text": "\n\n## Semantic segmentation\nSemantic segmentation label images can have more than two labels and typically label regions where pixels have the same meanings, for example: nuclei, nuclear envelope and background.", "code": "semantic_segmentation = binary_image + nsbatwm.maximum_filter(binary_image).astype(np.uint32) + 1\nsemantic_segmentation"}
{"imports": "import stackview\nstackview.picker(instance_segmentation)", "text": "\n\n## Sparse annotations\nAnnotated label images are typically drawn by humans. When executing this notebook locally, you can draw some annotations. If you annotate a couple of nuclei precisely, you create a sparse nuclei annotation. Hold down the ALT key to erase an annotation.", "code": "sparse_label_annotation = np.zeros_like(cropped_image, dtype=np.uint32)\nstackview.annotate(cropped_image, sparse_label_annotation)\n\nstackview.insight(sparse_label_annotation)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nTo demonstrate a potential use-case, we take a close look at an image of cells expressing a membrane marker.", "code": "membranes = cells3d()[30, 0, 110:150, 110:150]\ncle.imshow(membranes)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nWe define coordinates of four points which will be connected to two lines. The connection will be done using a _touch_ matrix which allows connecting n points with n points.", "code": "coords = np.asarray([\n    [0, 17],  # line 1 start (x, y)\n    [10, 24], # line 1 end\n    [20, 21], # line 2\n    [35, 21]\n]).T\n\nconnection_matrix = cle.symmetric_maximum_matrix(np.asarray([\n    [0, 0, 0, 0, 0],\n    [0, 0, 1, 0, 0], # this connects the two points of line 1\n    [0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 1], # this connects the two points of line 2\n    [0, 0, 0, 0, 0]\n]))\nconnection_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nFirst we visualize these lines on top of the membrane image.", "code": "mesh = cle.create_like(membranes)\nmesh = cle.touch_matrix_to_mesh(coords, connection_matrix, mesh)\n\ncle.imshow(membranes, continue_drawing=True)\ncle.imshow(mesh, alpha=0.5, colormap='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\n## Measure the mean intensity along lines\nNext we use the matrix configured above to measure the mean average intensity along the lines. We also need to specify how many samples will be taken along the lines.", "code": "num_samples = 10\n\nmean_intensity_matrix = cle.generate_mean_intensity_between_points_matrix(\n                                membranes, coords, connection_matrix, num_samples=num_samples)\nmean_intensity_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nWe can visualize these measurements also again as lines. As we pass points and connections between points as matrix, this is technically a mesh.", "code": "mean_intensity_mesh = cle.create_like(membranes)\nmean_intensity_mesh = cle.touch_matrix_to_mesh(coords, mean_intensity_matrix, mean_intensity_mesh)\nmean_intensity_mesh"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nWe can also visualize this quantitative mesh on top of the original membrane image.", "code": "cle.imshow(membranes, continue_drawing=True)\ncle.imshow(mean_intensity_mesh, alpha=0.5, colormap='jet', colorbar=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## The example dataset\nIn this example we load an image showing a zebrafish eye, courtesy of Mauricio Rocha Martins, Norden lab, MPI CBG Dresden.", "code": "multichannel_image = imread(\"../../data/zfish_eye.tif\")\nmultichannel_image.shape\n\ncropped_image = multichannel_image[200:600, 500:900]\n\nnuclei_channel = cropped_image[:,:,0]\n\ncle.imshow(nuclei_channel)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Image segmentation\nFirst, we use cellpose to segment the cells", "code": "# load cellpose model\nmodel = models.Cellpose(gpu=False, model_type='nuclei')\n\n# apply model\nchannels = [0,0] # This means we are processing single channel greyscale images.\nlabel_image, flows, styles, diams = model.eval(nuclei_channel, diameter=None, channels=channels)\n\n# show result\ncle.imshow(label_image, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Labeling pixels on label borders\nNext, we will extract the outline of the segmented nuclei.", "code": "binary_borders = cle.detect_label_edges(label_image)\n\nlabeled_borders = binary_borders * label_image\n\ncle.imshow(label_image, labels=True)\ncle.imshow(binary_borders)\ncle.imshow(labeled_borders, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Dilating outlines\nWe extend the outlines a bit to have a more robust measurement.", "code": "extended_outlines = cle.dilate_labels(labeled_borders, radius=2)\n\ncle.imshow(extended_outlines, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Overlay visualization\nUsing this label image of nuclei outlines, we can measure the intensity in the nuclear envelope.", "code": "nuclear_envelope_channel = cropped_image[:,:,2]\n\ncle.imshow(nuclear_envelope_channel)\n\ncle.imshow(nuclear_envelope_channel, alpha=0.5, continue_drawing=True)\ncle.imshow(extended_outlines, alpha=0.5, labels=True)"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Label intensity statistics\nMeasuring the intensity in the image works using the right intensty and label images.", "code": "stats = cle.statistics_of_labelled_pixels(nuclear_envelope_channel, extended_outlines)\n\nstats[\"mean_intensity\"]"}
{"imports": "import numpy as np\nfrom skimage.io import imread, imshow\nimport pyclesperanto_prototype as cle\nfrom cellpose import models, io\nfrom skimage import measure\nimport matplotlib.pyplot as plt", "text": "\n\n## Parametric maps\nThese measurements can also be visualized using parametric maps", "code": "intensity_map = cle.mean_intensity_map(nuclear_envelope_channel, extended_outlines)\ncle.imshow(intensity_map, min_display_intensity=3000, colorbar=True, colormap=\"jet\")"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nfrom skimage import measure\nfrom pyclesperanto_prototype import imshow\nimport pandas as pd \nimport numpy as np\n\n# load image\nimage = imread(\"../../data/blobs.tif\")\n\n# denoising\nblurred_image = filters.gaussian(image, sigma=1)\n\n# binarization\nthreshold = filters.threshold_otsu(blurred_image)\nthresholded_image = blurred_image >= threshold\n\n# labeling\nlabel_image = measure.label(thresholded_image)\n\n# visualization\nimshow(label_image, labels=True)", "text": "\n\nThe results are stored as `RegionProps` objects, which are not very informative:", "code": "properties[0:5]"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nfrom skimage import measure\nfrom pyclesperanto_prototype import imshow\nimport pandas as pd \nimport numpy as np\n\n# load image\nimage = imread(\"../../data/blobs.tif\")\n\n# denoising\nblurred_image = filters.gaussian(image, sigma=1)\n\n# binarization\nthreshold = filters.threshold_otsu(blurred_image)\nthresholded_image = blurred_image >= threshold\n\n# labeling\nlabel_image = measure.label(thresholded_image)\n\n# visualization\nimshow(label_image, labels=True)", "text": "\n\nYou can also add custom columns by computing your own metric, for example the `aspect_ratio`:", "code": "df['aspect_ratio'] = [p.major_axis_length / p.minor_axis_length for p in properties]\ndf"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nfrom skimage import measure\nfrom pyclesperanto_prototype import imshow\nimport pandas as pd \nimport numpy as np\n\n# load image\nimage = imread(\"../../data/blobs.tif\")\n\n# denoising\nblurred_image = filters.gaussian(image, sigma=1)\n\n# binarization\nthreshold = filters.threshold_otsu(blurred_image)\nthresholded_image = blurred_image >= threshold\n\n# labeling\nlabel_image = measure.label(thresholded_image)\n\n# visualization\nimshow(label_image, labels=True)", "text": "\n\nThose dataframes can be saved to disk conveniently:", "code": "df.to_csv(\"blobs_analysis.csv\")"}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nfrom skimage import measure\nfrom pyclesperanto_prototype import imshow\nimport pandas as pd \nimport numpy as np\n\n# load image\nimage = imread(\"../../data/blobs.tif\")\n\n# denoising\nblurred_image = filters.gaussian(image, sigma=1)\n\n# binarization\nthreshold = filters.threshold_otsu(blurred_image)\nthresholded_image = blurred_image >= threshold\n\n# labeling\nlabel_image = measure.label(thresholded_image)\n\n# visualization\nimshow(label_image, labels=True)", "text": "\n\n## Exercises\nAnalyse the loaded blobs `image`. \n\n* How many objects are in it?", "code": ""}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nfrom skimage import measure\nfrom pyclesperanto_prototype import imshow\nimport pandas as pd \nimport numpy as np\n\n# load image\nimage = imread(\"../../data/blobs.tif\")\n\n# denoising\nblurred_image = filters.gaussian(image, sigma=1)\n\n# binarization\nthreshold = filters.threshold_otsu(blurred_image)\nthresholded_image = blurred_image >= threshold\n\n# labeling\nlabel_image = measure.label(thresholded_image)\n\n# visualization\nimshow(label_image, labels=True)", "text": "\n\n* How large is the largest object?", "code": ""}
{"imports": "from skimage.io import imread\nfrom skimage import filters\nfrom skimage import measure\nfrom pyclesperanto_prototype import imshow\nimport pandas as pd \nimport numpy as np\n\n# load image\nimage = imread(\"../../data/blobs.tif\")\n\n# denoising\nblurred_image = filters.gaussian(image, sigma=1)\n\n# binarization\nthreshold = filters.threshold_otsu(blurred_image)\nthresholded_image = blurred_image >= threshold\n\n# labeling\nlabel_image = measure.label(thresholded_image)\n\n# visualization\nimshow(label_image, labels=True)", "text": "\n\n* What are mean and standard deviation of the image?", "code": ""}
{"imports": "from skimage.measure import regionprops\nimport numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nWe generate a label image of cells with given sizes in x and y and a size ratio of 1:1.5.\n\nAssume this is the result of some cell segmentation algorithm.", "code": "cell_size_x = 10\ncell_size_y = 15\n\n# generate and show tissue\ntissue_labels = cle.artificial_tissue_2d(width=100, height=100, delta_x=cell_size_x, delta_y=cell_size_y, random_sigma_x=1, random_sigma_y=1)\ncle.imshow(tissue_labels, labels=True)"}
{"imports": "from skimage.measure import regionprops\nimport numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nWe now generate an image where the cells might be hard to segment from, e.g. a membrane image.", "code": "cell_borders = cle.detect_label_edges(label_image)\n\nconvolved_membranes = cle.gaussian_blur(cell_borders, sigma_x=1, sigma_y=2)\n\nnoise_level = 3\nnoise = (np.random.random(convolved_membranes.shape) - 0.5) * cle.mean_of_all_pixels(convolved_membranes) * noise_level\nnoise = noise.astype(np.float32)\n\nartifical_membrane_image = (convolved_membranes + noise)\n\ncle.imshow(artifical_membrane_image)"}
{"imports": "from skimage.measure import regionprops\nimport numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n## Shape descriptors based on neighbor meshes\nIn some cases, we can't segment the cells properly, we can just do spot detection and visulize the centers of the cells.", "code": "blurred = cle.gaussian_blur(artifical_membrane_image, sigma_x=2, sigma_y=2)\n\nlocal_minima = cle.detect_minima_box(blurred)\n\nspot_image = cle.label_spots(local_minima)\n\n# we extend the spots a little bit for visualization purposes\nspot_image = cle.maximum_sphere(spot_image, radius_x=1, radius_y=1)\n\ncle.imshow(spot_image, labels=True)"}
{"imports": "from skimage.measure import regionprops\nimport numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nFrom such an image of labelled spots, we can make a voronoi diagram, were we can analyse wich cells (expanded spots) are close by each other.\n\nThe result is an approximation of cell segmentation.", "code": "voronoi_diagram_all = cle.extend_labeling_via_voronoi(spot_image)\n\n# exclude labels on image edges\nvoronoi_diagram = cle.exclude_labels_on_edges(voronoi_diagram_all)\n\ncle.imshow(voronoi_diagram, labels=True)"}
{"imports": "from skimage.measure import regionprops\nimport numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nFrom such a pair of spots-image and voronoi diagram, we can dermine to matrices, a touch-matrix (also known as adjaceny-graph matrix) and a distance matrix.", "code": "touch_matrix = cle.generate_touch_matrix(voronoi_diagram)\n\n# igonore touching the background\ncle.set_column(touch_matrix, 0, 0)\n\n\ncentroids = cle.centroids_of_labels(voronoi_diagram)\n\ndistance_matrix = cle.generate_distance_matrix(centroids, centroids)\n\n\ncle.imshow(touch_matrix)\ncle.imshow(distance_matrix)"}
{"imports": "from skimage.io import imread\nimport stackview\n\nfrom nyxus import Nyxus\n\nintensity_image = imread(\"../../data/blobs.tif\")\n\nstackview.insight(intensity_image)\n\nlabel_image = imread(\"../../data/blobs_labeled.tif\")\n\n# visualization\nstackview.insight(label_image)", "text": "\n\nThus, one can also request only specific columns, which should also be faster.", "code": "nyx = Nyxus(['ORIENTATION', 'PERIMETER'])\nfeatures = nyx.featurize(intensity_image, label_image)\nfeatures"}
{"imports": "import pyclesperanto_prototype as cle\n\nimport pandas as pd\nfrom skimage.io import imread, imsave, imshow\nimport matplotlib\nimport numpy as np\n\n# initialize GPU\ncle.select_device(\"RTX\")\n\n# load data\nimage = imread('../../data/blobs.tif')\n\n# segment the image\nlabels = cle.voronoi_otsu_labeling(image, spot_sigma=3.5)\ncle.imshow(labels, labels=True)", "text": "\n\n## Deriving basic statistics of labelled objects", "code": "statistics = cle.statistics_of_labelled_pixels(image, labels)\nstatistics.keys()"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")", "text": "\n\nFor visualizing relationships between neighboring objects, we start at an artificial cell grid. Cells are aligned approximately in a honeycomb grid. Intensity in these cells is uniformly distributed. Just a single cell in the center of the grid has much higher intensity.", "code": "# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\n\n# fill it with random measurements\nvalues = random([int(cle.maximum_of_all_pixels(tissue))])\nfor i, y in enumerate(values):\n    if (i != 95):\n        values[i] = values[i] * 10 + 45\n    else:\n        values[i] = values[i] * 10 + 90\n\nmeasurements = cle.push(np.asarray([values]))\n\n# visualize measurments in space\nexample_image = cle.replace_intensities(tissue, measurements)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")", "text": "\n\n## Example data\nLet's take a look at an image with arbitrarily shaped pixels. Let's call them \"cells\". In our example image, there is one cell in the center with higher intensity:", "code": "cle.imshow(example_image, min_display_intensity=30, max_display_intensity=90, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")", "text": "\n\n## Touching neighbors\nWe can show all cells that belong to the \"touching\" neighborhood by visualizing the touching neighbor graph as mesh.", "code": "mesh = cle.draw_mesh_between_touching_labels(tissue)\n\n# make lines a bit thicker for visualization purposes\nmesh = cle.maximum_sphere(mesh, radius_x=1, radius_y=1)\n\ncle.imshow(mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")", "text": "\n\nIf we apply a local maximum filter to this grid, we can see how the high intensity of the single cell in the center spreads to directly touching neighbor cells.", "code": "local_maximum = cle.maximum_of_touching_neighbors_map(example_image, tissue)\n\ncle.imshow(local_maximum, min_display_intensity=30, max_display_intensity=90, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")", "text": "\n\n## Neighbors of touching neighbors\nYou can also extend the neighborhood by considering neighbors of neighbor (of neighbors (of neighbors)). How far you go, can be configured with a radius parameter. \n\n* Radius==0 means, no neighbors are taken into account, \n* radius==1 is identical with touching neighbors, \n* radius > 1 are neighbors of neighbors.", "code": "for radius in range(0, 5):\n    local_maximum = cle.maximum_of_touching_neighbors_map(example_image, tissue, radius=radius)\n    cle.imshow(local_maximum, min_display_intensity=30, max_display_intensity=90, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")", "text": "\n\n## Proximal neighbors\nWe can also compute the local maximum of cells with centroid distances below a given upper threshold.", "code": "local_maximum = cle.maximum_of_proximal_neighbors_map(example_image, tissue, max_distance=20)\ncle.imshow(local_maximum, min_display_intensity=30, max_display_intensity=90, color_map='jet')\n\nlocal_maximum = cle.maximum_of_proximal_neighbors_map(example_image, tissue, max_distance=50)\ncle.imshow(local_maximum, min_display_intensity=30, max_display_intensity=90, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\n# Test data\nLet's generate some tissue-like structure consisting of cells which typically have approximately 6 neighbors.", "code": "cells = cle.artificial_tissue_2d(\n    delta_x=48, \n    delta_y=32, \n    random_sigma_x=7, \n    random_sigma_y=7, \n    width=250, \n    height=250)\n\ncle.imshow(cells, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\n## Mesh between neighboring cells\n\nBefore counting neighbors, we should visualize neighbor-relationships. We can do this by drawing a mesh between centroids of touching neighbor cells.", "code": "mesh = cle.draw_mesh_between_touching_labels(cells)\n\ncle.imshow(mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\nWe can also combine both visualizations in one image. Note, these images should not be used any further for quantitative analysis. It just serves visualization purposes.\n\n## Centroid connections and cell borders\nA common way for visualizing tissues in this context is by drawing cell-borders and the centroid mesh in different colours.", "code": "visualization = mesh * 2 + cle.detect_label_edges(cells)\n\ncle.imshow(visualization, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\n## Analyze and visualize number of touching neighbors\nWe can also count the touching neighbors and visualize the result as parametric image in colours.", "code": "neighbor_count_image = cle.touching_neighbor_count_map(cells)\n\ncle.imshow(neighbor_count_image, color_map='jet', colorbar=True, min_display_intensity=0)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\nNote, the numbers along the image border may not be accurate. Hence, we should exclude the corresponding cells from the further analysis.", "code": "cells_ex_border = cle.exclude_labels_on_edges(cells)\n\ncle.imshow(cells_ex_border, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\nAfter correcting the label image, we can also correct the parametric image.", "code": "neighbor_count_image_ex_border = neighbor_count_image * (cells_ex_border != 0)\n\ncle.imshow(neighbor_count_image_ex_border, color_map='jet', colorbar=True, min_display_intensity=0)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\nNow, we can measure the number of neighbors. We can either just read those numbers and put them in a list ...", "code": "cle.read_intensities_from_map(cells_ex_border, neighbor_count_image_ex_border)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport pandas as pd", "text": "\n\n... we can also read these values together with all other statistics and put them in a pandas DataFrame.", "code": "statistics = cle.statistics_of_labelled_pixels(neighbor_count_image_ex_border, cells_ex_border)\n\ntable = pd.DataFrame(statistics)\n\n# rename a column\ntable = table.rename(columns={\"mean_intensity\": \"number_of_neighbors\"})\n\n# only filter out a subset of all columns; only what we care\ntable = table[[\"label\", \"number_of_neighbors\", \"centroid_x\", \"centroid_y\"]]\n\ntable"}
{"imports": "import pyclesperanto_prototype as cle\nfrom numpy import random\nfrom skimage.io import imread", "text": "\n\nA mesh can for example be drawn between proximal neighbors, nuclei which are closer than a given maximum distance.", "code": "max_distance = 320\n\nproximal_neighbor_mesh = cle.draw_mesh_between_proximal_labels(nuclei, maximum_distance=max_distance)\n\n# we make the lines a bit thicker for visualization purposes\nproximal_neighbor_mesh = cle.maximum_box(proximal_neighbor_mesh, radius_x=5, radius_y=5)\n\ncle.imshow(proximal_neighbor_mesh)\n\nproximal_distance_mesh = cle.draw_distance_mesh_between_proximal_labels(nuclei, maximum_distance=max_distance)\n\n# we make the lines a bit thicker for visualization purposes\nproximal_distance_mesh = cle.maximum_box(proximal_distance_mesh, radius_x=5, radius_y=5)\n\ncle.imshow(proximal_distance_mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom numpy import random\nfrom skimage.io import imread", "text": "\n\n## Distance meshes in more detail\nFor drawing a distance mesh, we need to combine a distance matrix, an abstract representation of distances of all objects to each other with a neighborhood-matrix, which represents which cells are neighbors.\n\nWe start with the distance matrix.", "code": "centroids = cle.centroids_of_background_and_labels(nuclei)\n\ndistance_matrix = cle.generate_distance_matrix(centroids, centroids)\n\n# we ignor distances to the background object\ncle.set_column(distance_matrix, 0, 0)\ncle.set_row(distance_matrix, 0, 0)\n\ncle.imshow(distance_matrix, colorbar=True)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom numpy import random\nfrom skimage.io import imread", "text": "\n\nNext, we should setup a matrix which represents for each nucleus (from the left to the right) which are its n nearest neighbors.", "code": "proximal_neighbor_matrix = cle.generate_proximal_neighbors_matrix(distance_matrix, max_distance=max_distance)\n\ncle.imshow(proximal_neighbor_matrix)\n\ndistance_touch_matrix = distance_matrix * proximal_neighbor_matrix\n\ncle.imshow(distance_touch_matrix, colorbar=True)\n\ndistance_mesh1 = cle.touch_matrix_to_mesh(centroids, distance_touch_matrix)\n\n# we make the lines a bit thicker for visualization purposes\ndistance_mesh1 = cle.maximum_box(distance_mesh1, radius_x=5, radius_y=5)\n\ncle.imshow(distance_mesh1, colorbar=True)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport pandas as pd\n\ncle.get_device()", "text": "\n\nOur starting point is a label image and another label image, where some of the labels in the first image are selected from. The first label image represents all cells. The second label image represents cells that express the marker.", "code": "label_image = cle.artificial_tissue_2d()\ncle.imshow(label_image, labels=True)\n\nrandom_vector = np.random.random((1, int(label_image.max() + 1)))\nsparse_labels = cle.exclude_labels_with_values_out_of_range(random_vector, label_image, minimum_value_range=0, maximum_value_range=0.3)\ncle.imshow(sparse_labels, labels=True)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport pandas as pd\n\ncle.get_device()", "text": "\n\nWe now count for every label in `label_image`, how many labels are proximal to it in the `sparse_labels` image. For measuring the distance, we use the centroid distance.", "code": "distance_map = cle.average_distance_to_n_nearest_other_labels_map(label_image, sparse_labels, n=1)\ncle.imshow(distance_map)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Associate artificial measurements to the cells", "code": "centroids = cle.label_centroids_to_pointlist(tissue)\n\ncoordinates = cle.pull_zyx(centroids)\nvalues = random([coordinates.shape[1]])\n\nfor i, y in enumerate(coordinates[1]):\n    if (y < 128):\n        values[i] = values[i] * 10 + 45\n    else:\n        values[i] = values[i] * 10 + 90\n\nmeasurements = cle.push_zyx(np.asarray([values]))\n\n# visualize measurments in space\nparametric_image = cle.replace_intensities(tissue, measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Local averaging smoothes edges\nBy averaging measurments locally, we can reduce the noise, but we also introduce a stripe where the region touch", "code": "local_mean_measurements = cle.mean_of_touching_neighbors(measurements, touch_matrix)\n\nparametric_image = cle.replace_intensities(tissue, local_mean_measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Edge preserving filters: median\nBy averaging using a median filter, we can also reduce noise while keeping the edge between the regions sharp", "code": "local_median_measurements = cle.median_of_touching_neighbors(measurements, touch_matrix)\n\nparametric_image = cle.replace_intensities(tissue, local_median_measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Increasing filter radius: neighbors of neighbors\nIn order to increase the radius of the operation, we need to determin neighbors of touching neighbors", "code": "neighbor_matrix = cle.neighbors_of_neighbors(touch_matrix)\n\nlocal_median_measurements = cle.median_of_touching_neighbors(measurements, neighbor_matrix)\n\nparametric_image = cle.replace_intensities(tissue, local_median_measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nThe image data we use here shows a crop of a developing Tribolium castaneum embryo imaged using light sheet microscopy by Daniela Vorkel, Myers lab, MPI-CBG / CSBD Dresden.", "code": "raw_image = imread(\"../../data/Lund_000500_resampled-cropped.tif\")\n\nraw_image.shape"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nWe can now segment nuclei in our our dataset.", "code": "background_subtracted = cle.top_hat_box(raw_image, radius_x=5, radius_y=5, radius_z=5)\n\nnuclei = cle.voronoi_otsu_labeling(background_subtracted)\n\northogonal_show(nuclei, labels=True)"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nAfter segmentation, we expand the labels a bit so they touch.", "code": "expanded_nuclei = cle.dilate_labels(nuclei, radius=4)\n\northogonal_show(expanded_nuclei, labels=True)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nOur starting point is a label image and another label image, where some of the labels in the first image are selected from.", "code": "label_image = cle.artificial_tissue_2d()\ncle.imshow(label_image, labels=True)\n\nrandom_vector = np.random.random((1, int(label_image.max() + 1)))\nsparse_labels = cle.exclude_labels_with_values_out_of_range(random_vector, label_image, minimum_value_range=0, maximum_value_range=0.3)\ncle.imshow(sparse_labels, labels=True)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\nWe use this example label image to show what the different measurements mean. In the following, most measures will be explained for the object number `7` in the center of the image.", "code": "labels = cle.scale(cle.asarray([\n   [1, 1, 2, 2, 3, 3, 3, 3],\n   [1, 1, 2, 2, 3, 3, 3, 3],\n   [1, 1, 7, 7, 7, 7, 3, 3],\n   [1, 1, 7, 7, 7, 7, 3, 3],\n   [6, 6, 7, 7, 7, 7, 4, 4],\n   [6, 6, 7, 7, 7, 7, 4, 4],\n   [5, 5, 5, 5, 5, 5, 4, 4],\n   [5, 5, 5, 5, 5, 5, 4, 4],\n]), factor_x=10, factor_y=10, auto_size=True).astype(np.uint32)\n\nlabels"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n# Distance meshes\nBefore diving into details we should first have a look at neighborhood relationships and distances between neighbors. A distance mesh visualizes the distances between centroids in colour.", "code": "distance_mesh = cle.draw_distance_mesh_between_touching_labels(labels)\ncle.imshow(distance_mesh, colorbar=True, colormap=\"rainbow\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\nSimple statistics such as the longest distance between direct neighbors can be measured from that image.", "code": "distance_mesh.max()"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\nFor more detailed statistics we use a table / pandas DataFrame.", "code": "stats = pd.DataFrame(cle.statistics_of_labelled_neighbors(labels))\nstats"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\nThis table contains these columns:", "code": "stats.describe().T"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n## Visualization of statistics\nWe can visualize those measurements in parametric map images.\n\nFor visualization of the table columns as maps, we typically need to prefix the measurements with a `0`. This `0` represents the measurement of the background.", "code": "stats[\"touching_neighbor_count\"].tolist()\n\nlist_of_measurements = cle.prefix_in_x([stats[\"touching_neighbor_count\"].tolist()])\nlist_of_measurements\n\ncle.replace_intensities(labels, list_of_measurements)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Number of touching neighbors and proximal neighbors", "code": "visualize(cell_estimation, tribolium_statistics, \"touching_neighbor_count\")\n\nvisualize(cell_estimation, tribolium_statistics, \"proximal_neighbor_count_d10\")\n\nvisualize(cell_estimation, tribolium_statistics, \"proximal_neighbor_count_d20\")\n\nvisualize(cell_estimation, tribolium_statistics, \"proximal_neighbor_count_d40\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Distances to touching neighbors", "code": "visualize(cell_estimation, tribolium_statistics, \"minimum_distance_of_touching_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"average_distance_of_touching_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_touching_neighbors\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Distance to nearest neighbors", "code": "visualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_n1_nearest_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_n6_nearest_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_n10_nearest_neighbors\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Distance to the most distant other label", "code": "visualize(cell_estimation, tribolium_statistics, \"distance_to_most_distant_other\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Touch count\nTouch count is the number of voxels labels touch others.", "code": "visualize(cell_estimation, tribolium_statistics, \"touch_count_sum\")\n\nvisualize(cell_estimation, tribolium_statistics, \"minimum_touch_count\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_touch_count\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt", "text": "\n\n## Demonstration with a simpler example\nOur example image shows a couple of objects. In the following, we will concentrate on the objects `4` and `5` in the center of the image.", "code": "labels = cle.scale(cle.asarray([\n   [1, 1, 1, 1, 2, 2, 2, 2],\n   [1, 1, 1, 1, 2, 2, 2, 2],\n   [1, 1, 4, 4, 5, 5, 2, 2],\n   [1, 1, 4, 4, 5, 5, 2, 2],\n   [1, 1, 4, 4, 3, 3, 2, 2],\n   [1, 1, 4, 4, 3, 3, 2, 2],\n   [3, 3, 3, 3, 3, 3, 3, 3],\n   [3, 3, 3, 3, 3, 3, 3, 3],\n]), factor_x=10, factor_y=10, auto_size=True).astype(np.uint32)\nlabels"}
{"imports": "import apoc\n\nfrom skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib.pyplot as plt", "text": "\n\nFor object classification, we need an intensity image and a label image as input.", "code": "# load intensity image\nimage = imread('../../data/blobs.tif')\n\n# segment the image\nlabels = cle.label(cle.threshold_otsu(image))\n\nfig, axs = plt.subplots(1, 2)\n\ncle.imshow(image, color_map=\"Greys_r\", plot=axs[0])\ncle.imshow(labels, labels=True, plot=axs[1])"}
{"imports": "import apoc\n\nfrom skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib.pyplot as plt", "text": "\n\n## Training\nWe also need a ground truth annotation image. This image is also a label image with a sparse annotation. A line with value `1` was drawn through all objects that are supposed to belong to class `1`. A line with value `2` was drawn through all objects that should be classified as class `2`. If the line crosses the background, this is ignored. In this example, objects were annotated in three classes:\n* Elongated objects\n* Roundish objects\n* Small objects", "code": "annotation = cle.push(imread('../../data/label_annotation.tif'))\n\nfig, axs = plt.subplots(1, 2)\n\ncle.imshow(labels, labels=True, plot=axs[0])\ncle.imshow(annotation, labels=True, plot=axs[1])"}
{"imports": "import apoc\n\nfrom skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib.pyplot as plt", "text": "\n\nNext, we need to define which features we want to use for classifying objects. We will use area, shape and the standard deviation of the intensity.", "code": "features = 'area mean_max_distance_to_centroid_ratio standard_deviation_intensity'\n\n# Create an object classifier\nfilename = \"../../data/blobs_object_classifier.cl\"\nclassifier = apoc.ObjectClassifier(filename)\n\n# train it; after training, it will be saved to the file specified above\nclassifier.train(features, labels, annotation, image)"}
{"imports": "import apoc\n\nfrom skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib.pyplot as plt", "text": "\n\nAfter the classifier has been trained, we can use it immediately to predict the classification of the objects in the image.", "code": "# determine object classification\nclassification_result = classifier.predict(labels, image)\n\ncle.imshow(classification_result, labels=True)"}
{"imports": "import apoc\n\nfrom skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib.pyplot as plt", "text": "\n\n## Prediction\nYou can also reload the classifier from disc and apply it to other images. We will simulate this by rotating the original image. This is by the way a good sanity check to see if the classification depends on the orientation of the image.", "code": "image2 = cle.rotate(image, angle_around_z_in_degrees=90)\nlabels2 = cle.rotate(labels, angle_around_z_in_degrees=90)\n\nclassifier2 = apoc.ObjectClassifier(\"../../data/blobs_object_classifier.cl\")\n\nclassification_result2 = classifier2.predict(labels2, image2)\n\ncle.imshow(classification_result2, labels=True)"}
{"imports": "from skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport pandas as pd\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ncle.select_device('RTX')", "text": "\n\nWe previously created an object classifier and apply it now to the pair of intensity and label images.", "code": "classifier = apoc.ObjectClassifier(\"../../data/maize_cslm_object_classifier.cl\")\nclassification_map = classifier.predict(labels=labels, image=image)\n\ncle.imshow(classification_map, labels=True, min_display_intensity=0)"}
{"imports": "from skimage.io import imread, imsave\nimport pyclesperanto_prototype as cle\nimport pandas as pd\nimport numpy as np\nimport apoc\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ncle.select_device('RTX')", "text": "\n\nFirst, we display the number of decisions on every level. Again, from lower to higher levels, the total number of decisions increases, in this table from the left to the right.", "code": "pd.DataFrame(counts).T"}
{"imports": "from sklearn.ensemble import RandomForestClassifier\n\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow, replace_intensities, relabel_sequential\nfrom skimage.filters import threshold_otsu\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import clear_border\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt", "text": "\n\nOur starting point are an image, a label image and some ground truth annotation. The annotation is also a label image where the user was just drawing lines with different intensity (class) through small objects, large objects and elongated objects.", "code": "# load and label data\nimage = imread('../../data/blobs.tif')\nlabels = label(image > threshold_otsu(image))\nannotation = imread('../../data/label_annotation.tif')\n\n# visualize\nfig, ax = plt.subplots(1,3, figsize=(15,15))\nimshow(image, plot=ax[0])\nimshow(labels, plot=ax[1], labels=True)\nimshow(image, plot=ax[2], continue_drawing=True)\nimshow(annotation, plot=ax[2], alpha=0.7, labels=True)"}
{"imports": "from sklearn.ensemble import RandomForestClassifier\n\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow, replace_intensities, relabel_sequential\nfrom skimage.filters import threshold_otsu\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import clear_border\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt", "text": "\n\n## Feature extraction\nThe first step to classify objects according to their properties is [feature extraction](feature_extraction).", "code": "stats = regionprops(labels, intensity_image=image)\n\n# read out specific measurements\nlabel_ids =          np.asarray([s.label for s in stats])\nareas =              np.asarray([s.area for s in stats])\nminor_axis_lengths = np.asarray([s.minor_axis_length for s in stats])\nmajor_axis_lengths = np.asarray([s.major_axis_length for s in stats])\n\n# compute additional parameters\naspect_ratios = major_axis_lengths / minor_axis_lengths"}
{"imports": "from sklearn.ensemble import RandomForestClassifier\n\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow, replace_intensities, relabel_sequential\nfrom skimage.filters import threshold_otsu\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import clear_border\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt", "text": "\n\nWe also read out the maximum intensity of every labeled object from the ground truth annotation. These values will serve to train the classifier.", "code": "annotation_stats = regionprops(labels, intensity_image=annotation)\n\nannotated_class = np.asarray([s.max_intensity for s in annotation_stats])"}
{"imports": "from sklearn.ensemble import RandomForestClassifier\n\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow, replace_intensities, relabel_sequential\nfrom skimage.filters import threshold_otsu\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import clear_border\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt", "text": "\n\nFrom that table, we extract now a table that only contains the annotated rows/labels.", "code": "annotated_table = table[table['annotated_class'] > 0]\nannotated_table"}
{"imports": "from sklearn.ensemble import RandomForestClassifier\n\nfrom skimage.io import imread\nfrom pyclesperanto_prototype import imshow, replace_intensities, relabel_sequential\nfrom skimage.filters import threshold_otsu\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import clear_border\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt", "text": "\n\nWe also extract the annotation from that table and call it `ground_truth`.", "code": "ground_truth = annotated_table['annotated_class'].tolist()\nground_truth"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\n## Object area maps in tiles\nDask brings built-in support for the zarr file format. We can create dask arrays directly from a zarr file.", "code": "zarr_image = da.from_zarr(zarr_filename)\nzarr_image"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\n## Testing tiled image processing\nWe should test our area mapping algorithm on a single tile. Actually, in a real scenario, the image processing workflow is developed on individual tiles, e.g. in a notebook like this one. As soon as we are sure that the algorithm works, we can apply it to all tiles.", "code": "test_image = image[100:200,100:200]\n\nimshow(test_image)\n\ntest_result = area_map(test_image)\n\nimshow(test_result, colorbar=True)"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\n## Applying the tiled image processing to a zarr-backed dataset\n\nApplying the function to our zarr dataset will also result in a dask array.", "code": "overlap_width = 30\n\ntile_map = da.map_overlap(area_map, zarr_image, depth=overlap_width, boundary=0)\n\ntile_map"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nWhen we invoke saving the results to disk, the processing will happen on individual tiles.", "code": "processed_zarr_filename = '../../data/P1_H_C3H_M004_17-processed.zarr'\n\ntile_map.to_zarr(processed_zarr_filename, overwrite=True)"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nfrom skimage.measure import label as skimage_label\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom dask_image.ndmeasure import label as daskimage_label\n\nimage = imread(\"../../data/blobs.tif\") > 128\nimshow(image)\n\ntiles = da.from_array(image, chunks=(128, 128))\ntiles", "text": "\n\nWe will use scikit-image function `label()` for processing our image.", "code": "procedure = skimage_label\n\ntile_map = da.map_blocks(procedure, tiles)\n\nresult = tile_map.compute()\nimshow(result, labels=True)"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nfrom skimage.measure import label as skimage_label\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom dask_image.ndmeasure import label as daskimage_label\n\nimage = imread(\"../../data/blobs.tif\") > 128\nimshow(image)\n\ntiles = da.from_array(image, chunks=(128, 128))\ntiles", "text": "\n\nIn this image, we can already see that the result has artifacts at the tile borders in the horizontal and vertical image center. To further check the result, we will compute the connected component labeling of the image without tiling.", "code": "reference = skimage_label(image)\n\nimshow(reference, labels=True)"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nfrom skimage.measure import label as skimage_label\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom dask_image.ndmeasure import label as daskimage_label\n\nimage = imread(\"../../data/blobs.tif\") > 128\nimshow(image)\n\ntiles = da.from_array(image, chunks=(128, 128))\ntiles", "text": "\n\nNext, we can compare the maximum intensity in the label image to see if the total number of labels in these two images are equal. They are not:", "code": "result.max(), reference.max()"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nfrom skimage.measure import label as skimage_label\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom dask_image.ndmeasure import label as daskimage_label\n\nimage = imread(\"../../data/blobs.tif\") > 128\nimshow(image)\n\ntiles = da.from_array(image, chunks=(128, 128))\ntiles", "text": "\n\nBy computing the standard deviation of the pixel intensity in the result image grouped by the reference labels, we can visualize which objects are not segmented correctly.", "code": "stddev_map = cle.standard_deviation_intensity_map(result, reference) > 0\n\nimshow(stddev_map)"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nfrom skimage.measure import label as skimage_label\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom dask_image.ndmeasure import label as daskimage_label\n\nimage = imread(\"../../data/blobs.tif\") > 128\nimshow(image)\n\ntiles = da.from_array(image, chunks=(128, 128))\ntiles", "text": "\n\n## Tiled connected component labeling using dask-image\nThe image processing library dask-image has a distributed version of connected component labeling available [dask_image.ndmeasure.label](http://image.dask.org/en/latest/dask_image.ndmeasure.html?highlight=label#dask_image.ndmeasure.label):", "code": "result_di, num_labels = daskimage_label(image)\n\nimshow(result_di, labels=True)"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\n## Loading the zarr-backed image\nDask brings built-in support for the zarr file format. We can create dask arrays directly from a zarr file.", "code": "zarr_image = da.from_zarr(zarr_filename)\nzarr_image"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nThis time, we do not use tile overlap, because we are not measuring properties of the nuclei and thus, don't need a prefect segmentation of them.", "code": "tile_map = da.map_blocks(count_nuclei, zarr_image)\n\ntile_map"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nAs the result image is much smaller then the original, we can compute the whole result map.", "code": "result = tile_map.compute()\n\nresult.shape"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nAgain, as the result map is small, we can just visualize it.", "code": "cle.imshow(result, colorbar=True)"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\n## Loading the zarr-backed image\nDask brings built-in support for the zarr file format. We can create dask arrays directly from a zarr file.", "code": "zarr_image = da.from_zarr(zarr_filename)\nzarr_image"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nFor processing tiles using dask, we setup processing blocks with no overlap.", "code": "tile_map = da.map_blocks(count_nuclei, zarr_image)\n\ntile_map"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nAs the result image is much smaller then the original, we can compute the whole result map.", "code": "result = tile_map.compute()\n\nresult.shape"}
{"imports": "import zarr\nimport dask.array as da\nimport numpy as np\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow\nfrom numcodecs import Blosc", "text": "\n\nAgain, as the result map is small, we can just visualize it.", "code": "cle.imshow(result, colorbar=True)"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow", "text": "\n\nOur starting point is again a binary image showing segmented objects.", "code": "image = imread(\"../../data/blobs.tif\") > 128\nimshow(image)"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow", "text": "\n\nIf we process the same in tiles, we will get slightly wrong results because of the tiled connected-component-labeling issue demonstated earlier.", "code": "# tile the image\ntiles = da.from_array(image, chunks=(128, 128))\n\n# setup the operation we want to apply\nprocedure = area_map\n\n# setup the tiling\ntile_map = da.map_blocks(procedure, tiles)\n\n# compute result\nresult = tile_map.compute()\n\n# visualize\nimshow(result, colorbar=True)"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow", "text": "\n\nAgain, the errors are visible at the border and we can visualize that by direct comparison:", "code": "absolute_error = cle.absolute_difference(result, reference)\n\ncle.imshow(absolute_error, colorbar=True)"}
{"imports": "import numpy as np\nimport dask\nimport dask.array as da\nfrom skimage.data import cells3d\nfrom skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom pyclesperanto_prototype import imshow", "text": "\n\nTo prevent this error, we need to think again about processing the image tiles with an overlap. In this particular example, we are not executing any operation that takes neighboring pixels into account. Hence, we cannot estimate the necessary overlap from such parameters. We need to take the maximum size (diameter) of the objects into account. We could also do this emprically, as before. Therefore, let's compute the mean squared error, first of the two example results above:", "code": "cle.mean_squared_error(result, reference)"}
{"imports": "import dask\nimport dask.array as da\nfrom skimage.filters import gaussian\nfrom skimage.data import cells3d\nfrom pyclesperanto_prototype import imshow", "text": "\n\nAfter loading the image, it can be tiled like that. In dask, tiles are also called _chunks_.", "code": "tiles = da.from_array(image, chunks=(128, 128))\ntiles"}
{"imports": "import dask\nimport dask.array as da\nfrom skimage.filters import gaussian\nfrom skimage.data import cells3d\nfrom pyclesperanto_prototype import imshow", "text": "\n\nNext, we tell dask what to do with our tiles. We want to _map_ the function `procedure` on all individual tiles. Note, this does not process the whole image yet.", "code": "tile_map = da.map_blocks(procedure, tiles)"}
{"imports": "import dask\nimport dask.array as da\nfrom skimage.filters import gaussian\nfrom skimage.data import cells3d\nfrom pyclesperanto_prototype import imshow", "text": "\n\nAs we can read, the function was executed twice with very small images (0x0 and 1x1 pixels). Dask does that in principle to explore if the function works. Next, we will actually execute our `procedure` on the tiles of the image.", "code": "result = tile_map.compute() # Warning: This loads all image data into memory"}
{"imports": "import dask\nimport dask.array as da\nfrom skimage.filters import gaussian\nfrom skimage.data import cells3d\nfrom pyclesperanto_prototype import imshow", "text": "\n\n**Note:** The `imshow` function may not work on big datasets. We are using it here for demonstration purposes.", "code": "imshow(result)"}
{"imports": "import dask\nimport dask.array as da\nfrom skimage.filters import gaussian\nfrom skimage.data import cells3d\nfrom pyclesperanto_prototype import imshow", "text": "\n\n## Border effects\nWhen processing images tile-by-tile we always must assume that along the border artifacts appear that result from cutting the image into tiles. As our example image fits in memory, we can apply `procedure` to it and compare it to the result from the tiled image processing", "code": "untiled_result = procedure(image)\nimshow(untiled_result)"}
{"imports": "import dask\nimport dask.array as da\nfrom skimage.filters import gaussian\nfrom skimage.data import cells3d\nfrom pyclesperanto_prototype import imshow", "text": "\n\nThe differences are not obvious, but we can visualize them.", "code": "difference = result - untiled_result\nimshow(difference)"}
{"imports": "import dask\nimport dask.array as da\nfrom skimage.filters import gaussian\nfrom skimage.data import cells3d\nfrom pyclesperanto_prototype import imshow", "text": "\n\nAfter loading the image, we tile it as usual.", "code": "tiles = da.from_array(image, chunks=(128, 128))\ntiles"}
{"imports": "import dask\nimport dask.array as da\nfrom skimage.filters import gaussian\nfrom skimage.data import cells3d\nfrom pyclesperanto_prototype import imshow", "text": "\n\nThe function was executed twice with very small images (0x0 and 1x1 pixels) to check if it works. Next, we actually compute the result.", "code": "result = tile_map.compute() # Warning: This loads all image data into memory"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom skimage.measure import regionprops_table\nimport numpy as np\nimport pandas as pd", "text": "\n\nWe try the function on timepoint 6 (= 5th frame as we are counting from 0):", "code": "tp_6 = segment_single_image(image_stack[5])\ntp_6"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom skimage.measure import regionprops_table\nimport numpy as np\nimport pandas as pd", "text": "\n\n## Visualizing images and image stacks\n\nWe can visualize our numpy-array like this:", "code": "cle.imshow(tp_6, labels=True)"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom skimage.measure import regionprops_table\nimport numpy as np\nimport pandas as pd", "text": "\n\nNow we can run our function in a for-loop over the whole time-lapse dataset:", "code": "segmented_slices = [segment_single_image(image) for image in image_stack]\nsegmented_stack = np.asarray(segmented_slices)"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\nfrom skimage.measure import regionprops_table\nimport numpy as np\nimport pandas as pd", "text": "\n\nOur `segmented_stack` should keep the same shape as the original `image_stack`:", "code": "segmented_stack.shape"}
{"imports": "import stackview\nstackview.curtain(image_stack, segmented_stack, zoom_factor=0.3)", "text": "\n\nNow, we try it out on timepoint 6 of our time-lapse dataset:", "code": "df = analyze_mean_intensity_single_timepoint(image_stack, segmented_stack, 5)\n\ndf"}
{"imports": "import stackview", "text": "\n\n`stackview.curtain` allows us to visualize our label_image on top of our image", "code": "stackview.curtain(image, label_image, continuous_update=True,zoom_factor = 3) "}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import measure\nimport pyclesperanto_prototype as cle", "text": "\n\nWe first open an image and label objects in it.", "code": "# Load data\nblobs = imread('../../data/blobs.tif')\ncle.asarray(blobs)\n\nlabeled_blobs = cle.voronoi_otsu_labeling(blobs, spot_sigma=3.5)\nlabeled_blobs"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import measure\nimport pyclesperanto_prototype as cle", "text": "\n\nThen, we analyze the labeled elements and get their properties.", "code": "# Analyse objects\nregionprops = measure.regionprops(labeled_blobs)"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nfrom skimage import measure\nimport pyclesperanto_prototype as cle", "text": "\n\nFinally, we use the `axs.annotate()` function with the following arguments:\n * `text`: the string to be displayed;\n * `xy`: the coordinates to plot the text;\n * `fontsize`: the size of the text;\n * `color`: the color of the text;", "code": "# Visualization\nfig, axs = plt.subplots(1, 1)\ncle.imshow(blobs, continue_drawing=True, plot=axs)\ncle.imshow(cle.reduce_labels_to_label_edges(labeled_blobs), labels=True, plot=axs, continue_drawing=True, alpha=0.7)\n\n# Plot label number over each element (iterate over each element)\nfor element in regionprops:\n    # Get element centroid (x, y)\n    element_centroid = (element.centroid[1]-8, element.centroid[0]+5)\n    \n    # Get element label and convert it to string\n    element_label = str(element.label)\n    \n    # Plot label number at the coordinates of that element centroid\n    axs.annotate(text = element_label, xy = element_centroid, fontsize = 12, color = 'white')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom numpy import random\nfrom skimage.io import imread\nimport matplotlib", "text": "\n\n# Starting point: Label map", "code": "binary = cle.binary_not(cle.threshold_otsu(intensity_image))\ncells = cle.voronoi_labeling(binary)\n\ncle.imshow(cells, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom numpy import random\nfrom skimage.io import imread\nimport matplotlib", "text": "\n\n## Nearest neighbor distance maps", "code": "average_distance_of_n_closest_neighbors_map = cle.average_distance_of_n_closest_neighbors_map(cells, n=1)\ncle.imshow(average_distance_of_n_closest_neighbors_map, color_map='jet')\n\naverage_distance_of_n_closest_neighbors_map = cle.average_distance_of_n_closest_neighbors_map(cells, n=5)\ncle.imshow(average_distance_of_n_closest_neighbors_map, color_map='jet')"}
