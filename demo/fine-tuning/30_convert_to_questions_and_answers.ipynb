{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ae0f648-9fbb-4cd0-a05a-740b514fbfe5",
   "metadata": {},
   "source": [
    "# Converting text and code in questions and answers\n",
    "This notebook loads a jsonl file that contains a list of dictionaries of the following format:\n",
    "```\n",
    "{\n",
    "    \"imports\":\"from skimage.io import imread\\nimport stackview\",\n",
    "    \"text\":\"You can load and show an image like this\",\n",
    "    \"code\":\"image = imread('blobs.tif')\\nstackview.insight(image)\"\n",
    "}\n",
    "```\n",
    "\n",
    "It will turn this information into a list of dictionaries in this format:\n",
    "```\n",
    "{\n",
    "    \"question:\":\"How can I open and visualize blobs.tif ?\",\n",
    "    \"answer\":\"You can do this like this:\\n\\n```python\\n```from skimage.io import imread\\nimport stackview\\n\\nimage = imread('blobs.tif')\\nstackview.insight(image)\"\n",
    "}\n",
    "```\n",
    "\n",
    "This is done using a languge model. Executing this notebook for about 70 entries costs about $0.10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43f13043-9a7e-4408-b1a9-4286481a3893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai\n",
    "import time\n",
    "from bia_bob import bob\n",
    "import os\n",
    "from bia_bob._utilities import filter_out_blacklist, save_jsonl_file, load_jsonl_file\n",
    "import json\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from bia_bob._utilities import load_jsonl_file, save_jsonl_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e9be79d-a385-48ae-9644-8eb1072715c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'imports': 'import numpy as np\\nfrom matplotlib import pyplot as plt\\n\\nimage1 = np.ones((3,5))\\nimage1\\n\\nimage2 = np.random.random((3,5))\\nimage2',\n",
       " 'text': '\\n\\nNow we take the average over columns, which means along the first axis or ```axis=0```:',\n",
       " 'code': 'np.mean(image2, axis=0)'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = load_jsonl_file(\"imports_text_code_selected.jsonl\")\n",
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb49e4b-c447-4486-bee8-3e2a8725eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(message:str, model=\"gpt-3.5-turbo\"):\n",
    "    \"\"\"A prompt helper function that sends a message to openAI\n",
    "    and returns only the text response.\n",
    "    \"\"\"\n",
    "    import openai\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469a4d6e-cb81-491d-aae4-eced8e15f9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_question_answer(imports, text, code):\n",
    "    question = prompt(\"Reformulated the following so that it becomes a question asking for Python code.\\n\\n\" + text)\n",
    "    refined_code = prompt(f\"\"\"\n",
    "Add necessary import statements to Python code so that the code works. \n",
    "Do not add import statements that are not necessary.\n",
    "These are the available import statements:\n",
    "```\n",
    "{imports}\n",
    "```\n",
    "\n",
    "And this is the code:\n",
    "```\n",
    "{code}\n",
    "```\n",
    "\n",
    "Keep the original code, add import statements as explained above and respond with code only.\n",
    "\"\"\")\n",
    "    refined_code = refined_code.replace(\"```python\", \"\").replace(\"```\", \"\")\n",
    "    \n",
    "    \n",
    "    explanation = prompt(f\"\"\"Explain the following code shortly, but do not explain import statements:\n",
    "```python\n",
    "{refined_code}\n",
    "```\n",
    "\"\"\")\n",
    "\n",
    "    answer = f\"\"\"\n",
    "{explanation}\n",
    "\n",
    "```python\n",
    "{refined_code}\n",
    "```\n",
    "\"\"\" \n",
    "\n",
    "    return question, answer\n",
    "\n",
    "#q, a = make_question_answer(training_data[0]['imports'], training_data[0]['text'], training_data[0]['code'])\n",
    "#\n",
    "#print(f\"\"\"\n",
    "#Q: {q}\n",
    "#\n",
    "#A: {a}\n",
    "#\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f1d0a25-eedc-45e9-aae8-70b9f35b50f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    questions_answers = load_jsonl_file(\"questions_answers.jsonl\")\n",
    "except:\n",
    "    questions_answers = []\n",
    "for i, entry in enumerate(training_data):\n",
    "    if i < len(questions_answers):\n",
    "        continue\n",
    "    print(i)\n",
    "    q,a = make_question_answer(entry['imports'], entry['text'], entry['code'])\n",
    "    questions_answers.append({\n",
    "        \"question\":q,\n",
    "        \"answer\":a,\n",
    "    })\n",
    "\n",
    "    save_jsonl_file(questions_answers, \"questions_answers.jsonl\")\n",
    "\n",
    "    # do not overheat the OpenAI API\n",
    "    # time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83a949-63e0-42be-b69e-d6d5bc9dc4c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5108c04b-bfd9-4d19-be80-fa619d8ac504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef850fe6-bee7-4866-8ac4-6c9c517b7e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
