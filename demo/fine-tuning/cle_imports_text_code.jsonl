{"imports": "import pyclesperanto_prototype as cle\n\nfrom skimage.io import imread, imsave, imshow\nimport matplotlib\nimport numpy as np\n\n# initialize GPU\ncle.select_device(\"GTX\")", "text": "\n\n## Crop out a part of the image", "code": "width = 75\nheight = 75\ntile = cle.create([height, width])\n\nx = 10\ny = 10\ncle.crop(image, tile, x, y)\n\ntile"}
{"imports": "import pyclesperanto_prototype as cle\n\nfrom skimage.io import imread, imsave, imshow\nimport matplotlib\nimport numpy as np\n\n# initialize GPU\ncle.select_device(\"GTX\")", "text": "\n\n## Create output image\nWe create an empty image and make a collage by pasting the cropped image into it. We also transform the cropped image for visualisation purpose:", "code": "collage = cle.create([width * 2 + 6, height * 2 + 6])\n\n# \"white\" background\ncle.set(collage, 255)\n\ncollage"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nPixels in memory need to be addressable. If you want to access pixel 5, the computer must be able to locate where this pixel is stored. Pixel adresses are stored in the data type 32-bit integer. This means 2^32 adresses are available. If an image is of type 8-bit, that means every pixel consists of 8-bit, which means 1 byte. As the image can have 2^32 pixels, the image size of an 8-bit is limited to 2^32 bytes. These are...", "code": "number_of_bytes = 2**32\nnumber_of_bytes\n\nnumber_of_kilobytes = number_of_bytes / 1024\nnumber_of_kilobytes\n\nnumber_of_megabytes = number_of_kilobytes / 1024\nnumber_of_megabytes\n\nnumber_of_gigabytes = number_of_megabytes / 1024\nnumber_of_gigabytes"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n... Giga-Bytes.\n\nThis notebook is executed on a computer that has technically 32 GB of GPU memory. Hence, it should be possible to allocate multiple images of that size:", "code": "image = cle.create((1024, 1024, 4 * 1024))"}
{"imports": "import numpy as np\nimport cupy as cp\nimport cupyx.scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nLet's start with a numpy-array and send it to cupy.", "code": "np_data = imread('../../data/Haase_MRT_tfl3d1.tif')\nnp_data.shape\n\ncp_data = cp.asarray(np_data)\ncp_data.shape"}
{"imports": "import numpy as np\nimport cupy as cp\nimport cupyx.scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nNext, we can apply a filter to the image in cupy.", "code": "cp_filtered = ndi.gaussian_filter(cp_data, sigma=5)\ncp_filtered.shape"}
{"imports": "import numpy as np\nimport cupy as cp\nimport cupyx.scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nJust as an example, we can now threshold the image using `threshold_otsu` which is provided by clesperanto but not by cupy.", "code": "cl_binary = cle.threshold_otsu(cp_filtered)\ncl_binary.shape"}
{"imports": "import numpy as np\nimport cupy as cp\nimport cupyx.scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nIn order to get the image back to cupy, we need to do this:", "code": "cu_binary = cp.asarray(cl_binary)\ncu_edges = ndi.sobel(cu_binary, output=float)\ncu_edges.shape"}
{"imports": "import numpy as np\nimport cupy as cp\nimport cupyx.scipy.ndimage as ndi\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread", "text": "\n\nA cupy-image can also be visualized using clesperantos imshow:", "code": "cle.imshow(cu_edges)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.available_device_names()", "text": "\n\nYou can then select a GPU and process on it.", "code": "cle.select_device('gfx')\n\nimage = np.random.random((10, 100, 100))\nprocessed_image = cle.gaussian_blur(image, sigma_x=10)\ncle.imshow(processed_image)"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle  # version 0.19.3", "text": "\n\n## top hat box", "code": "image1_thb = cle.top_hat_box(image0_L0r, None, 10.0, 10.0, 0.0)\nimage1_thb"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = cle.asarray(imread(\"../../data/blobs.tif\"))\nblobs", "text": "\n\n## Local Variance filter", "code": "blobs_edges = cle.variance_box(blobs, radius_x=5, radius_y=5)\nblobs_edges"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = cle.asarray(imread(\"../../data/blobs.tif\"))\nblobs", "text": "\n\n# Local standard deviation\n... is just the square root of the local variance", "code": "blobs_edges = cle.standard_deviation_box(blobs, radius_x=5, radius_y=5)\nblobs_edges"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = cle.asarray(imread(\"../../data/blobs.tif\"))\nblobs", "text": "\n\n## Edge detection is not edge enhancement\nIntuitively, one could apply an edge detection filter to enhance edges in images showing edges. Let's try with an image showing membranes. It's a 3D image btw.", "code": "image = cle.asarray(imread(\"../../data/EM_C_6_c0.tif\"))\nimage\n\nimage[60]\n\nimage_sobel = cle.sobel(image)\nimage_sobel[60]"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = cle.asarray(imread(\"../../data/blobs.tif\"))\nblobs", "text": "\n\nWhen looking very carefully, you may observe that the edges are a bit thicker in the second image. The edge detection filter detects two edges, the increasing signal side of the membrane and the decreasing signal on the opposite side. Let's zoom:", "code": "fig, axs = plt.subplots(1, 2)\ncle.imshow(                image[60, 125:145, 135:155], plot=axs[0])\ncle.imshow(cle.pull(image_sobel)[60, 125:145, 135:155], plot=axs[1])"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"RTX\")\n\nblobs = cle.asarray(imread(\"../../data/blobs.tif\"))\nblobs", "text": "\n\n## Enhancing edges\nThus, to enhance edges in a membrane image, other filters are more useful. Enhancement may for example mean making membranes thicker and potentially closing gaps.\n\n## Local standard deviation", "code": "image_std = cle.standard_deviation_box(image, radius_x=5, radius_y=5, radius_z=5)\nimage_std[60]"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport numpy as np\nimport scipy.ndimage as ndi\nimport random\n\ncle.select_device(\"cpu\")", "text": "\n\n## Create example data", "code": "# create example data\nunaligned_stack = np.random.normal(size=(50, 200, 200))\ncle.imshow(unaligned_stack)\n\n# add a white box in a random location to each image in the stack\nBOX_SIZE = 20\nimage_shape = unaligned_stack[0].shape\n\nfor i in range(len(unaligned_stack)):\n    \n    if i == 0:\n        # place the box in the centre of the first image\n        offset_x = image_shape[0] // 2 - BOX_SIZE // 2\n        offset_y = image_shape[1] // 2 - BOX_SIZE // 2\n    else:\n        offset_x = int(random.random() * (image_shape[0]-BOX_SIZE))\n        offset_y = int(random.random() * (image_shape[1]-BOX_SIZE))\n        \n    unaligned_stack[i, offset_x:offset_x+BOX_SIZE, offset_y:offset_y+BOX_SIZE] = 5\n\ncle.imshow(unaligned_stack[0])\ncle.imshow(unaligned_stack[1])"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport numpy as np\nimport scipy.ndimage as ndi\nimport random\n\ncle.select_device(\"cpu\")", "text": "\n\n## Align images\n\nTemplate matching translates images in the x and y directions to align each image based on a common subimage. In this example, the images can be aligned based on the white square in the first image.\n\nFirst, we must define a template to search for within each image. We can crop the white square in the first image to be used as our template.", "code": "template = unaligned_stack[0, 90:110, 90:110]\ncle.imshow(template)\ntemplate.min(), template.max()"}
{"imports": "", "text": "\n\n## A simple viewer updated later on\nWe start with a simple NumpyImage viewer that can be updated further down in the notebook.", "code": "blobs_view = niw.NumpyImage(blobs)\nblobs_view\n\nblobs_view.data = cle.gaussian_blur(blobs, sigma_x=15, sigma_y=15)"}
{"imports": "", "text": "\n\nFor a more complex graphical user interface (GUI) processing 3D data, we define a couple of sliders:", "code": "z_slice_slider = widgets.IntSlider(\n    value=depth / 2,\n    min=0,\n    max=depth,\n    continuous_update=True,\n    orientation='vertical',\n)\n\nbackground_subtraction_radius_slider = widgets.FloatSlider(\n    value=4.5,\n    min=0,\n    max=20.0,\n    step=0.1,\n    description='Background subtraction:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='.1f',\n)\n\nnoise_removal_sigma_slider = widgets.FloatSlider(\n    value=2.2,\n    min=0,\n    max=20.0,\n    step=0.1,\n    description='Noise removal:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='.1f',\n)\n\nedge_dilation_radius_slider = widgets.FloatSlider(\n    value=1.4,\n    min=0,\n    max=20,\n    step=0.1,\n    description='Edge dilation:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='.1f',\n)\n\nthreshold_slider = widgets.FloatSlider(\n    value=10,\n    min=0,\n    max=50.0,\n    step=0.1,\n    description='Threshold:',\n    disabled=False,\n    continuous_update=False,\n    orientation='horizontal',\n    readout=True,\n    readout_format='.1f',\n)\n\noutput_selector = widgets.RadioButtons(\n    options=['background subtracted', 'denoised', 'edge eroded', 'binary', 'labels', 'result'],\n    value='result',\n    description='Show output:',\n    disabled=False\n)"}
{"imports": "", "text": "\n\nFurthermore, we define two viewers for showing input and output images:", "code": "image_view = niw.NumpyImage(image[127])\nresult_view = niw.NumpyImage(image[127])"}
{"imports": "", "text": "\n\nWhen executing longer workflows multiple times, it may make sense to allocate memory in advance. This spares re-allocation time in every execution.", "code": "# allocate memory\nimage_gpu = cle.push(image)\nslice_gpu = cle.create([height, width])\n\n# have global variables for reusing memory\nbackground_subtracted_gpu = cle.create_like(image_gpu)\ndenoised_gpu = cle.create_like(image_gpu)\neroded_gpu = cle.create_like(image_gpu)\nbinary_gpu = cle.create_like(image_gpu)\nlabels_gpu = cle.create_labels_like(image_gpu)\nresult_gpu = cle.create_like(image_gpu)"}
{"imports": "", "text": "\n\nWe now use horizontal and vertical box arrangements to view the GUI elements.", "code": "widgets.HBox([z_slice_slider, image_view, result_view,\n             widgets.VBox([\n                 background_subtraction_radius_slider,\n                 noise_removal_sigma_slider,\n                 edge_dilation_radius_slider,\n                 threshold_slider,\n                 output_selector\n             ])])"}
{"imports": "from dask import array\ndask_array = array.random.random((450, 1024,1024))\ndask_array", "text": "\n\nPerform Gaussian blur with dask_array on GPU", "code": "blurred_device = cle.gaussian_blur(dask_array)\nblurred_device"}
{"imports": "from dask import array\ndask_array = array.random.random((450, 1024,1024))\ndask_array", "text": "\n\nManage the GPU array with Dask", "code": "blurred_device_dask = array.from_array(blurred_device)\nblurred_device_dask"}
{"imports": "from dask import array\ndask_array = array.random.random((450, 1024,1024))\ndask_array", "text": "\n\nData pulling from device to host need to be operated manually. Collect result back to host before releasing GPU memory.", "code": "blurred_host = array.from_array(cle.pull(blurred_device)) # pull gpu array back to host then manage by dask\nblurred_host"}
{"imports": "from dask import array\ndask_array = array.random.random((450, 1024,1024))\ndask_array", "text": "\n\nRelease GPU memory. Carefully using the buffer release, it must come with the variable deletion to avoid kernel crash due to invalid memory pointer.", "code": "blurred_device.data.release()\n # good practice to remove the variables to avoid accessing invalid gpu pointers after memory release\ndel blurred_device \ndel blurred_device_dask"}
{"imports": "import dask\nfrom dask.distributed import Client, Scheduler, Worker, Nanny, SpecCluster\nimport multiprocessing\nimport psutil", "text": "\n\nManually config the scheduler. Then create the cluster and manage by Dask client.", "code": "scheduler = {'cls': Scheduler, 'options': {\"dashboard_address\": ':8787'}}\ncluster = SpecCluster(scheduler=scheduler, workers=workers)\nclient = Client(cluster)\nclient"}
{"imports": "import dask\nfrom dask.distributed import Client, Scheduler, Worker, Nanny, SpecCluster\nimport multiprocessing\nimport psutil", "text": "\n\nWe only have one GPU worker. That means the large image can only work in sequential, but if your device get multiple GPUs this suppose can be automatically handle by Dask.\n\nTo test the functionality we create a list of Dask futures with the `cle_gaussian_blur` function.", "code": "futures = []\nfor i in range(4):\n    future = dask.delayed(cle_gaussian_blur)(dask_array)\n    futures.append(future)"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle", "text": "\n\nWhen working with numpy / scikit-image, images are per default visualized as array of numbers.", "code": "blobs = imread(\"../../data/blobs.tif\")\nblobs"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle", "text": "\n\nIn pyclesperanto_prototype, we per default visualize images as images, with additional information such as shape, pixel type and size.", "code": "cle_blobs = cle.asarray(blobs)\ncle_blobs"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle", "text": "\n\n## Customization with `imshow`\nFor customized visualization of the image, e.g. colormaps and colorbars, use `imshow()`.", "code": "cle.imshow(cle_blobs, colormap='jet', colorbar=True)"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle", "text": "\n\n## Label images\nThe visualization interprets `uint32` pixel type as label image and visualizes label images in color.", "code": "labels = cle.voronoi_otsu_labeling(blobs, spot_sigma=3.5)\n\nlabels"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle", "text": "\n\nYou can supress that behaviour by changing the type of the image.", "code": "labels.astype(float)"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle", "text": "\n\n## Volumetric image data\nThree dimensional images are visualized as maximum projection.", "code": "head = cle.asarray(imread(\"../../data/Haase_MRT_tfl3d1.tif\"))\nhead"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle", "text": "\n\nYou can visualize indiviual slices like when slicing numpy-arrays.", "code": "head[60]\n\nhead[:, 100]\n\nhead[:,:,100]"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n## Determining the presign of pixels", "code": "data = np.asarray([[-np.inf],\n                    [np.inf],\n                    [np.nan],\n                    [0],\n                    [1],\n                    [-1]])\n\nnp.sign(data)\n\ncle.sign(data)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n## Absolute", "code": "data = [[-3, 4]]\n\nnp.fabs(data)\n\ncle.fabs(data)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nNote: `cle.fabs` is just an alias:", "code": "cle.fabs.__name__"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n## Square", "code": "np.square(data)\n\ncle.power(data, exponent=2)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n## Cubic root", "code": "data = [[27, 8]]\n\nnp.cbrt(data)\n\ncle.cbrt(data)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n## Clip", "code": "data = [[1,2], [3,4]]\n\nnp.clip(data, a_min=2, a_max=3)\n\ncle.clip(data, a_min=2, a_max=3)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n## Modulo", "code": "test = [[4, 5]]\ntest_div = [[2, 2]]\n\nnp.mod(test, test_div)\n\ncle.mod(test, test_div)"}
{"imports": "import torch\nimport numpy as np\n\nimport pyclesperanto_prototype as cle\n\ntensor = torch.zeros((10, 10))\ntensor[1:3, 1:3] = 1\ntensor[5:7, 5:7] = 1", "text": "\n\n## Pushing tensors to the GPU", "code": "cle_tensor = cle.push(tensor)\ncle_tensor"}
{"imports": "import torch\nimport numpy as np\n\nimport pyclesperanto_prototype as cle\n\ntensor = torch.zeros((10, 10))\ntensor[1:3, 1:3] = 1\ntensor[5:7, 5:7] = 1", "text": "\n\n... turns the tensor into an OpenCL-Array", "code": "type(cle_tensor)"}
{"imports": "import torch\nimport numpy as np\n\nimport pyclesperanto_prototype as cle\n\ntensor = torch.zeros((10, 10))\ntensor[1:3, 1:3] = 1\ntensor[5:7, 5:7] = 1", "text": "\n\n## Passing tensors as arguments\nYou can also just pass a tensor as argument to clesperanto functions. The tensor will be pushed to the GPU implicitly anyway.", "code": "cle_labels = cle.label(tensor)\ncle_labels"}
{"imports": "import torch\nimport numpy as np\n\nimport pyclesperanto_prototype as cle\n\ntensor = torch.zeros((10, 10))\ntensor[1:3, 1:3] = 1\ntensor[5:7, 5:7] = 1", "text": "\n\n## Converting results back to a tensor\nTo turn the OpenCL image into a tensor, you need to call the `get()` function. Furthermore, in case of label images, you need to convert them into a pixel type that is accepted by pytorch, for example signed 32-bit integer.", "code": "labels_tensor = torch.tensor(cle_labels.astype(np.int32).get())\ntype(labels_tensor)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread, imshow\nimport matplotlib.pyplot as plt\n\ncle.get_device()", "text": "\n\nTechnically, we haven't checked yet if all eGFP positive nuclei are also Cy3 positive. We can do this by determining how many eGFP positive nuclei are close by each individual Cy3 positive nucleus. Therefore, we need to set a maximum distance threshold allowing us to specify how far away centroids of nuclei are allowed to be.", "code": "maximum_distance = 15 # pixels\n\n# draw a parametric map of cell counts\ncount_map = cle.proximal_other_labels_count_map(nuclei_cy3, nuclei_egfp)\ncle.imshow(count_map, colorbar=True)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread, imshow\nimport matplotlib.pyplot as plt\n\ncle.get_device()", "text": "\n\nThe `count_map` is a parametric image. We can identify all the nuclei where the count value >= 1. These are all the Cy3-positive nuclei which have at least one eGFP-positive nucleus with a centroid distance <= 15 pixels. ", "code": "double_positive_nuclei = cle.exclude_labels_with_map_values_out_of_range(\n    count_map, \n    nuclei_cy3, \n    minimum_value_range=1)\n\ncle.imshow(double_positive_nuclei, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread, imshow\nimport matplotlib.pyplot as plt\n\ncle.get_device()", "text": "\n\n## Visualization\nWe can also use the outlines around cells which are double positive and visualize those on the original images of both channels.", "code": "# determine outlines\noutlines = cle.detect_label_edges(double_positive_nuclei)\n\n# add outlines to original images. As outlines have value 1, \n# we need to multiply them to make them properly visible:\nchannel_0_with_outlines = cle.maximum_images(channel_0, outlines * channel_0.max())\n\n# visualize result\ncle.imshow(channel_0_with_outlines)\n\n# let's zoom in\ncle.imshow(channel_0_with_outlines.get()[400:800, 1000:1700])"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread, imshow\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ncle.get_device()", "text": "\n\nFirstly, we can measure the intensity in the second channel, marked with eGFP and visualize that measurement in a parametric image. In such a parametric image, all pixels inside a nucleus have the same value, in this case the mean average intensity of the cell.", "code": "intensity_map = cle.mean_intensity_map(channel_egfp, nuclei_cy3)\n\n# visualize\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(channel_egfp, plot=axs[0], color_map=\"gray\")\ncle.imshow(intensity_map, plot=axs[1], color_map=\"gray\")"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread, imshow\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ncle.get_device()", "text": "\n\nFrom such a parametric image, we can retrieve the intensity values and get them in a vector. The first item in this list has value 0 and corresponds to the intensity of the background, which is 0 in the parametric image.", "code": "intensity_vector = cle.read_intensities_from_map(nuclei_cy3, intensity_map)\nintensity_vector"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread, imshow\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ncle.get_device()", "text": "\n\nThe intensity vector can then be retrieved from the tabular statistics. Note: In this case, the background intensity is not 0, because we were directly reading it from the original image.", "code": "intensity_vector2 = statistics['mean_intensity']\nintensity_vector2"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imread, imshow\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ncle.get_device()", "text": "\n\nFrom such a histogram, we could conclude that objects with intensity above 50 are positive. \n\n## Selecting labels above a given intensity threshold\nWe next generate a new labels image with the nuclei having intensity > 50. Note, all the above steps for extracting the intensity vector are not necessary for this. We just did that to get an idea about a good intensity threshold.\n\nThe following label image show the nuclei segmented in the Cy3 channel which have a high intensity in the eGFP channel.", "code": "intensity_threshold = 50\n\nnuclei_with_high_intensity_egfg = cle.exclude_labels_with_map_values_within_range(intensity_map, nuclei_cy3, maximum_value_range=intensity_threshold)\nintensity_map = cle.mean_intensity_map(channel_egfp, nuclei_cy3)\n\n# visualize\nfig, axs = plt.subplots(1, 2, figsize=(15,15))\ncle.imshow(channel_egfp, plot=axs[0], color_map=\"gray\")\ncle.imshow(nuclei_with_high_intensity_egfg, plot=axs[1], labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nTo demonstrate a potential use-case, we take a close look at an image of cells expressing a membrane marker.", "code": "membranes = cells3d()[30, 0, 110:150, 110:150]\ncle.imshow(membranes)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nWe define coordinates of four points which will be connected to two lines. The connection will be done using a _touch_ matrix which allows connecting n points with n points.", "code": "coords = np.asarray([\n    [0, 17],  # line 1 start (x, y)\n    [10, 24], # line 1 end\n    [20, 21], # line 2\n    [35, 21]\n]).T\n\nconnection_matrix = cle.symmetric_maximum_matrix(np.asarray([\n    [0, 0, 0, 0, 0],\n    [0, 0, 1, 0, 0], # this connects the two points of line 1\n    [0, 0, 0, 0, 0],\n    [0, 0, 0, 0, 1], # this connects the two points of line 2\n    [0, 0, 0, 0, 0]\n]))\nconnection_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nFirst we visualize these lines on top of the membrane image.", "code": "mesh = cle.create_like(membranes)\nmesh = cle.touch_matrix_to_mesh(coords, connection_matrix, mesh)\n\ncle.imshow(membranes, continue_drawing=True)\ncle.imshow(mesh, alpha=0.5, colormap='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\n## Measure the mean intensity along lines\nNext we use the matrix configured above to measure the mean average intensity along the lines. We also need to specify how many samples will be taken along the lines.", "code": "num_samples = 10\n\nmean_intensity_matrix = cle.generate_mean_intensity_between_points_matrix(\n                                membranes, coords, connection_matrix, num_samples=num_samples)\nmean_intensity_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nWe can visualize these measurements also again as lines. As we pass points and connections between points as matrix, this is technically a mesh.", "code": "mean_intensity_mesh = cle.create_like(membranes)\nmean_intensity_mesh = cle.touch_matrix_to_mesh(coords, mean_intensity_matrix, mean_intensity_mesh)\nmean_intensity_mesh"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport numpy as np", "text": "\n\nWe can also visualize this quantitative mesh on top of the original membrane image.", "code": "cle.imshow(membranes, continue_drawing=True)\ncle.imshow(mean_intensity_mesh, alpha=0.5, colormap='jet', colorbar=True)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nOur starting point is a label image and another label image, where some of the labels in the first image are selected from.", "code": "label_image = cle.artificial_tissue_2d()\ncle.imshow(label_image, labels=True)\n\nrandom_vector = np.random.random((1, int(label_image.max() + 1)))\nsparse_labels = cle.exclude_labels_with_values_out_of_range(random_vector, label_image, minimum_value_range=0, maximum_value_range=0.3)\ncle.imshow(sparse_labels, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\nWe select an NVidida (GTX or RTX) GPU if available.", "code": "cle.select_device('TX')"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\n## Neighborhood definitions\nWe differentiate three kinds of neighborhoods. \n\n### Touching neighbors\nTo demonstrate touching neighborhoods, we increase the size of our labeled objects a bit first.", "code": "larger_labels = cle.dilate_labels(labels, radius=6)\nlarger_labels"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\n## We can then connect the centroids of touching objects.", "code": "touching_mesh = cle.draw_mesh_between_touching_labels(larger_labels)\ntouching_mesh"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\nclesperanto's `imshow` function allows to overlay both images.", "code": "cle.imshow(larger_labels, labels=True, continue_drawing=True)\ncle.imshow(touching_mesh, alpha=0.5)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\n### n-nearest neighbors\n\nAlso the n-nearest neighbors are drived from the distances between centroids. When interpreting the resulting neighbor-mesh, it is possible that a n=2-neighbor mesh contains objects that have connections to more than 2 neighbors. The unterlying reason is that the other object might connect to them.", "code": "n = 2\n\nn_nearest_neighbors_mesh = cle.draw_mesh_between_n_closest_labels(labels, n=n)\n\ncle.imshow(labels, labels=True, continue_drawing=True)\ncle.imshow(n_nearest_neighbors_mesh, alpha=0.5)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\nNote that this neighborhoood-representation is centroid-based. Collaborators have asked for distances between edges of objects. This is hard to compute on graphics cards, because it is tricky to paralellize.\n\n### Proximal neighbors\nProximal neighbors are neighbors which have a centroid distance below a given threshold", "code": "distance_threshold = 30\n\nproximal_neighbors_mesh1 = cle.draw_mesh_between_proximal_labels(labels, maximum_distance=distance_threshold)\n\ncle.imshow(labels, labels=True, continue_drawing=True)\ncle.imshow(proximal_neighbors_mesh1, alpha=0.5)\n\ndistance_threshold = 60\n\nproximal_neighbors_mesh2 = cle.draw_mesh_between_proximal_labels(labels, maximum_distance=distance_threshold)\n\ncle.imshow(labels, labels=True, continue_drawing=True)\ncle.imshow(proximal_neighbors_mesh2, alpha=0.5)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\nThis matrix can be represented as mesh, identical with the one shown above.", "code": "centroids = cle.centroids_of_labels(larger_labels)\n\ntouching_mesh2 = cle.touch_matrix_to_mesh(centroids, touch_matrix)\ntouching_mesh2\n\ncle.imshow(larger_labels, labels=True, continue_drawing=True)\ncle.imshow(touching_mesh2, alpha=0.5)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\n## Basic neighborhood quantification\nThe meshes shown above are quite informative visually. If one wanted to quantify these visual representations, one could for example count the number of neighbors within a given radius.", "code": "proximal_neighbor_count_map = cle.proximal_neighbor_count_map(labels, max_distance=distance_threshold)\n\ncle.imshow(proximal_neighbor_count_map, colorbar=True, colormap='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\nThe same information can also be derived in tabular form.", "code": "stats = cle.statistics_of_labelled_neighbors(labels, nearest_neighbor_ns=[2], \n                                     proximal_distances=[distance_threshold], \n                                     dilation_radii=[])\n                                 \npd.DataFrame(stats).T                          "}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\n## Quantitative meshes\nThere are also visual forms of representing measurements on neighborhood graphs.\n\n### Distance meshes\nIn this distance meshes the value/'color' along the mesh lines represents a quantiative measurement.", "code": "distance_mesh = cle.draw_distance_mesh_between_proximal_labels(labels, maximum_distance=distance_threshold)\n\ncle.imshow(labels > 0, continue_drawing=True)\ncle.imshow(distance_mesh, alpha=0.7, min_display_intensity=30, max_display_intensity=distance_threshold, colormap='jet', colorbar=True)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\nThe same can be done using the standard deviation of the intensity along the lines.", "code": "# Determine intensity along the edges\nstddev_intensity_matrix = cle.generate_standard_deviation_intensity_between_points_matrix(blobs, centroids, proximal_neighbor_matrix, num_samples=10)\n\n# draw the intensity mesh\nstddev_intensity_mesh = cle.touch_matrix_to_mesh(centroids, stddev_intensity_matrix)\n\ncle.imshow(blobs, continue_drawing=True)\ncle.imshow(stddev_intensity_mesh, alpha=0.7, min_display_intensity=0, max_display_intensity=100, colormap='jet', colorbar=True)\n\ncle.imshow(blobs, continue_drawing=True)\ncle.imshow(stddev_intensity_mesh, alpha=0.7, min_display_intensity=0, max_display_intensity=20, colormap='jet', colorbar=True)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\n## Using neighbor graph matrices for modifying label images\nIn the mesh shown above, there are some edges obviously different from others. The edges which connect centroids that lie both within the same objects have a much lower standard deviation intensity. We can exploit this to merge labels. Just as a reminder we look at the label image again.", "code": "labels"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\nFurthermore, we can view the `standard-deviation intensity along edges matrix` introduced above.", "code": "stddev_intensity_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\nWe can threshold this matrix to identify edges that have low standard deviation.", "code": "binary_matrix = cle.logical_and(stddev_intensity_matrix < 20, stddev_intensity_matrix > 0)  \nbinary_matrix"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\nWe can visualize this _mesh_ again in image space...", "code": "# draw the intensity mesh\nbinary_mesh = cle.touch_matrix_to_mesh(centroids, binary_matrix)\n\ncle.imshow(blobs, continue_drawing=True)\ncle.imshow(binary_mesh, alpha=0.7)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\n... and use it to merge labels.", "code": "merged_labels = cle.merge_labels_according_to_touch_matrix(labels, binary_matrix)\nmerged_labels"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport pandas as pd\nimport numpy as np\nimport stackview", "text": "\n\n## Merging touching labels\nThere are also short-cuts to similar functions such as for merging touching labels.", "code": "labels\n\ncle.merge_touching_labels(labels)"}
{"imports": "import pyclesperanto_prototype as cle\nimport igraph\nimport networkx\nfrom skimage.io import imread, imsave, imshow\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"amd\")", "text": "\n\n... and visualizing a graph of proximal objects which have a maximum centroid distance of 50 pixels.", "code": "mesh = cle.draw_mesh_between_proximal_labels(labels, maximum_distance=50)\ncle.imshow(mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nimport igraph\nimport networkx\nfrom skimage.io import imread, imsave, imshow\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"amd\")", "text": "\n\n## igraph\nWe can also retrieve an analogous igraph graph directly from the label image", "code": "igraph_graph = cle.proximal_labels_to_igraph(labels, maximum_distance=50)\n\nfig, ax = plt.subplots()\nigraph.plot(igraph_graph, target=ax)"}
{"imports": "import pyclesperanto_prototype as cle\nimport igraph\nimport networkx\nfrom skimage.io import imread, imsave, imshow\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"amd\")", "text": "\n\nNote: The visualization is flipped because the origin of the coordinate system is on the bottom left, while in clesperanto it's on the top left, because clesperanto uses community standards from the image processing field.\n\n## networkx\nThe same also works with networkx.", "code": "networkx_graph = cle.proximal_labels_to_networkx(labels, maximum_distance=50)\n\npos = networkx.get_node_attributes(networkx_graph,'pos')\n\nnetworkx.draw(networkx_graph, pos)"}
{"imports": "import pyclesperanto_prototype as cle\nimport igraph\nimport networkx\nfrom skimage.io import imread, imsave, imshow\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"amd\")", "text": "\n\n## n-nearest neighbors\nWe can alternatively also create networks between n-nearest neighbors for all", "code": "igraph_graph = cle.n_nearest_labels_to_igraph(labels, n=3)\n\nfig, ax = plt.subplots()\nigraph.plot(igraph_graph, target=ax)\n\nnetworkx_graph = cle.n_nearest_labels_to_networkx(labels, n=3)\n\npos = networkx.get_node_attributes(networkx_graph,'pos')\n\nnetworkx.draw(networkx_graph, pos)"}
{"imports": "import pyclesperanto_prototype as cle\nimport igraph\nimport networkx\nfrom skimage.io import imread, imsave, imshow\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"amd\")", "text": "\n\n## touching neighbors\nStarting from a label image where neighbors touch, we can also generate graphs between those.", "code": "touching_labels = cle.dilate_labels(labels, radius=5)\n\ncle.imshow(touching_labels, labels=True)\n\nigraph_graph = cle.touching_labels_to_igraph(touching_labels)\n\nfig, ax = plt.subplots()\nigraph.plot(igraph_graph, target=ax)\n\nnetworkx_graph = cle.touching_labels_to_networkx(touching_labels)\n\npos = networkx.get_node_attributes(networkx_graph,'pos')\n\nnetworkx.draw(networkx_graph, pos)"}
{"imports": "import pyclesperanto_prototype as cle\nimport igraph\nimport networkx\nfrom skimage.io import imread, imsave, imshow\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"amd\")", "text": "\n\n# How it works\nThe process under the hood involves the following steps:", "code": "# extract centroid positions\ncentroids = cle.centroids_of_labels(labels)\n\n# determine a distance matrix\ndistance_matrix = cle.generate_distance_matrix(centroids, centroids)\n\n# threshold the distance matrix\nadjacency_matrix = cle.generate_proximal_neighbors_matrix(distance_matrix, max_distance=50)\n\n# generate a mesh from centroid positions and the adjacency matrix\nmesh = cle.touch_matrix_to_mesh(centroids, adjacency_matrix, cle.create_like(blobs))\n\ncle.imshow(mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nimport igraph\nimport networkx\nfrom skimage.io import imread, imsave, imshow\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncle.select_device(\"amd\")", "text": "\n\nAs you can see, the igraph is directed. To make it direct in both direction along all edges, you can convert the adjacency matrix before passing it to `to_igraph`:", "code": "bidirectional_matrix = cle.touch_matrix_to_adjacency_matrix(adjacency_matrix)\ncle.set_where_x_equals_y(bidirectional_matrix, 0)\n\nigraph_graph = cle.to_igraph(bidirectional_matrix, centroids)\nfig, ax = plt.subplots()\nigraph.plot(igraph_graph, target=ax)"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport stackview", "text": "\n\nOur starting point is an oversegmented (synthetic) label image.", "code": "oversegmented = cle.asarray(imread('../../data/syntetic_cells.tif')).astype(np.uint32)\noversegmented"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport stackview", "text": "\n\nFurthermore, we need an annotation where pixel-intensity = 1 implies that labels should be merged.", "code": "annotation = cle.asarray(imread('../../data/syntetic_cells_merge_annotation.tif')).astype(np.uint32)\n\n# binarize the image\nannotation = annotation == 1\n\nannotation"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport stackview", "text": "\n\nFor visualization purposes, we overlay both.", "code": "cle.imshow(oversegmented, labels=True, continue_drawing=True)\ncle.imshow(annotation, alpha=0.5)"}
{"imports": "import apoc\nfrom skimage.io import imread, imshow, imsave\nimport pyclesperanto_prototype as cle\nimport numpy as np\nimport stackview", "text": "\n\nWe can now merge all cells whose borders are annotated.", "code": "result = cle.merge_annotated_touching_labels(oversegmented, annotation)\nresult"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imshow", "text": "\n\nLet's define a label image, just for testing", "code": "label_map = cle.push(np.asarray([\n    [1, 1, 1, 1, 0, 2, 2, 2, 2],\n    [1, 1, 1, 1, 0, 2, 2, 2, 2],\n    [1, 1, 1, 1, 0, 2, 2, 2, 2],\n    [1, 1, 1, 1, 0, 2, 2, 2, 2],\n    [0, 0, 0, 0, 0, 0, 0, 0, 0],\n    [3, 3, 3, 3, 0, 4, 4, 4, 4],\n    [3, 3, 3, 3, 0, 4, 4, 4, 4],\n    [3, 3, 3, 3, 0, 4, 4, 4, 4],\n    [3, 3, 3, 3, 0, 4, 4, 4, 4]\n]))\n\ncle.imshow(label_map, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom numpy import random\nfrom skimage.io import imshow", "text": "\n\n# Sepcial meshes\n## Mesh of touching neighbors", "code": "angle_mesh = cle.touch_matrix_to_mesh(centroids, touch_matrix)\ncle.imshow(angle_mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom numpy import random\nfrom skimage.io import imshow", "text": "\n\n## Mesh nearest neighbors", "code": "nearest_neighbor_mesh = cle.draw_mesh_between_n_closest_labels(cells, n=1)\ncle.imshow(nearest_neighbor_mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom numpy import random\nfrom skimage.io import imshow", "text": "\n\n## Meshes of proximal neighbors/", "code": "close_neighbors_mesh = cle.draw_mesh_between_proximal_labels(cells, maximum_distance=25)\ncle.imshow(close_neighbors_mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom numpy import random\nfrom skimage.io import imshow", "text": "\n\n## Distance meshes\nThis is the same custom mesh as shown in the section on top", "code": "distance_mesh = cle.draw_distance_mesh_between_touching_labels(cells)\ncle.imshow(distance_mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\n\n# fill it with random measurements\nvalues = random([int(cle.maximum_of_all_pixels(tissue))])\nfor i, y in enumerate(values):\n    if (i != 95):\n        values[i] = values[i] * 10 + 45\n    else:\n        values[i] = values[i] * 10 + 90\n\nmeasurements = cle.push(np.asarray([values]))\n\n# visualize measurments in space\nexample_image = cle.replace_intensities(tissue, measurements)", "text": "\n\n## Example data\nLet's take a look at an image with arbitrarily shaped pixels. Let's call them \"cells\". In our example image, there is one cell in the center with higher intensity:", "code": "cle.imshow(example_image, min_display_intensity=30, max_display_intensity=90, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\n\n# fill it with random measurements\nvalues = random([int(cle.maximum_of_all_pixels(tissue))])\nfor i, y in enumerate(values):\n    if (i != 95):\n        values[i] = values[i] * 10 + 45\n    else:\n        values[i] = values[i] * 10 + 90\n\nmeasurements = cle.push(np.asarray([values]))\n\n# visualize measurments in space\nexample_image = cle.replace_intensities(tissue, measurements)", "text": "\n\n## Touching neighbors\nWe can show all cells that belong to the \"touch\" neighborhood by computing the local maximum intensity in this neighborhood. Let's visualize the touching neighbor graph as mesh first.", "code": "mesh = cle.draw_mesh_between_touching_labels(tissue)\n\n# make lines a bit thicker for visualization purposes\nmesh = cle.maximum_sphere(mesh, radius_x=1, radius_y=1)\n\ncle.imshow(mesh)"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\n\n# fill it with random measurements\nvalues = random([int(cle.maximum_of_all_pixels(tissue))])\nfor i, y in enumerate(values):\n    if (i != 95):\n        values[i] = values[i] * 10 + 45\n    else:\n        values[i] = values[i] * 10 + 90\n\nmeasurements = cle.push(np.asarray([values]))\n\n# visualize measurments in space\nexample_image = cle.replace_intensities(tissue, measurements)", "text": "\n\nFrom those neighbor-graph one can compute local properties, for example the maximum:", "code": "local_maximum = cle.maximum_of_touching_neighbors_map(example_image, tissue)\n\ncle.imshow(local_maximum, min_display_intensity=30, max_display_intensity=90, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\n\n# fill it with random measurements\nvalues = random([int(cle.maximum_of_all_pixels(tissue))])\nfor i, y in enumerate(values):\n    if (i != 95):\n        values[i] = values[i] * 10 + 45\n    else:\n        values[i] = values[i] * 10 + 90\n\nmeasurements = cle.push(np.asarray([values]))\n\n# visualize measurments in space\nexample_image = cle.replace_intensities(tissue, measurements)", "text": "\n\n## Neighbors of touching neighbors\nYou can also extend the neighborhood by considering neighbors of neighbor (of neighbors (of neighbors)). How far you go, can be configured with a radius parameter. Note: Radiu==0 means, no neighbors are taken into account, radius==1 is identical with touching neighbors, radius > 1 are neighbors of neighbors:", "code": "for radius in range(0, 5):\n    local_maximum = cle.maximum_of_touching_neighbors_map(example_image, tissue, radius=radius)\n    cle.imshow(local_maximum, min_display_intensity=30, max_display_intensity=90, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Associate artificial measurements to the cells", "code": "centroids = cle.label_centroids_to_pointlist(tissue)\n\ncoordinates = cle.pull_zyx(centroids)\nvalues = random([coordinates.shape[1]])\n\nfor i, y in enumerate(coordinates[1]):\n    if (y < 128):\n        values[i] = values[i] * 10 + 45\n    else:\n        values[i] = values[i] * 10 + 90\n\nmeasurements = cle.push_zyx(np.asarray([values]))\n\n# visualize measurments in space\nparametric_image = cle.replace_intensities(tissue, measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Local averaging smoothes edges\nBy averaging measurments locally, we can reduce the noise, but we also introduce a stripe where the region touch", "code": "local_mean_measurements = cle.mean_of_touching_neighbors(measurements, touch_matrix)\n\nparametric_image = cle.replace_intensities(tissue, local_mean_measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Edge preserving filters: median\nBy averaging using a median filter, we can also reduce noise while keeping the edge between the regions sharp", "code": "local_median_measurements = cle.median_of_touching_neighbors(measurements, touch_matrix)\n\nparametric_image = cle.replace_intensities(tissue, local_median_measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nimport matplotlib\nfrom numpy.random import random\n\ncle.select_device(\"RTX\")\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\ntouch_matrix = cle.generate_touch_matrix(tissue)\n\ncle.imshow(tissue, labels=True)", "text": "\n\n# Increasing filter radius: neighbors of neighbors\nIn order to increase the radius of the operation, we need to determin neighbors of touching neighbors", "code": "neighbor_matrix = cle.neighbors_of_neighbors(touch_matrix)\n\nlocal_median_measurements = cle.median_of_touching_neighbors(measurements, neighbor_matrix)\n\nparametric_image = cle.replace_intensities(tissue, local_median_measurements)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=100, color_map='jet')"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nOur starting point is a label image and another label image, where some of the labels in the first image are selected from.", "code": "label_image = cle.artificial_tissue_2d()\ncle.imshow(label_image, labels=True)\n\nrandom_vector = np.random.random((1, int(label_image.max() + 1)))\nsparse_labels = cle.exclude_labels_with_values_out_of_range(random_vector, label_image, minimum_value_range=0, maximum_value_range=0.3)\ncle.imshow(sparse_labels, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nimport pandas as pd\n\ncle.select_device(\"TX\")\n\ncle.__version__", "text": "\n\nAssume we have a label image like this. Obviously, the labels are not touching.", "code": "label_image = cle.asarray([\n    [0, 0, 0, 0, 0],\n    [0, 1, 0, 2, 0],\n    [0, 0, 0, 0, 0],\n])\n\nstats = cle.statistics_of_labelled_neighbors(label_image, \n                                             proximal_distances=[], \n                                             nearest_neighbor_ns=[], \n                                             dilation_radii=[0, 1, 2])\n\ndf = pd.DataFrame(stats)\n\ndf.describe().T"}
{"imports": "import pyclesperanto_prototype as cle\nimport pandas as pd\n\ncle.select_device(\"TX\")\n\ncle.__version__", "text": "\n\nThe resulting table contains columns for neighbor statistics of dilated labels with specified radii (1,2). From these columns we can see how these statistics change when labels are dilated.", "code": "df[[\"label\", \"touch_count_sum_dilated_r_0\", \"touch_count_sum_dilated_r_1\", \"touch_count_sum_dilated_r_2\"]]\n\ndf[[\"label\", \"average_distance_of_touching_neighbors_dilated_r_0\", \"average_distance_of_touching_neighbors_dilated_r_1\"]]"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\nWe use this example label image to show what the different measurements mean. In the following, most measures will be explained for the object number `7` in the center of the image.", "code": "labels = cle.scale(cle.asarray([\n   [1, 1, 2, 2, 3, 3, 3, 3],\n   [1, 1, 2, 2, 3, 3, 3, 3],\n   [1, 1, 7, 7, 7, 7, 3, 3],\n   [1, 1, 7, 7, 7, 7, 3, 3],\n   [6, 6, 7, 7, 7, 7, 4, 4],\n   [6, 6, 7, 7, 7, 7, 4, 4],\n   [5, 5, 5, 5, 5, 5, 4, 4],\n   [5, 5, 5, 5, 5, 5, 4, 4],\n]), factor_x=10, factor_y=10, auto_size=True).astype(np.uint32)\n\nlabels"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n# Distance meshes\nBefore diving into details we should first have a look at neighborhood relationships and distances between neighbors. A distance mesh visualizes the distances between centroids in colour.", "code": "distance_mesh = cle.draw_distance_mesh_between_touching_labels(labels)\ncle.imshow(distance_mesh, colorbar=True, colormap=\"rainbow\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\nSimple statistics such as the longest distance between direct neighbors can be measured from that image.", "code": "distance_mesh.max()"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\nFor more detailed statistics we use a table / pandas DataFrame.", "code": "stats = pd.DataFrame(cle.statistics_of_labelled_neighbors(labels))\nstats"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n## Visualization of statistics\nWe can visualize those measurements in parametric map images.\n\nFor visualization of the table columns as maps, we typically need to prefix the measurements with a `0`. This `0` represents the measurement of the background.", "code": "stats[\"touching_neighbor_count\"].tolist()\n\nlist_of_measurements = cle.prefix_in_x([stats[\"touching_neighbor_count\"].tolist()])\nlist_of_measurements\n\ncle.replace_intensities(labels, list_of_measurements)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Number of touching neighbors and proximal neighbors", "code": "visualize(cell_estimation, tribolium_statistics, \"touching_neighbor_count\")\n\nvisualize(cell_estimation, tribolium_statistics, \"proximal_neighbor_count_d10\")\n\nvisualize(cell_estimation, tribolium_statistics, \"proximal_neighbor_count_d20\")\n\nvisualize(cell_estimation, tribolium_statistics, \"proximal_neighbor_count_d40\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Distances to touching neighbors", "code": "visualize(cell_estimation, tribolium_statistics, \"minimum_distance_of_touching_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"average_distance_of_touching_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_touching_neighbors\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Distance to nearest neighbors", "code": "visualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_n1_nearest_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_n6_nearest_neighbors\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_distance_of_n10_nearest_neighbors\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Distance to the most distant other label", "code": "visualize(cell_estimation, tribolium_statistics, \"distance_to_most_distant_other\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pandas as pd", "text": "\n\n### Touch count\nTouch count is the number of voxels labels touch others.", "code": "visualize(cell_estimation, tribolium_statistics, \"touch_count_sum\")\n\nvisualize(cell_estimation, tribolium_statistics, \"minimum_touch_count\")\n\nvisualize(cell_estimation, tribolium_statistics, \"maximum_touch_count\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt", "text": "\n\n## Demonstration with a simpler example\nOur example image shows a couple of objects. In the following, we will concentrate on the objects `4` and `5` in the center of the image.", "code": "labels = cle.scale(cle.asarray([\n   [1, 1, 1, 1, 2, 2, 2, 2],\n   [1, 1, 1, 1, 2, 2, 2, 2],\n   [1, 1, 4, 4, 5, 5, 2, 2],\n   [1, 1, 4, 4, 5, 5, 2, 2],\n   [1, 1, 4, 4, 3, 3, 2, 2],\n   [1, 1, 4, 4, 3, 3, 2, 2],\n   [3, 3, 3, 3, 3, 3, 3, 3],\n   [3, 3, 3, 3, 3, 3, 3, 3],\n]), factor_x=10, factor_y=10, auto_size=True).astype(np.uint32)\nlabels"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\nIf we then run an operation on the GPU and check memory consumption again, we should see an increase.", "code": "image = np.random.random((1024, 1024, 100))\n\nblurred = cle.gaussian_blur(image)\n\n!nvidia-smi --query-gpu=memory.used --format=csv"}
{"imports": "from skimage.io import imread\nfrom scipy.optimize import minimize\nimport numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nWe start with loading an example image and a manual annotation. Not all objects must be annotated (sparse annotation).", "code": "blobs = cle.push(imread('../../data/blobs.tif'))\n\ncle.imshow(blobs)\n\nannotation = cle.push(imread('../../data/blobs_annotated.tif'))\n\ncle.imshow(annotation)"}
{"imports": "import numpy as np\nfrom skimage.io import imshow\n\nrandom_image = np.random.random([512,512])\nbinary_image = random_image > 0.9995\n\n# push to GPU\ninput_image = cle.push(binary_image * random_image)\n\n# blur the image\nsigma = 3\nstarting_point = cle.gaussian_blur(input_image, sigma_x=sigma, sigma_y=sigma)\n\n# show input image\nstarting_point", "text": "\n\n## Local maxima detection", "code": "maxima = cle.detect_maxima_box(starting_point)\nmaxima"}
{"imports": "import numpy as np\nfrom skimage.io import imshow\n\nrandom_image = np.random.random([512,512])\nbinary_image = random_image > 0.9995\n\n# push to GPU\ninput_image = cle.push(binary_image * random_image)\n\n# blur the image\nsigma = 3\nstarting_point = cle.gaussian_blur(input_image, sigma_x=sigma, sigma_y=sigma)\n\n# show input image\nstarting_point", "text": "\n\n## Make a local threshold image", "code": "# Extend labeled maxima until they touch\nvoronoi_label_image = cle.extend_labeling_via_voronoi(labeled_maxima)\nvoronoi_label_image\n\n# Replace labels with thresholds\nthreshold_image = cle.replace_intensities(voronoi_label_image, thresholds)\nthreshold_image\n\n# Apply threshold\nbinary_segmented = cle.greater(starting_point, threshold_image)\nbinary_segmented"}
{"imports": "import pyclesperanto_prototype as cle\n\n# select a specific OpenCL / GPU device and see which one was chosen\ncle.select_device('RTX')", "text": "\n\nFor visualisation purposes we crop out a sub-region:", "code": "input_crop = cle.crop(input_image, start_x=bb_x, start_y=bb_y, width=bb_width, height=bb_height)\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 15))\ncle.imshow(input_image, plot=axs[0])\ncle.imshow(input_crop, plot=axs[1])"}
{"imports": "import pyclesperanto_prototype as cle\n\n# select a specific OpenCL / GPU device and see which one was chosen\ncle.select_device('RTX')", "text": "\n\n## Applying the algorithm\nGauss-Otsu-labeling is a command in clesperanto, which asks for a sigma parameter. It controls how precise segmented objects are outlined (`outline_sigma`).", "code": "sigma_outline = 1\n\nsegmented = cle.gauss_otsu_labeling(input_image, outline_sigma=sigma_outline)\nsegmented_crop = cle.crop(segmented, start_x=bb_x, start_y=bb_y, width=bb_width, height=bb_height)\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 15))\ncle.imshow(segmented, labels=True, plot=axs[0])\ncle.imshow(segmented_crop, labels=True, plot=axs[1])"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\nFor demonstration purposes we load an intensity image and create a binary image.", "code": "raw_image = cle.asarray(imread(\"../../data/blobs.tif\"))\nraw_image\n\nbinary_image = raw_image > 100\nbinary_image"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Gauss-Otsu-Labeling\nWe often use image blurring, e.g. using a [Gaussian blur](), [Otus's thresholding method]() and CCL in combination. Thus, pyclesperanto has a function which combines these operations and make them easier accessible. The parameter `outline_sigma` allows tuning the smoothness of the outline of the labeled objects. When increasing it, also small objects may disappear.", "code": "gol1 = cle.gauss_otsu_labeling(raw_image, outline_sigma=1)\ngol1\n\ngol5 = cle.gauss_otsu_labeling(raw_image, outline_sigma=5)\ngol5"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Voronoi-Otsu-Labeling\nAnother common approach is blurring the raw image, detecting maxima and using a binary watershed to flood a corresponding binary image with label values. Results are supposed to be similar to a binary image that has been processed by ImageJ's binary Watershed algorithm before it is passed to CCL. The algorithm has a parameter `outline_sigma` as explained above. Furthermore, the `spot_sigma` parameter allows to tune how distant local maxima are in the initial detection step.", "code": "vol1 = cle.voronoi_otsu_labeling(raw_image, outline_sigma=1, spot_sigma=1)\nvol1\n\nvol32 = cle.voronoi_otsu_labeling(raw_image, outline_sigma=1, spot_sigma=3.2)\nvol32"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n## Post-processing label images\n### Voronoi tesselation\nStarting at different label or binary images, we can partionion an entire image into labels using Voronoi tesselation.", "code": "tesselated_image = cle.extend_labeling_via_voronoi(vol32)\ntesselated_image"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\nSimilarly, starting from a binary image, we can label the objects using connected component labeling and then partion the image.", "code": "partioned_image = cle.voronoi_labeling(binary_image)\npartioned_image"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Exclude small/large labels\nYou can exclude small and large labels using dedicated operations. It is also possible to select a size range of labels to keep or remove.", "code": "large_labels = cle.exclude_small_labels(ccl_image_diamond, maximum_size=350)\nlarge_labels\n\nsmall_labels = cle.exclude_large_labels(ccl_image_diamond, minimum_size=200)\nsmall_labels\n\nmedium_sized_labels = cle.exclude_labels_out_of_size_range(ccl_image_diamond, minimum_size=200, maximum_size=350)\nmedium_sized_labels"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Combine label images\nYou can also combine label images.", "code": "combined_labels = cle.combine_labels(small_labels, large_labels)\ncombined_labels"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Dilating label images\nDilating label images, is similar to a maximum filter. The only difference is that labels don't overwrite each other.", "code": "dilated_labels_3 = cle.dilate_labels(combined_labels, radius=3)\ndilated_labels_3\n\ndilated_labels_7 = cle.dilate_labels(combined_labels, radius=7)\ndilated_labels_7"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Eroding label images\nWhen eroding label images, basically two options exist: Erode labels using a minimum-filter after introducing a background-pixel between labels, and eroding the labels while keeping their connected regions connected.", "code": "eroded_labels_3 = cle.erode_labels(dilated_labels_7, radius=3)\neroded_labels_3\n\neroded_connected_labels_3 = cle.erode_connected_labels(dilated_labels_7, radius=3)\neroded_connected_labels_3"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Label opening\nIn a similar way, labels can also be opened. Note: Depending on the radius, small labels may disappear.\n\nopened_labels_1 = cle.opening_labels(combined_labels, radius=1)\n\ncle.imshow(opened_labels_1, labels=True)", "code": "opened_labels_5 = cle.opening_labels(combined_labels, radius=5)\nopened_labels_5"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Label closing\nAnalogously, an operation for closing label images exists.", "code": "closed_labels_1 = cle.closing_labels(combined_labels, radius=1)\nclosed_labels_1\n\nclosed_labels_5 = cle.closing_labels(combined_labels, radius=5)\nclosed_labels_5"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Excluding labels according to other parameters\nWe can also exclude labels in a label image according to other parameters, e.g. using shape. Therefore, we need a parametric image where the pixels in the label correspond to the parameter we want to consider for excluding labels.", "code": "shape_parametric_image = cle.extension_ratio_map(closed_labels_1)\nshape_parametric_image\n\nminimum_extension_ratio = 1.8\nmaximum_extension_ratio = 100\nelongated_labels = cle.exclude_labels_with_map_values_out_of_range(\n    shape_parametric_image, \n    closed_labels_1, \n    minimum_value_range=minimum_extension_ratio,\n    maximum_value_range=maximum_extension_ratio,\n)\nelongated_labels"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n## Other operations\n### Label borders\nLabel border images can be derived as label image and as binary image.", "code": "label_border_image = cle.reduce_labels_to_label_edges(elongated_labels)\nlabel_border_image\n\nbinary_border_image = cle.detect_label_edges(elongated_labels)\nbinary_border_image"}
{"imports": "from skimage.io import imread\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n### Label centroids\nLabels can also be reduced to their centroids.", "code": "label_centroids_image = cle.reduce_labels_to_centroids(elongated_labels)\nlabel_centroids_image"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport stackview", "text": "\n\nFor demonstrating the filter, we create a semantic segmentation of blobs.", "code": "blobs = cle.imread(\"../../data/blobs.tif\")\n\nsemantic_segmentation = (blobs > 70) + \\\n                        (blobs > 200) + 1\n\nsemantic_segmentation.astype(np.uint32)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport stackview", "text": "\n\nUsing the functions `mode_sphere` and `mode_box` we can make the result less noisy.", "code": "cle.mode_sphere(semantic_segmentation, radius_x=2, radius_y=2).astype(np.uint32)\n\ncle.mode_sphere(semantic_segmentation, radius_x=4, radius_y=4).astype(np.uint32)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport stackview", "text": "\n\nWhen the radius becomes wider and wider, the result contains less and less local information.", "code": "cle.mode_sphere(semantic_segmentation, radius_x=10, radius_y=10).astype(np.uint32)"}
{"imports": "from skimage.data import cells3d\nimport pyclesperanto_prototype as cle\n\nimage = cells3d()\nimage.shape\n\nnuclei = image[30, 1]\n\ncle.imshow(nuclei)\n\nlabels = cle.eroded_otsu_labeling(nuclei, number_of_erosions=11, outline_sigma=4)\n\ncle.imshow(labels, labels=True)", "text": "\n\n## Parameter: number_of_erosions\nIf the specified number of erosions is too small, sticky objects will be labeled together.", "code": "labels = cle.eroded_otsu_labeling(nuclei, number_of_erosions=5, outline_sigma=4)\n\ncle.imshow(labels, labels=True)"}
{"imports": "from skimage.data import cells3d\nimport pyclesperanto_prototype as cle\n\nimage = cells3d()\nimage.shape\n\nnuclei = image[30, 1]\n\ncle.imshow(nuclei)\n\nlabels = cle.eroded_otsu_labeling(nuclei, number_of_erosions=11, outline_sigma=4)\n\ncle.imshow(labels, labels=True)", "text": "\n\nIf too many erosions are configured, objects may disappear.", "code": "labels = cle.eroded_otsu_labeling(nuclei, number_of_erosions=20, outline_sigma=4)\n\ncle.imshow(labels, labels=True)"}
{"imports": "from skimage.data import cells3d\nimport pyclesperanto_prototype as cle\n\nimage = cells3d()\nimage.shape\n\nnuclei = image[30, 1]\n\ncle.imshow(nuclei)\n\nlabels = cle.eroded_otsu_labeling(nuclei, number_of_erosions=11, outline_sigma=4)\n\ncle.imshow(labels, labels=True)", "text": "\n\n## Parameter: outline_sigma\nWith this outline, you can control the denoising before thresholding. If this value is too low, objects may have noisy edges and holes lead to more object-splits.", "code": "labels = cle.eroded_otsu_labeling(nuclei, number_of_erosions=5, outline_sigma=1)\n\ncle.imshow(labels, labels=True)"}
{"imports": "from skimage.data import cells3d\nimport pyclesperanto_prototype as cle\n\nimage = cells3d()\nimage.shape\n\nnuclei = image[30, 1]\n\ncle.imshow(nuclei)\n\nlabels = cle.eroded_otsu_labeling(nuclei, number_of_erosions=11, outline_sigma=4)\n\ncle.imshow(labels, labels=True)", "text": "\n\nIf this value is too high, object outlines may be not fitting to the original objects anymore.", "code": "labels = cle.eroded_otsu_labeling(nuclei, number_of_erosions=11, outline_sigma=10)\n\ncle.imshow(labels, labels=True)"}
{"imports": "from skimage.data import cells3d\nimport pyclesperanto_prototype as cle\n\nimage = cells3d()\nimage.shape\n\nnuclei = image[30, 1]\n\ncle.imshow(nuclei)\n\nlabels = cle.eroded_otsu_labeling(nuclei, number_of_erosions=11, outline_sigma=4)\n\ncle.imshow(labels, labels=True)", "text": "\n\n## Similar algorithm: Voronoi-Otsu-Labeling\nVoronoi-Otsu-Labeling is a similar algorithm. When you see labels swapping over in neighbor-objects when using it like shown below, you may want to give object-splitting-Otsu-labeling a try.", "code": "labels = cle.voronoi_otsu_labeling(nuclei, spot_sigma=10, outline_sigma=5)\n\ncle.imshow(labels, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import closing, disk\nfrom skimage.io import imsave\n\nimage = cells3d()\n\nmembrane2d = cle.push(image[30,0])\n\ncle.imshow(membrane2d)\n\nlabels = cle.label(cle.gaussian_blur(membrane2d, sigma_x=2, sigma_y=2) < 2000)\n\ncle.imshow(labels, labels=True)\n\nfor i, r in enumerate(range(0, 24, 3)):\n    \n    fix, axs = plt.subplots(1,3, figsize=(10,10))\n    \n    cle.imshow(cle.closing_labels(labels, radius=r), plot=axs[0], labels=True)\n    cle.imshow(labels, plot=axs[1], labels=True)\n    cle.imshow(cle.opening_labels(labels, radius=r), plot=axs[2], labels=True)\n    \n    axs[0].set_title(\"Closed labels (r=\" + str(r) + \")\")\n    axs[1].set_title(\"Original labels\")\n    axs[2].set_title(\"Opened labels (r=\" + str(r) + \")\")", "text": "\n\n## Comparison of label closing to binary closing", "code": "r = 5\n\nfix, axs = plt.subplots(1,3, figsize=(10,10))\n\ncle.imshow(labels, plot=axs[0], labels=True)\ncle.imshow(cle.closing_labels(labels, radius=r), plot=axs[1], labels=True)\ncle.imshow(cle.closing_sphere(labels != 0, radius_x=r, radius_y=r), plot=axs[2], color_map=\"Greys_r\")\n\naxs[0].set_title(\"Original labels\")\naxs[1].set_title(\"Closed labels (r=\" + str(r) + \")\")\naxs[2].set_title(\"Binary closing (r=\" + str(r) + \")\")\n"}
{"imports": "import pyclesperanto_prototype as cle\nfrom skimage.data import cells3d\nimport matplotlib.pyplot as plt\nfrom skimage.morphology import closing, disk\nfrom skimage.io import imsave\n\nimage = cells3d()\n\nmembrane2d = cle.push(image[30,0])\n\ncle.imshow(membrane2d)\n\nlabels = cle.label(cle.gaussian_blur(membrane2d, sigma_x=2, sigma_y=2) < 2000)\n\ncle.imshow(labels, labels=True)\n\nfor i, r in enumerate(range(0, 24, 3)):\n    \n    fix, axs = plt.subplots(1,3, figsize=(10,10))\n    \n    cle.imshow(cle.closing_labels(labels, radius=r), plot=axs[0], labels=True)\n    cle.imshow(labels, plot=axs[1], labels=True)\n    cle.imshow(cle.opening_labels(labels, radius=r), plot=axs[2], labels=True)\n    \n    axs[0].set_title(\"Closed labels (r=\" + str(r) + \")\")\n    axs[1].set_title(\"Original labels\")\n    axs[2].set_title(\"Opened labels (r=\" + str(r) + \")\")", "text": "\n\n## Comparison of label closing to morphological closing", "code": "r = 24\n\nfix, axs = plt.subplots(1,3, figsize=(10,10))\n    \ncle.imshow(labels, plot=axs[0], labels=True)\ncle.imshow(cle.closing_labels(labels, radius=r), plot=axs[1], labels=True)\ncle.imshow(cle.closing_sphere(labels, radius_x=r, radius_y=r), plot=axs[2], labels=True)\n\naxs[0].set_title(\"Original labels\")\naxs[1].set_title(\"Closed labels (r=\" + str(r) + \")\")\naxs[2].set_title(\"Binary closing (r=\" + str(r) + \")\")\n"}
{"imports": "import pyclesperanto_prototype as cle\n\n# select a specific OpenCL / GPU device and see which one was chosen\ncle.select_device('RTX')\n\ninput_image = cle.asarray(input_image)\ninput_image", "text": "\n\nInitially, we push the image to GPU memory and segment it using thresholding to see how good it can be done right away.", "code": "threshold = 550\nbinary = input_image < threshold\n\nlabels = cle.voronoi_labeling(binary)\n\nfig, axs = plt.subplots(1, 3, figsize=(15, 15))\ncle.imshow(input_image, plot=axs[0])\ncle.imshow(binary, plot=axs[1])\ncle.imshow(labels, plot=axs[2], labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\n\n# select a specific OpenCL / GPU device and see which one was chosen\ncle.select_device('RTX')\n\ninput_image = cle.asarray(input_image)\ninput_image", "text": "\n\nAlternatively, with some intermediate correction, e.g. binary opening, we can improve segmentation quality in the binary image before labeling individual objects.", "code": "binary = input_image < threshold\n\n# binary opening, a.k.a. binary erosion followed by binary dilation:\ncorrected_binary = cle.maximum_box(cle.minimum_box(binary, radius_x=2, radius_y=2), radius_x=2, radius_y=2)\n\nlabels = cle.voronoi_labeling(corrected_binary)\n\nfig, axs = plt.subplots(1, 3, figsize=(15, 15))\ncle.imshow(input_image, plot=axs[0])\ncle.imshow(binary, plot=axs[1])\ncle.imshow(labels, plot=axs[2], labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\n\n# select a specific OpenCL / GPU device and see which one was chosen\ncle.select_device('RTX')", "text": "\n\nFurthermore, background intensity appears to increase, potentially a result if more scattering deep in the sample. We can compensate for that by using a background subtraction technique:", "code": "backgrund_subtracted = cle.top_hat_box(equalized_intensities_stack, radius_x=5, radius_y=5, radius_z=5)\nshow(backgrund_subtracted)"}
{"imports": "import pyclesperanto_prototype as cle\n\n# select a specific OpenCL / GPU device and see which one was chosen\ncle.select_device('RTX')", "text": "\n\n## Segmentation\n", "code": "segmented = cle.voronoi_otsu_labeling(backgrund_subtracted, spot_sigma=3, outline_sigma=1)\nshow(segmented, labels=True)"}
{"imports": "import pyclesperanto_prototype as cle\n\n# select a specific OpenCL / GPU device and see which one was chosen\ncle.select_device('RTX')", "text": "\n\nAs segmentation results are hard to inspect in 3D, we generate an image stack with the original intensities + outlines of the segmentation. We show this stack for a couple of slices.", "code": "a_slice = cle.create([resampled.shape[1], resampled.shape[0]])\nsegmented_slice = cle.create([resampled.shape[1], resampled.shape[0]])\n\nfor z in range(0, resampled.shape[2], 20):\n    label_outlines = None\n    combined = None\n\n    # get a single slice from the intensity image and the segmented label image\n    cle.copy_slice(resampled, a_slice, z)\n    cle.copy_slice(segmented, segmented_slice, z)\n\n    # determine outlines around labeled objects\n    label_outlines = cle.detect_label_edges(segmented_slice, label_outlines)\n\n    # combine both images\n    outline_intensity_factor = cle.maximum_of_all_pixels(a_slice)\n    combined = cle.add_images_weighted(a_slice, label_outlines, combined, 1.0, outline_intensity_factor)\n\n    # visualisation\n    fig, axs = plt.subplots(1, 3, figsize=(15, 15))\n    cle.imshow(a_slice, plot=axs[0])\n    cle.imshow(segmented_slice, plot=axs[1], labels=True)\n    cle.imshow(combined, plot=axs[2])"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nA potential use-case is fine-tuning cell segmentation results. Thus, we take a look at a segmentation of cells based on membranes.", "code": "membranes = cle.imread(\"../../data/membranes.tif\")\nmembranes\n\n\nlabels = cle.imread(\"../../data/membranes_labeled.tif\").astype(np.uint32)\nlabels"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle\nimport matplotlib.pyplot as plt", "text": "\n\nThe `smooth_labels` function allows to straighten the outlines of the labels.", "code": "cle.smooth_labels(labels, radius=5)"}
{"imports": "import pyclesperanto_prototype as cle\n\n# select a specific OpenCL / GPU device and see which one was chosen\ncle.select_device('RTX')", "text": "\n\nBefore segmenting the image, need to push it to GPU memory. For visualisation purposes we crop out a sub-region:", "code": "input_gpu = cle.push(input_image)\ninput_gpu\n\ninput_crop = cle.crop(input_gpu, start_x=bb_x, start_y=bb_y, width=bb_width, height=bb_height)\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 15))\ncle.imshow(input_gpu, plot=axs[0])\ncle.imshow(input_crop, plot=axs[1])"}
{"imports": "import pyclesperanto_prototype as cle\n\n# select a specific OpenCL / GPU device and see which one was chosen\ncle.select_device('RTX')", "text": "\n\n## Applying the algorithm\nVoronoi-Otsu-labeling is a command in clesperanto, which asks for two sigma parameters. The first sigma controls how close detected cells can be (`spot_sigma`) and second controls how precise segmented objects are outlined (`outline_sigma`).", "code": "sigma_spot_detection = 5\nsigma_outline = 1\n\nsegmented = cle.voronoi_otsu_labeling(input_gpu, spot_sigma=sigma_spot_detection, outline_sigma=sigma_outline)\nsegmented_crop = cle.crop(segmented, start_x=bb_x, start_y=bb_y, width=bb_width, height=bb_height)\n\nfig, axs = plt.subplots(1, 2, figsize=(15, 15))\ncle.imshow(segmented, labels=True, plot=axs[0])\ncle.imshow(segmented_crop, labels=True, plot=axs[1])"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imshow\nimport matplotlib\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\n\ncle.imshow(tissue, labels=True)\n\nmembranes = cle.detect_label_edges(tissue)\ncle.imshow(membranes)", "text": "\n\n# Analysis and visualization of neighbor count", "code": "touch_matrix = cle.generate_touch_matrix(tissue)\nneighbor_count = cle.count_touching_neighbors(touch_matrix)\n\nparametric_image = cle.replace_intensities(tissue, neighbor_count)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=10, color_map='jet')\n"}
{"imports": "import pyclesperanto_prototype as cle\nimport numpy as np\nfrom skimage.io import imshow\nimport matplotlib\n\n# Generate artificial cells as test data\ntissue = cle.artificial_tissue_2d()\n\ncle.imshow(tissue, labels=True)\n\nmembranes = cle.detect_label_edges(tissue)\ncle.imshow(membranes)", "text": "\n\n## Average the measurement between cells to reduce noise\nMean of touching neighbors", "code": "local_mean_neighbor_count = cle.mean_of_touching_neighbors(neighbor_count, touch_matrix)\n\nparametric_image = cle.replace_intensities(tissue, local_mean_neighbor_count)\ncle.imshow(parametric_image, min_display_intensity=0, max_display_intensity=10, color_map='jet')"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape\n\ncle.imshow(input_image)", "text": "\n\n## Rotation\nFor rotating an image, you need to provide angles corresponding to axes.", "code": "rotated = cle.rotate(input_image, angle_around_z_in_degrees=45)\ncle.imshow(rotated)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape\n\ncle.imshow(input_image)", "text": "\n\nImages are rotated around their center by default. You can change this by providing an additional parameter. The image will then be rotated around the origin.", "code": "rotated = cle.rotate(input_image, angle_around_z_in_degrees=15, rotate_around_center=False)\ncle.imshow(rotated)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape\n\ncle.imshow(input_image)", "text": "\n\n## Translation\nImages can be translate by providing translation distances along axes:", "code": "translated = cle.translate(input_image, translate_x=50, translate_y=-50)\ncle.imshow(translated)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape\n\ncle.imshow(input_image)", "text": "\n\n## Scaling\nYou can scale the image by providing scaling factors.", "code": "scaled = cle.scale(input_image, factor_x=0.5, factor_y=2)\ncle.imshow(scaled)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape\n\ncle.imshow(input_image)", "text": "\n\n## Auto-size\nEspecially for scaling, the `auto_size` parameter may be helpful:", "code": "scaled = cle.scale(input_image, factor_x=0.5, factor_y=2, auto_size=True)\ncle.imshow(scaled)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape\n\ncle.imshow(input_image)", "text": "\n\n## Rigid transform\nRigid transforms allow to do translations and rotations in one shot", "code": "rigid_transformed = cle.rigid_transform(input_image, translate_x=20, angle_around_z_in_degrees=45)\ncle.imshow(rigid_transformed)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape\n\ncle.imshow(input_image)", "text": "\n\nAlternatively, you can configure a transform object and pass it:", "code": "transform = cle.AffineTransform3D()\ntransform.translate(50)\ntransform.scale(1, 2, 0.5)\n\ntransformed_image = cle.affine_transform(input_image, transform=transform)\ncle.imshow(transformed_image)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape\n\ncle.imshow(input_image)", "text": "\n\n# Interoperability with scikit-image\nScikit-image only supports 2D transforms and thus, we pick a slice to transform it:", "code": "# pull image stack from GPU and pick a slice\nimage = cle.pull_zyx(input_image)[80]\n\nfrom skimage.io import imshow\nimshow(image)"}
{"imports": "from skimage import transform as tf\n\n# define transform with #scikit image\ntransform = tf.AffineTransform(scale=0.5, translation=[10,0])\n\ntransformed_image = tf.warp(image, transform.inverse)\nimshow(transformed_image)", "text": "\n\nNext, we push this single plane image to the GPU and transform it using pyclesperanto", "code": "image_gpu = cle.push_zyx(image)\n\n# define transform with #scikit image\nfrom skimage import transform as tf\ntransform = tf.AffineTransform(scale=0.5, translation=[10,0])\n\ntransformed_image = cle.affine_transform(image_gpu, transform=transform)\ncle.imshow(transformed_image)"}
{"imports": "from skimage import transform as tf\n\n# define transform with #scikit image\ntransform = tf.AffineTransform(scale=0.5, translation=[10,0])\n\ntransformed_image = tf.warp(image, transform.inverse)\nimshow(transformed_image)", "text": "\n\n# Nearest neighbor interpolation", "code": "# create a larger image\nrescaled = cle.create(np.asarray(crop.shape) * 10)\n\n# fill it with a scaled version of the image; \ncle.scale(crop, rescaled, factor_x=10, factor_y=10, factor_z=10, linear_interpolation=False)\ncle.imshow(rescaled)"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n## What you need to know before deskewing\nWhen deskewing a dataset, the voxel sizes and the deskewing angle must be known. Ask your microscopist if these values are unknown. The resulting dataset will later be isotropic and have a voxel size like the original dataset along the X axis.", "code": "voxel_size_x_in_microns = 0.1449922\nvoxel_size_y_in_microns = 0.1449922\nvoxel_size_z_in_microns = 0.3\n\ndeskewing_angle_in_degrees = 30"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nWhen looking at this image stack from the side, one can see the tilt of the light sheet orientation.", "code": "fig, axs = plt.subplots(1, 1, figsize=(15,15))\n\ncle.imshow(cle.maximum_x_projection(original_image), plot=axs)"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nThe resulting image has a quite different size because the image stack is not just sheared, it is also rotated in a way that the Z-planes of the resulting image stack correspond to an orientation that the Z-axis goes in proximal-distal orientation from the objective. As if we hat acquired an image using a confocal microscope. ", "code": "fig, axs = plt.subplots(3, 1, figsize=(30,10))\n\ncle.imshow(deskewed[20].T, plot=axs[0])\ncle.imshow(deskewed[30].T, plot=axs[1])\ncle.imshow(deskewed[45].T, plot=axs[2])"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nIf we project this stack from the side, we see the deskewed tilt, especially in comparison again the projected original image", "code": "fig, axs = plt.subplots(2, 1, figsize=(15,5))\n\ncle.imshow(cle.maximum_x_projection(cle.flip(deskewed, flip_y=False)).T, plot=axs[0])\naxs[0].title.set_text(\"Deskewed image\")\ncle.imshow(cle.maximum_x_projection(original_image), plot=axs[1])\naxs[1].title.set_text(\"Raw image\")"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n## Loading example data", "code": "voxel_size_x_in_microns = 0.1449922\nvoxel_size_y_in_microns = 0.1449922\nvoxel_size_z_in_microns = 0.3\n\ndeskewing_angle_in_degrees = 30"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\nTo demonstrate the effect, we will now reduce the imaging data in Z; we remove planes and update the voxel size.", "code": "reduction_factor = 3\n\noriginal_image = original_image[::reduction_factor]\nvoxel_size_z_in_microns = voxel_size_z_in_microns * reduction_factor"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\nWhen looking at this image stack from the side, one can see the tilt of the light sheet orientation.", "code": "cle.imshow(original_image[:,:,100].T)"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n## Deskewing with linear interpolation", "code": "deskewed = cle.deskew_y(original_image, \n                        angle_in_degrees=deskewing_angle_in_degrees, \n                        voxel_size_x=voxel_size_x_in_microns, \n                        voxel_size_y=voxel_size_y_in_microns, \n                        voxel_size_z=voxel_size_z_in_microns,\n                       linear_interpolation=True)\n\ndeskewed.shape\n\ncle.imshow(deskewed[:,:250,100])"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")", "text": "\n\n## Deskewing without linear interpolation", "code": "deskewed_wo_interpolation = cle.deskew_y(original_image, \n                        angle_in_degrees=deskewing_angle_in_degrees, \n                        voxel_size_x=voxel_size_x_in_microns, \n                        voxel_size_y=voxel_size_y_in_microns, \n                        voxel_size_z=voxel_size_z_in_microns,\n                        linear_interpolation=False)\n\ndeskewed_wo_interpolation.shape\n\ncle.imshow(deskewed_wo_interpolation[:,:250,100])"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")\n\ncle.__version__", "text": "\n\n## Loading example data", "code": "voxel_size_x_in_microns = 0.1449922\nvoxel_size_y_in_microns = 0.1449922\nvoxel_size_z_in_microns = 0.3\n\ndeskewing_angle_in_degrees = 30"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")\n\ncle.__version__", "text": "\n\nTo demonstrate the effect, we will now reduce the imaging data in Z; we remove planes and update the voxel size.", "code": "reduction_factor = 3\n\noriginal_image = original_image[::reduction_factor]\nvoxel_size_z_in_microns = voxel_size_z_in_microns * reduction_factor"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")\n\ncle.__version__", "text": "\n\nWhen looking at this image stack from the side, one can see the tilt of the light sheet orientation.", "code": "cle.imshow(original_image[:,:,100].T)"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")\n\ncle.__version__", "text": "\n\n## Deskewing with orthogonal interpolation", "code": "deskewed = cle.deskew_y(original_image, \n                        angle_in_degrees=deskewing_angle_in_degrees, \n                        voxel_size_x=voxel_size_x_in_microns, \n                        voxel_size_y=voxel_size_y_in_microns, \n                        voxel_size_z=voxel_size_z_in_microns,\n                        linear_interpolation=True)\n\ndeskewed.shape\n\ncle.imshow(deskewed[:,:250,100])"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")\n\ncle.__version__", "text": "\n\n## Deskewing without orthogonal interpolation", "code": "deskewed_wo_interpolation = cle.deskew_y(original_image, \n                        angle_in_degrees=deskewing_angle_in_degrees, \n                        voxel_size_x=voxel_size_x_in_microns, \n                        voxel_size_y=voxel_size_y_in_microns, \n                        voxel_size_z=voxel_size_z_in_microns,\n                        linear_interpolation=False)\n\ndeskewed_wo_interpolation.shape\n\ncle.imshow(deskewed_wo_interpolation[:,:250,100])"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.select_device(\"RTX\")\n\ncle.__version__", "text": "\n\n## Deskewing well z-sampled data\nThe artifact is still present but harder to discover in case voxels were sampled almost isotropically.", "code": "voxel_size_z_in_microns = 0.3\n\noriginal_image = imread('../../data/RBC_tiny.tif')\noriginal_image.shape\n\ndeskewed = cle.deskew_y(original_image, \n                        angle_in_degrees=deskewing_angle_in_degrees, \n                        voxel_size_x=voxel_size_x_in_microns, \n                        voxel_size_y=voxel_size_y_in_microns, \n                        voxel_size_z=voxel_size_z_in_microns,\n                        linear_interpolation=True)\n\ncle.imshow(deskewed[:,:250,100])\n\ndeskewed_wo_interpolation = cle.deskew_y(original_image, \n                        angle_in_degrees=deskewing_angle_in_degrees, \n                        voxel_size_x=voxel_size_x_in_microns, \n                        voxel_size_y=voxel_size_y_in_microns, \n                        voxel_size_z=voxel_size_z_in_microns,\n                        linear_interpolation=False)\n\ncle.imshow(deskewed_wo_interpolation[:,:250,100])"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\n## What you need to know before deskewing\nWhen deskewing a dataset, the voxel sizes and the deskewing angle must be known. Ask your microscopist if these values are unknown. The resulting dataset will later be isotropic and have a voxel size like the original dataset along the X axis.", "code": "voxel_size_x_in_microns = 0.1449922\nvoxel_size_y_in_microns = 0.1449922\nvoxel_size_z_in_microns = 0.3\n\ndeskewing_angle_in_degrees = 30"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nWhen looking at this image stack from the side, one can see the tilt of the light sheet orientation.", "code": "fig, axs = plt.subplots(1, 1, figsize=(15,15))\n\ncle.imshow(cle.maximum_y_projection(original_image), plot=axs)"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nThe resulting image has a quite different size because the image stack is not just sheared, it is also rotated in a way that the Z-planes of the resulting image stack correspond to an orientation that the Z-axis goes in proximal-distal orientation from the objective. As if we hat acquired an image using a confocal microscope. ", "code": "fig, axs = plt.subplots(1, 3, figsize=(10,10))\n\ncle.imshow(deskewed[5].T, plot=axs[0])\ncle.imshow(deskewed[15].T, plot=axs[1])\ncle.imshow(deskewed[35].T, plot=axs[2])"}
{"imports": "from skimage.io import imread\nimport matplotlib.pyplot as plt\nimport pyclesperanto_prototype as cle\n\ncle.get_device()", "text": "\n\nIf we project this stack from the side, we see the deskewed tilt, especially in comparison again the projected original image", "code": "fig, axs = plt.subplots(2, 1, figsize=(15,5))\n\ncle.imshow(cle.maximum_y_projection(cle.flip(deskewed,flip_x=False)), plot=axs[0])\naxs[0].title.set_text(\"Deskewed image\")\ncle.imshow(cle.maximum_y_projection(original_image).T, plot=axs[1])\naxs[1].title.set_text(\"Raw image\")"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\n## Setup example data", "code": "voxel_size_x_in_microns = 0.1449922\nvoxel_size_y_in_microns = 0.1449922\nvoxel_size_z_in_microns = 0.3\n\ndeskewing_angle_in_degrees = 30\n\n\nrbc = np.ones([150, 118, 209])\nrbc.shape"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\n## Deskew it", "code": "deskewed = cle.deskew_y(rbc, \n                        angle_in_degrees=deskewing_angle_in_degrees, \n                        voxel_size_x=voxel_size_x_in_microns, \n                        voxel_size_y=voxel_size_y_in_microns, \n                        voxel_size_z=voxel_size_z_in_microns)\n\ndeskewed.shape"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nTo reverse the deskewing transformation from deskewed volume back into the original volume, we need to get the deskewing-transformation first as an object.", "code": "transform = cle.AffineTransform3D()\ntransform._deskew_y(angle_in_degrees=deskewing_angle_in_degrees, \n                        voxel_size_x=voxel_size_x_in_microns, \n                        voxel_size_y=voxel_size_y_in_microns, \n                        voxel_size_z=voxel_size_z_in_microns)"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\nCompute the size of the original image stack and the corresponding transform", "code": "new_size, autosize_transform, translation = cle._tier8._affine_transform._determine_translation_and_bounding_box(\n                                    rbc, transform)\n\nnew_size\n\n"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\n## Invert the transform\nOnce we set up the transform, we can invert it.", "code": "inverse_transform = autosize_transform.inverse()"}
{"imports": "import numpy as np\nimport pyclesperanto_prototype as cle", "text": "\n\n## Apply the inverse transform", "code": "undeskewed = cle.affine_transform(deskewed, transform=inverse_transform, auto_size=True)\n\nundeskewed.shape\n\nrbc.shape"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape", "text": "\n\n## The Z-plane\nWe draw a maximum-intensity projection along Z first to clarify names of dimensions. This is a projection of the XY-plane, also known as the Z-plane. In this plane, X goes from left to right and Y goes from top to bottom.", "code": "fig, (ax1,ax2) = plt.subplots(1, 2)\n\ncle.imshow(input_image[60], plot=ax1)\ncle.imshow(cle.maximum_z_projection(input_image), plot=ax2)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape", "text": "\n\n## The Y-plane\nWe now take a look at the Y-plane, also known as the XZ-plane, and a maximum intensity projection along Y. X goes from left to the right in these images and Z from top to bottom.", "code": "fig, (ax1,ax2) = plt.subplots(1, 2)\n\ncle.imshow(input_image[:,60], plot=ax1)\ncle.imshow(cle.maximum_y_projection(input_image), plot=ax2)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape", "text": "\n\n## The X-plane\nWe now take a look at the X-plane, also known as the ZY-plane, and a maximum intensity projection along X. Y goes from top to the bottom in these images and Z goes from left to right.", "code": "fig, (ax1,ax2) = plt.subplots(1, 2)\n\ncle.imshow(cle.transpose_xy(input_image[:,:,64]), plot=ax1)\ncle.imshow(cle.maximum_x_projection(input_image), plot=ax2)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread\n\n\n# Laod example data\ninput_image = imread(\"../../data/Haase_MRT_tfl3d1.tif\")\ninput_image.shape", "text": "\n\n### Update to the new nomenclature!\nIt is however recommended to update that code to use the new nomenclature which is more self-descriptive. Instead of passing a shearing factor, you should pass the shearing angle in degrees. Furthermore, the presign should now be different. A shearing to the left is negative, shearing to the right is positive. This code does the same as the CLIJ-compatible code above:", "code": "transformed_image = cle.affine_transform(input_image, transform=\"shear_in_z_plane_along_x=-45\")\ncle.imshow(transformed_image)"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread, imsave\n", "text": "\n\nObviously, there is a tilt in X direction visible in the YZ plane.", "code": "cle.imshow(input_image[:,:,int(input_image.shape[2] / 2)])"}
{"imports": "import pyclesperanto_prototype as cle\n\ncle.select_device('RTX')\n\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nfrom skimage.io import imshow, imread, imsave\n", "text": "\n\nNext, we shear this dataset to get the z-planes in the right position again. Note, we are deactivating interpolation in thise example to avoid blurring introduced by interpolation. Depending on slice distance and deskewing/shearing angle, this might introduce artifacts visible as steps between slices.", "code": "shear_angle = -(90 - deskewing_angle_in_degrees * voxel_size_xy / voxel_size_z)\n\n# transform the image\ntransform = cle.AffineTransform3D()\ntransform.shear_in_x_plane(angle_y_in_degrees=shear_angle)\ntransformed_image = cle.affine_transform(input_image, \n                                         transform=transform, \n                                         auto_size=True,\n                                         linear_interpolation=False)\n\ncle.imshow(transformed_image[:,:,int(transformed_image.shape[2] / 2)])"}
